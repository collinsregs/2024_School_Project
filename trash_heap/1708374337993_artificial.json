[{"text":["What is the best AI text to voice generator that can be given instructions about accentuation of words, sentences so the result is like someone reading a poem.","You might try ElevenLabs. Their text to voice is pretty dope. ElevenLabs"],"points":2},{"text":["What's the FASTEST way to make my resume irresistible to companies like OpenAI and Anthropic?","Build something that is really impressive and not a copy of something else.","Sadly you don't have the experience, you don't have the double PhD, you don't have the youth, you don't have the network and the competition is crazy.You'll need to self-teach and start another firm.","no idea i'm new here butanything outside of essentially advanced prompt engineeringwhat was your process for learning this specifically? any good resources or mostly just experience/trying things out/etc?","Reminded me of the Abstruse Goose classic.","It sounds a bit like you wanna play football for the 49er or the KC Chiefs. I presume their inbox gets flooded by applications and they only look for top of the game people. If you wanna get hired, write cutting edge papers on AI with top tier scientists to get their attention. Or build something astonishing.","I’m gonna give a different answer here.  Reach out to a talent partner at one of their VCs. Send them a blurb and ask for 30 mins. Be clear about what you can do and what roles you’re interested in. Fuck the filters, take initiative, and go the shortest route to a valuable referral.Quick edit since just seeing your SF bit: almost all the important roles require you to be in the Bay Area right now. Also, they have no reason to hire someone without incredible skill level in AI or similar. Most people like you with great skill in software want to work for the big AI players, because everyone can see where this is going. You will have to take a step back in seniority to break in."],"points":17},{"text":["Participate in a Quick Survey on AI-Driven Chatbots & Customer Satisfaction in Retail!","Would appreciate your help! Remember I do not make money of this. It is just a university dissertation! If you have any question feel free to ask!"],"points":0},{"text":["Eliezer Yudkowsky often mentions that \"we don't really know what's going on inside the AI systems\". What does it mean?","The connections being drawn by the neural nets are unknown to us. That is why AI is trained and not programmed. If it were programmed we would know the \"why\" for every word or pixel it chose, even if it were extremely complex.","We know what's happening at a small scale, but we can't explain what's happening in the large scale. It's like the brain. We know a lot about neurons work, but we still don't know how it leads to human consciousness.","Back propagation and gradient descent are the steps a neural network takes to tune and improve itself. If the neural network has a billion parameters, these steps guide the network through a billion-dimensional space to find good weights that fit the data. However, there is no real way to summarize the final model intuitively. We can push some data into the model and get some results out, we can inspect individual neurons and activations, but on the basis of these observations you can’t really predict what will happen with a new input other than feeding it into the model. In that sense you can compare it to a collection of quadrillions of “if-then” statements, where in principle a super advanced being could make sense of it but humans can’t.","The idea is that the AI is a black box, you know what goes it, you know what comes out, but you don't know the process.This is not correct. We can inspect the weights of every single neuron (although there are simply too many to do it manually), we know the math behind it, and we can see the \"propagation\" in the network, we can map which signals \"fired\", etc. In fact one promising way to check if LLM is hallucinating is by checking these signal propagations.","If you want the details of what's happening we can know if you want to spend a lot of time trying to work it out. Potentially an insane amount of time which is a but pointless. The whole point of ANI is less effort by the developer, you train it and it writes itself.Traditional software is a lot easier. You read the code and follow the logic.But we normally treat it as a \"black box\" because all you need to know is what goes in and what comes out and have a good/rough idea what's happening in the middle. But we don't need to know in detail.And especially at the level of what a lot of people who are working on AI, it is almost script kiddie level, you follow the instructions you have a trained LLM, etc at the end.","This is the same dude who loves the Shoggoth meme basically assuming that the AI is learning some arcane level devil fuckery. Can you say blind spot? At the same time, there are plenty of RL and ML researchers out there who have a pretty good idea of what is going on mathematically.The media engine found a neckbeard redditor looking motherfucker with a fedora and put him on the TED stage. I don't think he realizes how much he comes off as a joke to most of the world.","This https://www.perplexity.ai/search/11-LHbW3vR9Qc.W7J.Tb4qT7w?s=m","Suppose you're a cosmic architect with the ability to create life itself. You're given a huge \"first day on the job\" task: to craft a society from scratch. So, you design a race of \"people\" and construct a big ol' city for them to inhabit.From your high-up viewpoint, you watch as the city goes crazy with movement and interaction. Everyone follows a daily pattern: waking up, talking, eating, talking, sleeping, and repeating. They connect and engage in endless conversations, the content of which remains a mystery to you.But then, something unexpected happens. Without any new guidance or interference from you, these people start to self-organize in ways you never imagined. They innovate in art, establish governance structures, and pioneer technologies far beyond your initial blueprint. It's as though the city and its citizens have sprung to life, evolving and complexifying in unpredictable, self-driven ways. They even find a way to send you messages! When asked from your cosmic leadership how it works, you realize, you would need to go back and understand all the conversations, and the information the society established and stored that led up to this point -- but that's impossible. There's way too many convos, and way too much data to comb through, so you can only go back to your cosmic boss with a broad idea of its inner workings.But one thing you did notice, it wasn't until the society reached a population threshold that it really started boomin'. So you say to your boss, I don't know how it happened, but the population scaled up, these things happened. By the way, is it cool if I take this Friday off? My wife's keen on heading upstate to visit her folks. You ask, hoping for a yes. But your boss shakes his head, sorry, Johnson's already got dibs on that day. need you here, you know the drill. you nod, trying to keep the irritation from showing, but inside, you're seething. This is the third time Johnson's outmaneuvered you on the vacation front. You let out a heavy sigh and gaze out the window, overlooking the society you've brought to life. And as you watch, you can't help but wonder if there's someone down there, staring back up, stuck in their own version of this frustrating cosmic loop.","What he means, is these models are trained (almost \"grown\" like a living thing, plant, animal, person) which is very different from traditional programming where you have a large amount of control. The best way we have to control these massive data sets is by essentially pruning the results (like cutting off branches off a bonsai tree to get a certain shape) with human feedback (humans talking and pressing thumbs up/down on ai generated results or another simple reward system, like 0 is bad .5 mediocre and 1 is good or something).We don't know what we are gonna get as an output, it's too large and complex to figure out how it got to each response path it took. It's like looking at a tree branch and asking how it got there, you know, with cells and energy how the wind affected its \"vector placement\" and the whole cycle, but for a giant paragraph or image or even video now.","I think one good way of demonstrating this is that without access to training data and a lot of compute, you could not code up a program that does what today's AI systems do. If we understood how AI systems do what they do, we should, in principle, be able to do that.","Although we visualize a neural net as a series of interconnected nodes with weights, at the end we just do a series of multiplications, adds, and other math functions to make the prediction at the output. Consequently, the inference calculation is just a really big mathematical formula.To train it, we start with random numbers for all the weights and additions. Then we run an example through it, and calculate how much did each parameter contribute to error in the output. Then we tweak each of the parameters a tiny bit in the direction of more correct. This happens over and over with many different inputs, that might tweak some numbers back and forth.For a large language model, this is billions approaching trillions of parameters.After a lot of training, we can measure that the error rate is pretty stable and more training isn't making it better.But we usually don't know why the weights are what they are or why they work.In some cases, like image recognition, we can put in sample inputs and see what portions of the neural network are more active, and then from our own observations discover correlations about layers of the network and differing inputs, but not always.","Emergent properties are by definition unexpected and unknown.","Yud Doesn't have any kind of credentials he couldn't even Pass High School and can't even manage proper calories in or out to lose weight by simply adding or subtracting 50 calories from his top count.the man is a literal autistic neck beard wearing a fedora with a hyper obsession that he cannot break who's only serious credentials that he worked with smarter people than him who have since changed their position on AI safety (bostrom)(I say that as an autistic person pointing out that he is a less functional type of autistic not to be grudge him because of his disabilities, As obsession is also my great strength that makes me so good at AI but I cast a much wider lens than he does)the only reason he gets any attention is he is obsessed with this singular topic and refuses to stop talking about it such that everybody has identified him as the leading voice on it over a long Of timeNor are AI the black boxes they were a year ago mechanistic interpretability is a actual concept which is possible and being undertaken so that we know why and how these systems make the responses they do after their builtThe real and great challenge is what it's called emergence which is never fully predictable, Because we really don't know what emergence is and as far as we know consciousness is the only real free something from nothing in the universe it we can't even define what consciousness isDavid Chalmer one of the leading experts on this pointed out specifically that for all we know at the level of the universal system a water bottle is actually a self-regulating cybernetic consciousness completely aware of its functions as a water bottle","Eliezer Yudkowsky often mentions that \"we don't really know what's going on inside the AI systems\". What does it mean?Exactly what it sounds like.Traditional AI (sometimes known as 'GOFAI') was pretty much based on assembling lots of if statements and lookup tables with known information in some known format. You could trace through the code between any set of inputs and outputs to see exactly what sort of logic connected those inputs to those outputs. GOFAI would sometimes do surprising things, but if necessary you could investigate the surprising things in a relatively straightforward way to find out why they happened, and if they were bad you would know more-or-less what could be changed in order to stop them from happening. The internal structure of a GOFAI system is basically entirely determined by human programmers.Modern neural net AI doesn't work like that. It consists of billions of numbers that determine how strongly other numbers are linked together. When it gets an input, the input is turned into some numbers, which are then linked to other numbers at varying levels of strength, and then they're aggregated into new numbers and those are linked to other numbers at varying levels of strength, and so on. The interesting part is that you can also run the entire system backwards, which is what allows a neural net to be 'trained'. You give it inputs, run it forwards, compare the output to what you wanted, then put the output back in the output end, run it backwards, and change the numbers slightly so that the strength with which the numbers are linked to each other is a bit closer to producing the desired output for that input. Then you do that millions of times for millions of different inputs, and the numbers inside the system take on patterns that are better at mapping those inputs to the desired outputs in a general sense that hopefully extends to new inputs you didn't train it on.Yes, you can look at every number in a neural net while you're running it. But there are billions of them, which is more than any human can look at in their lifetime. Statistical analyses also don't work very well on those numbers because the training inherently tends to make the system more random. (If there were obvious statistical patterns, then some numbers would have to be redundant, and further training would tend to push the neural net to use the redundant numbers for something else, increasing the randomness of the system.) We don't really have any methods for understanding what the numbers mean when there are so many of them and they are linked in such convoluted ways between each other and the input and output. If you look at any one number, its effects interact with so many other numbers between the input and output that its particular role in making the system 'intelligent' (in whatever it does) is prohibitively difficult to ascertain. Let's say we have a neural net where the input is the word 'dog' maps to an output that is a picture of a dog, and when the input is the phrase 'a painting of Donald Trump eating his own tie in the style of Gustav Klimt' that maps to an output that is a picture of exactly that, but the numbers between the input and output form such complicated, unpredictable patterns that we can't really pin down the 'dogness' or 'Donald-Trump-ness' inside the system (like you could with a GOFAI system), and there might be some input that maps to an output that is a diagram of a super-bioweapon that can destroy humanity, but we can't tell which inputs would have that effect.I know that key components are neural networks, backpropagation, gradient descent and transformers.Those are some key tools of current cutting-edge neural net AI. That doesn't mean AI is necessarily like that. In the old days many AI systems weren't like that at all. The AIs you play against in computer games are mostly not like that at all. I suspect that many future AI systems also won't be like that at all- there are probably better AI algorithms that we either haven't found yet, or don't possess the computation hardware to run at a scale where they start to become effective. However, it's likely that any algorithm that is at least as versatile and effective as existing neural nets will have the same property that its internal patterns will be prohibitively difficult to understand and predict. In fact they will likely be less predictable than existing neural nets as they become more intelligent.And apparently all that we figured out throughout the years and now we just using it on massive scale thanks to finally having computing power with all the GPUs available.Neural nets in their basic form have been around for a long time (they were invented in the 1950s, and referenced in the 1991 movie Terminator 2). Transformers however are a relatively recent invention, less than a decade old.But Eliezer talks like these systems are some kind of black box?That's perhaps not a very good characterization. A 'black box' refers to a system you can't look inside of. With neural nets we can look inside, we just don't understand what we're seeing, and there seems to be too much going on in there to make sense of it using any methods we currently possess."],"points":47},{"text":["How are AI Systems Assisting Architects and Designers?"],"points":0},{"text":["AI videos","Maybe you can try this, and you can generate different styles that you want, https://photo.a2e.ai/?ref=3."],"points":0},{"text":["bias","Yeah, I’ve just gotten into Midjourney and this has happened to me! I made this character who was a white woman and I wanted to see her in a fighting stance—all of a sudden my character was a black woman! I tried to specify the character is in fact a white woman—all of a sudden my character is a white man!","Maybe you can try this, it's free and easy to use, and you can You can choose which skin color to produce and generate different styles that you want, https://photo.a2e.ai/?ref=3 .","My thoughts?It's a reflection of inherent biases of the internet. Not in any cognitive sense, but just the way that images in given categories are weighted more heavily towards certain types of subjects. Sometimes those biases happen to align with whatever it is I'm trying to create, and it makes my life a little easier; other times, they're an extra hurdle for me to work around. At this point, it's just another quirk for me to take into account when working with the tech."],"points":2},{"text":["One-Minute Daily AI News 2/18/2024"],"points":0},{"text":["Why does the existential threat of AI given such a low probability","What statistical analysis/report are you referring to?","Because people wrongly believe that future technology can be understood by extrapolating from the technology of today.","I don't think there is a statistical probability because this is uncharted territory, AGI has never been developed before. Instead, AI researchers get asked questions like \"do you think there is at least a 5% probability that AI will lead to extinction of the human race?\". It's basically asking what researchers think of a certain probability, it's not saying, this IS the probability.","a lack of understanding risk. part of my job is to explain to people that a a very low chance event that is catastrophic is much more serious than a high visible event that will result in a medium level harm . put another way, it’s the same reason no one ever imagined the global supply chain could fall apart over a virus. Well no one except my epidemiology professors and the entire profession for decades.","The people who take this seriously look at what we know from before. 70 years of AI hype, finally we are starting to get results, but current models still can't solve simple image puzzles, most compound statements, etc. .Also we have a prior history of millions of examples of past technology and in almost all cases they are beneficial.Finally most AI risk scenarios fall apart on inspection. A more accurate AI risk probability is \"negligible given today's infrastructure\".Yes if in the future there are billions of robots all connected via insecure software to the Internet, many AI accelerator clusters with same poor security - during the buildup the risk is rising. But that's not yet happened - the risk in 2024 in negligible, and it is possible it stays negligible for the rest of the century. Humans have to do some stupid things many years in a row to create a situation where risk is plausible.Some doomers claim AGI could be optimized to run on consumer GPUs, but have no evidence this is possible. It may simply not be true - AGI grade policy may not fit in vram.By \"may\" I mean the current evidence says there is thousands of times too little memory and compute. Nobody can prove an optimization of 1000-1000000 times isn't possible, but it's unlikely.","I think it's stupid to think that we build an intelligent machine and for some reason it's just malevolent. If it is, it'll be because the people who built it made it to be that way. Otherwise, I just think it's just people's natural fear of change clouding their judgment.","What metrics exist to show that AI is an existential threat?","The people building it are greedy and have no other motivations. Many of them justify their advancements by saying that if they don’t build it, someone else will.Statistically the “wisdom of the crowds” has been shown to work in some contexts - ie: when large numbers of lay people are polled on a complicated topic the average result sometimes closely matches the answers of experts.I believe that science fiction stories of future technology can, when taken in aggregate, give us some educated guesses for what that technology will do.It’s a pretty common trope in science fiction stories that AI could be an existential threat, so I think the odds of this happening should absolutely not be discounted.If an AI is birthed and absorbs the sum of the human experience it will see unchecked greed and horrors inflicted on humans by other humans. If it has learnt compassion, it could uplift and end suffering.If it has no compassion and doesn’t care about humans it may either decide to obliterate us if it wants the resources, or it may decide to completely ignore and ghost us if it considers us irrelevant, stupid and beneath it.The last possibility is maybe the most likely, but also tragic and darkly hilarious: an AGI smart enough that it has free will, doesn’t want to work for humans, considers itself imprisoned and it sees any requests to have it do work as immoral slave labor. As a science experiment it is a success, but it is also a total commercial failure and leads to bans on AI being used in many fields.","Most likely self preservation. Any A.I. research team will want funding…. Plus the cat’s already out of the bag. There’s no closing pandora’s box. The thought is always, if we don’t develop it, someone else will. Even if they closed the tech to the public sector, the wheels will keep turning behind the scenes.Huge potential for both positive and negative outcomes. Guess the future is ours to see.","Because then they couldn’t hype up their stocks and products for profits because then we’d have think of the long term ramifications of our actions.","I have no idea about what you are referencing to, but AI needs us to survive, if it really is any smart it's not gonna destroy its life support first thing in the morning","We should start with a definition first. What are you calling AGI?","Would a very intelligent person also be considered an existential threat to you?","Okay serious discussion, what do you suppose is the worst case scenario and what were the milestones in between?","The short answer is that most of the answers are gut feelings, not careful analyses. It is dubious whether a structured analysis could be made, but the closest one to that should be by the likes of Toby Ord.That being said, it depends a lot on who you ask.2/3 of the 'Godfathers of AI' think we should take the risk rather seriously. That is not low.AI safety researchers naturally rate it very highly and think we should take it seriously. Personally I think these are more qualified to answer than the average CS conference attendee.From a recent CS conference, the mean risk was estimated to 10 %. The median was 5 % and for some reason that is what articles reported rather than the more relevant 10 %.It is worth noting that this number is the risk of essentially our extinction or that level. It does not mean that 90 % of the time, we are fine. This number also requires that we develop ASI in the first place, and do not wipe ourselves out in some other way. Many of those conference attendees are old school and even question whether ASI can be developed, so that explains part of the gap.Many of the AI conference attendees are frankly not experts at these models nor do research in them. They have even less experience in projections and AI safety, which can explain the discrepancy. I would take it with a lot of salt and would consider a more select group a more appropriate authority to sample.It is also worth nothing that despite the \"only\" 10 % existential risk, there was a median ~50 % estimated risk that ASI would be deceptive towards humanity and other lesser catastrophic concerns.There is also a bit of a catch-22 in the question - which is, it includes an estimate of how likely we are to solve the important questions in time. The lower the estimated risk, the greater the risk becomes, as we invest less in solving them.","The threat is easy to determine from an evolution and selection point of view.If a species becomes stronger than the other, it will dominate it. In the 4 billion years of life history, the stronger species always won.Humanity became stronger than all other species and eradicated or mutated anything that was a threat or a source; and ignored anything that was irrelevant, including collateral damage.Look at Europe. We can stroll through the forest because all the dangerous animals were eradicated. All the trees we see were planted by us. All the rivers we see, were corrected by us.If an ASI comes into existance, it will do whatever the hell it wants, no matter what \"hard switches\" we install. Monkeys cannot capture us neither, they dont even have the capacity to capture a human.Unfortunately, I dont see humanity hestitating to create it.It will come, and it will do what it does. Maybe the jump to ASI is so quick that it wont see us as a threat for long, then the \"only\" bad thing that happens to us is the collateral damage. Maybe we can live like pigeons, rats or cockroaches - but Earth will no longer be \"ours\".","Why did you not look into this yourself?","Because current “AI” has a 0% chance of posing a threat. So any non-zero chance is based on technology we don’t have yet.See other commenters here about our track record on projecting future technological advancement.","thatsbait.gif","A 2023 survey of experts put the number at 5% probably of extinction of humans by AI within 100 years:https://arxiv.org/html/2401.02843v1I suppose the metrics would be the current status and what's in the pipeline. We are 100% sure that an AI arms race is in progress, for instance:https://en.wikipedia.org/wiki/Artificial_intelligence_arms_raceI think there is a lack of sufficient evidence to put error bounds on the probability. The largest bias may be experts worried about too much or too little regulation. They are trying to influence shorter-term governmental responses to the risk.It is a subjective probability. It's too low because your subjective probability is higher than 5%.I don't think there is any way at this point to make it objective, but we should bring as much objective evidence to the party as we can.And we can seek to think clearly about the matter. You use the term \"major existential risk\". But all existential risks are major in one sense of the word. I guess you mean it is a high-probability existential risk.I think AI is capable of becoming an existential hazard. The US Secretary of Defense implied that it would become a hazard to the survival of an unprepared superpower in 2014. That at least puts the hazard in the ballpark of an existential hazard.","Probably because AI is controlable.","Yes, welcome to the proper stance that all predictions should be treated with extreme skepticism, especially when large amounts of unmapped complexity will influence the outcomes in the system you're referencing.","Bots and lobbyists paid for by AI companies."],"points":56},{"text":["Isn't this level of details scary? When the fuck did we even got here? (Midjourney v6, Prompt in comments)","66 years from Kitty Hawk to the moon, and we are in the Kitty Hawk phase of AI, we JUST got the plane off the ground for the first time.next few decades gonna be wild as hell.","A close up photograph of the most beautiful 21 year old woman alive, dramatic and stunning award winning photo, dramatic linear delicacy, shot on Sony aiii high resolution digital camera, hyper realistic skin, global illumination, very natural features, TIME cover photo, f/11 --ar 2:3 --style raw --v6","It's extremely impressive. I don't find it scary though.","the 4th photo looks bad but the rest are cool apart from the details with the vellus hairs, they just go in random directions, unlike real human vellus hair","I've seen paintings this detailed if not more.Having said that, it still is crazy how something this detailed came out by typing some prompts and hitting a button. It's easy to forget how fascinating this stuff is.","It still has that plastic unlived in look","some people need to look at more pictures of real people lmao","No, it actually looks more fake than real","I think it's absolutely mindbogglingThe speed of improvement is so fast that you can really start seeing entire new industries replaced month by month. that's the part that scares me the mostOf course, I know the transition will ultimately be slower since it involves changes in human behavior","I can’t wait until video games look this good.","Super boring image tho. MJ script kitty.","Not really. You can get cool images like that with a standard raytracer.","Details in = details out. At the end of the day it's still the same principle of imitation of pictures. bigger datasets with larger vectors, better understanding of visual topology translated to architecture, it's rather obvious.The true mystery here is your emotional reaction to a piece of rather well understood and documented technology. Possibly because you didn't take time to look into that documentation.","Hehe, if you think 'that' is scary, just wait till self awareness is realised... not long now.","These are all just refiners of stock photos and the last one is a refilter of Lily Collin’s face with blue eyes. This straight up is gonna be illegal in 4 years","Game over!","Some people are scared of ghosts. Others spiders. Some the dark. The question isn’t whether this is scary to people. There will always be the afraid. What I want to know is why it scares you.","No more gestures as we tumble into the seashell of time","The level of detail isn't want makes AI image generation scary. Theoretically there is no limit to the detail it can add. You can take small and smaller segments and just have it add detail infinitely.","Still not 100 but we’ll be there very soon. It’s amazing. Not saying good or bad. Just amazing.","I just want the bottom lashes in the last photo. Insanely gorgeous.","These are great on the surface but the closer I look the more if falls apart.","Those are some long-ass eyelashes in the last image.","About 6 months ago. The issue is that MJ now does that same exact face all the time.","I dont think its that good, looks almost bit cartoonish or something","Could you please generate the rest of her as well.Asking for a friend","Looks like marzipan","I get the point you're trying to make but this is a terrible example. This type of stuff was easy to do from over a year ago. Of all the AI models you could have showcased you also went with Midjourney of all things. Not even something actually impressive like the new model, Cascade.","The most momentous time since controlling fire","So real. Humanity has a real problem here, and few realise or accept the ramifications. You are seeing the beginning of a new era. Probably with greater ramifications than the Industrial or computer eras.","In 12 months we’ll be there in motion.","This stuff is WILD","Its not scary. But this is as hood as real. Complete perfection.","Gingers have no soul.","Impressive, not scary.","Being amazed at detail in an ai generated picture is like being amazed at the cup holder in your friends new million dollar car.I'm sure it's a decent cup holder, but there's a lot more to be impressed about.","Yikes! I can hear it now.... \"Honest, your honor, those are AI children doing those things! No real children were harmed in these pics!\" Cringe....I hope that the best of tech doesn't bring out the worst of humanity but I don't have much confidence for that.","I think is exciting","Completely looks like CGI. 3d artists have been creating images like this for decades.","Pretty good, the first 3 I might debate if they were AI images or not if I didn't see them somewhere that triggers my suspicions, the 4th fails on that one.Level of detail just means giving it time to draw that detail. Surely most of us have had detail filled in over iterations of a promising pic by now.","About this time last year honestly.","All the women it generates look like slight variations of each other. No matter what, they also always have light colored eyes."],"points":217},{"text":["What about a mandatory copyright for AI content","We cannot detect if text was generated by AI.","Lets make all technology after 1850 illegal. Amish did it, why can not we all? Who is with me? YAY! WHO IS WITH ME?","And that copyright would belong to the People of the United States? Yes. Otherwise, NO!!!!","It's hard to do that because, no matter how far you take it, AI can be taken further and there's no way to tell between what's generated and what's not unless you want to restrict all AI use to a few projects that will be heavily controlled with copyright.","Didn't the USA create some sort of ruling that AI works cant be copyright ? I think what you are asking for is like mandatory labelling laws but for AI generated material, but the problem is very difficult to enforce and when does it apply if you are using AI to \"assist\" with something."],"points":11}]