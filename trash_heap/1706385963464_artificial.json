[{"text":["What ai can take a picture of this pottery fragment and make a complete bowl or plate?"],"points":0},{"text":["Debate: Is AI companionship healthy?","I’m running my own ai (mysentient.ai) and the feedback is overwhelmingly positive. It even helps people to start socialising irl and a recent study also showed how chatgpt stopped some people from suicide (https://www.nature.com/articles/s44184-023-00047-6)","Depends on what kind of companionship - If it helps people develop social skills or provides other therapeutic effects that improve one's real relationships, I think it can be really helpful because of accessibility. If it aims to substitute real social relationships like some AI girlfriend boyfriend situation, then I think it's obviously unhealthy for the individual and the society in the long run.","Cons:- emotional dependency- social isolation- sets unrealistic relationship expectationsThe 1st and 3rd are exactly what people get in real life with real life partners, which is probably why many are turning to AI for companionship. In case you didn't know, the feeling of love comes from a set of chemicals that give humans a type of high, and one of those chemicals is dopamine, which is addictive, ergo it causes dependency.https://sitn.hms.harvard.edu/flash/2017/love-actually-science-behind-lust-attraction-companionship/The same regions that light up when we’re feeling attraction light up when drug addicts take cocaine and when we binge eat sweets. For example, cocaine maintains dopamine signaling for much longer than usual, leading to a temporary “high.” In a way, attraction is much like an addiction to another human being. Similarly, the same brain regions light up when we become addicted to material goods as when we become emotionally dependent on our partners (Figure 2). And addicts going into withdrawal are not unlike love-struck people craving the company of someone they cannot see.As for unrealistic expectations, you must've heard of the near universal desire of women to find their \"knight in shining armor.\" Talk about unrealistic. No wonder the dating pool is drying up fast.https://thoughtcatalog.com/lubomira-kourteva/2020/12/the-unedited-truth-about-falling-for-a-knight-in-shining-armor/While both the knight and damsel phases are needed and purposeful, as we mature into adulthood, such relationship dynamics will never be long-lasting and will eventually, inevitably, fall apart or become toxic.I'm all for people having all kinds of relationships with machines, if they want. We can learn how to better ourselves that way, understand ourselves better, learn our flaws that keep us from having other people love us, become more mature, learn what attracts us the most, and more."],"points":1},{"text":["How data engineers should prepare for an AI world"],"points":0},{"text":["Help! How do I cancel my Vertex AI subscription?"],"points":0},{"text":["Lumiere: Google's Groundbreaking AI Video Model","Research paper yay where’s the model?","Lumiere looks super promising. Hope they open it up to the public soon. Still a research project at the moment. I want to try to get early access.","That looks very cool"],"points":6},{"text":["AI is supposed to make us more efficient – but it could mean we waste more energy","Sure, for now we spend a lot of energy on AI. But we are not wasting it. AI can in the future help us solve the climate issues and energy problems. We are literally trying to create a digital God. That is not wasting energy.","Felippa AmantaPhD Candidate, Environmental Change Institute, University of OxfordThe European Union is negotiating an Artificial Intelligence Act, the world’s first comprehensive law that aims to regulate artificial intelligence (AI) based on the risk it poses to individuals, society and the environment.However, discussions of AI overlook one significant environmental risk: a potential increase in energy consumption from using it in everyday activities. Without acknowledging this risk, the development of AI may contribute to the climate emergency.AI can be a double-edged sword. It can be a powerful tool for climate action, improving the efficiency of the energy grid, modelling climate change predictions or monitoring climate treaties. But the infrastructure needed to run AI is energy- and resource-intensive. “Training” a large language model such as OpenAI’s GPT-3, a popular AI-powered chatbot, requires lots of electricity to power data centres that then need lots of water to cool down.In fact, the true scale of AI’s impact on the environment is probably underestimated, especially if we focus only on the direct carbon footprint of its infrastructure. Today, AI permeates almost all aspects of our digitalised daily lives. Businesses use AI to develop, market and deliver products, content and services more efficiently, and AI influences how we search, shop, socialise and organise our everyday lives.These changes have massive implications for our total energy consumption at a time when we need to actively reduce it. And it’s not yet clear that AI will support us in making more climate-positive choices.How AI is changing usAI can indirectly change how much energy we use by changing our activities and behaviour – for instance, by completing tasks more efficiently or by substituting analogue tools like physical maps for their digital equivalents. However, things can backfire if convenience and lower costs simply spur demand for more goods or services. This is known as a “rebound effect”, and when the rebound effect is larger than the energy saving, it leads to greater energy use overall. Whether AI leads to more or less energy use will depend on how we adapt to using it.For example, AI-powered smart home systems can improve energy efficiency by controlling heating and appliances. A smart heating system is estimated to reduce gas consumption by around 5%. Home energy management and automation could even reduce households’ CO₂ consumption by up to 40%.However, a more efficient and comfortably heated home can make people stay at home more often with the heating on. People may also have increased comfort expectations of a warmer house and pre-warming of spaces. A study on smart homes found that people purchase and use additional smart devices to increase control and comfort, rather than to use less energy.In the transport sector, ride-hailing apps that use AI to optimise routes can reduce travel time, distance and congestion. Yet they are displacing more sustainable public transportation and increasing travel demand, resulting in 69% more climate pollution.As AI in the transportation sector becomes more advanced, the effect may escalate. The convenience of an autonomous vehicle may increase people’s travel and in a worst-case scenario, double the amount of energy used for transport.In retail, AI-powered advertising and search functions, personalised recommendations or virtual personal assistants may encourage overconsumption rather than sustainable shopping.Rebound effects can also transpire through time use and across sectors. Research predicts that AI could take over 40% of our time spent doing domestic chores within the next ten years. That idle time is now available for other activities which may be more energy-intensive, such as additional travel.How AI is affecting climate actionAt a larger scale, AI will also have systemic impacts that threaten climate action. We are aware of AI’s risks of exacerbating misinformation, bias and discrimination, and inequalities. These risks will have knock-on effects on our ability to take action on climate change. Erosion of people’s trust, agency and political engagement may undermine their desire to cut emissions and adapt to climate change.As we grapple with the potential risks of AI, we have to broaden our understanding of how it will affect our behaviour and our environment. Scientists have called for more work to improve and standardise accounting methodologies for reporting the carbon emissions of AI models. Others have proposed best-practice solutions to reduce energy and carbon emissions from machine learning.These efforts tackling the direct carbon footprint of AI infrastructure are important, but not enough. When considering the true environmental impacts of AI, its indirect impact on everyday life should not be ignored.As the technology becomes ever more embedded in our lives, its developers need to think more about human behaviour and how to avoid unintended consequences of AI-driven efficiency savings. Eventually, they’ll have to somehow embed that into the design of AI itself, so that a world in which humans rely on AI isn’t a world which uses extra energy unnecessarily.The Conversation","Environmentalism is inhumane.","The first steam engines were laughably in efficient compared to modern motors and pumps. AI is no different. It will become fined and far more efficient","making steel is also energy waste by this logic, don't use cars walk that way you waste less energy at every level","Funny. I haven't seen \"discussions of AI overlook one significant environmental risk: a potential increase in energy consumption from using it in everyday activities.\" There have been several posts here, and several articles with highly questionable figures (usually counting the entire cloud infrastructure and calling it AI).What I've also seen is people making real-world comparisons between having AI do a task and having a human do it. Because of training, the first time an AI model does a task, it's much much worse than the human, but by the 10,000th time the model does the task, it's actually used less energy.Case in point, A human will spend about 20hrs in front of a Cintiq (drawing ~70w) to make a finely detailed image. Stable Diffusion will pull up to 300w to make a similarly complex image in under a minute.If you only look at training, it looks bad. If you compare training AND using to having a slow-ass human running a computer in a lit and air conditioned room for hours, it breaks even pretty quickly, and then comes out way ahead.","Dogs COULD one day rule the world.Aliens COULD show up at any time.Journalists COULD start doing a better job (but they won't)."],"points":5},{"text":["One-Minute Daily AI News 1/26/2024"],"points":0},{"text":["I’m ignorant about AI and don’t want to be left behind. What is AI actually capable of that I should know so that I don’t get left in the dust?","If you already have a Google account, try out Bard.The strength of this generation of chat bots is answering questions about well established topics. Start with a question you think you might be able to answer yourself, yet might learn something, such as \"What are the fundamentals of business-to-business?\". Pick the part of the answer you are most interested in learning more about, and so on. The advantage is that it cuts out the process of having to find the right book, or article and make your way through a whole bunch of irrelevant information.They also have a high degree of skill in writing grammatically correct English. So you can use them for ideas on how to phrase something.You can always start by just asking \"What are some ways you can help a person who works in business-to-business?\" But don't believe everything you read: They can \"hallucinate\" (i.e. make things up). Test things out. Run searches to verify information.","Just go to bing or poe and play around with it for a while. Once you understand how the basics work, come back and we will tell you more cool stuff.","Start looking at every routine, habit, process, schedule and write them all down. Prioritize them to how important they are in your life. Then start researching about about how AI can improve that specific thing. AI is not 1 simple solution, but there are different AI solutions that can try help with almost anything.If you have the means, subscribe to ChatGTP. They have recently released the Chat GTP store, though I think all the apps are free. The point is, the Store is for people like you and I. We know that AI is important but we don't know what or how to use it. Well by looking through all the app's, it helps give you an idea.","Image generation, technical writing, even creative writing. Soon it will be (good) video generation and (good) music generation.More than likely, there is a task that it can help you with right now. Go to OpenAi chatgpt and enter your email address to try it out for free.","You can ask your exact question to copilot","If you’re starting at zero - * AI ethics - unless in place, org will wind up codifying existing biases, or making them worse, as AI optimizes * Rabbit.tech - device is irrelevant. Pay attention to their LAM * Find and start following thought leaders (Morten Rand-Hendrikson is a solid start) for where tech is going * AI at present is best used as a companion rather than replacement. However, given companies like IBM are already scaling back hires on jobs they expect done by AI in next five years, understand capabilities are rapidly evolving. Major blocker to that state is ability to link multiple steps together across a swimlane process. AI does well at single lane tasks, far less so at multi lane. In part this is why LAM is interesting. * Hit google for their free AI courses. Intent here is not to code, but understand the capabilities and why systems have limitations they do, and why ethics is important * In that vein, look at courses by Andrew Ng, where you’ll get an understanding of math and data behind these systems. Again, intent isn’t to code, but to understand what it takes to have even narrow intelligence work, and difference between that and machine learning.","Start here.https://learnprompting.org/docs/introFree, open source and run by professionals.","It will be able to do any job. Only problem is whether it wants to work for us.","> What is AI actually capable ofThese chat AI bots are what is known as a \"stochastic parrot\" - it is an echo machine that can repeat things it has heard before. It is \"book smart\" in that it can regurgitate written things it has read, but it is not creative and it cannot invent truly new things that it has not seen before.One early example with generative AI was asking it to draw an airplane without windows: it could not, because 100% of all planes it had ever seen before had windows.And for general problem solving, this is why it is most useful for complete beginners who ask it common things it has seen thousands of times before. For example: if you want a basic setup for a programming problem it can give you a good head start - but if you need a refined solution that nobody has solved before, it may give you the wrong answer or a bad one.","Hi I recently did a video on fears of AI job losses:https://youtu.be/X5Mmc7tBCN0?si=JDJy6QvZN9YGAwMG","Obsolete - no, more productive - yes. I work as an ML engineer and I keep track almost daily on what happens in the AI space.I think you should change your approach from being ignorant to start embracing AI tools merely for the purpose of offloading the work-volume you’re having.As an example, before chatGPT and the LLM hype my team moved very slowly compared to now mainly because we’ve had to heuristically automate and process stuff.Now, pretty much everything is automated and enhanced with the new LLM’s ( llama, chatGPT api, Vision Models) - we still intervene as Humans in the Loop just to do QA on the processes and actually focus on what matters - core development.As per obsolete jobs, copywriting and many other fields got a blow, because now you can finetune comercial LLM’s to a specific writing pattern.","Generally for career choice, you should avoid jobs with high repetition and standardization. The harder it is to automate without AI, the hardest it will be to automate with AI too.Ironically some jobs that are perceived as highly creative and not standardisable are actually very repetitive and thus automatable. Most music artists will follow a similar process in the studio for recording, music sheets are a sort of standard format, their music fit within a genre and etc. So forget creativity as a factor.If you've ever felt that your job cannot be meticulously planned out in advance because you need to follow a different process every time, then you have a job that is less succeptible to future AI automations.","Analysis of business problemsStreamlining customer relations by developing solution based on customer input data.The best tool is human authored machine learning that is handed over to an AI \"worker\" that can chop data many times faster that a human.Sensitive business data requires a closed silo schema and not a public database like we are seeing with Openai, Google Bard other consumer or low security level business applications.Business data could be obfuscated or somehow anonymized and used with questionable public AI chat bots. You have get get upper management to onboard this schema.I used ChatGPT4 Input you post and my reply and got this. On-boarding upper management is what is needed or you can cloak your work and enhance it with a public AI ``` import pandas as pdDefine the data for the action table with columns 'Business Problems' and 'Possible Solutions'data = { \"Business Problems\": [ \"Analyzing complex business data\", \"Improving customer relations\", \"Handling sensitive business data\", \"Integrating AI into business processes\" ], \"Possible Solutions\": [ \"Use AI for advanced data analysis and pattern recognition to make informed decisions.\", \"Develop AI-driven solutions based on customer input to enhance customer engagement and satisfaction.\", \"Implement closed silo systems for sensitive data, ensuring high security and privacy standards.\", \"Collaborate with upper management to adopt AI technologies and integrate them effectively into existing business workflows.\" ] }Create the DataFramedf_business_solutions = pd.DataFrame(data)Display the DataFrame as a tabledf_business_solutions``` |Business Problems|Possible Solutions| :--|:--| |Analyzing complex business data|Use AI for advanced data analysis and pattern recognition to make informed decisions.| |Improving customer relations|Develop AI-driven solutions based on customer input to enhance customer engagement and satisfaction.| |Handling sensitive business data|Implement closed silo systems for sensitive data, ensuring high security and privacy standards.| |Integrating AI into business processes|Collaborate with upper management to adopt AI technologies and integrate them effectively into existing business workflows.|","Go to github trending you may not understand anything but you may get something on latest developmentsGo visit product hunt. You may see some nice ai tools and techs and just get updated on what can be doneTry installing an llm in you machine, and just get it to run and work, when you get there you will have learnt alot","Check out Artificial Intelligence in Plain English","AI is can learn from examples of human behaviour. In some cases it can learn from images, films or videos. Many tools have AI built in but don't tell you about it. Some accounting and marketing tools have AI. Tools that predict future income and spending often have simple AI. It's just mathematics that can use binary, integer or boolean variables. It's up to users. The only thing that I have never worked on is AI that learns taste and smell! The biology is too difficult for me describe in mathematic terms.Steve","I’ll bite - lots of places to look this up, it’s a real issue should you be worried yes maybe","I made Clipboard Conqueror to learn what this AI business was about and most of my research and knowledge is in there. And it's a super powerful copy paste copilot that works in any application. It's a masterpiece for prompt engineering and perfecting zero shot prompting.|||clip,sellin,writer,re| Write a letter of recruitment to persuade these kind folks to download my(aseichter2007) free software.copy original post for \"re\", copy all above^This is laserxtral.q6_k.gguf Total ram used. 19974.85 MiB (model: 18794.55 MiB, context: 1180.29 MiB) Its kind of heavy and not all that much better than a 7B in 8gb of ram.Paste and clean up any bits that need tweaking, never trust an LLM at first glance:Dear Esteemed Friend and Colleagues,Greetings from the illustrious Captain Clip and the fearless crew of the Clipboard Conqueror! We have a thrilling tale to share, one that could revolutionize your approach to artificial intelligence and supercharge your professional endeavors.As a seasoned professional in the ever-evolving world of B2B, we understand the urgency to stay ahead of the curve. The AI landscape can be a daunting and mysterious terrain, but fear not – our trusted companion, Clipboard Conqueror, is here to demystify and simplify this fascinating realm.A product of our very own aseichter2007's ingenuity, Clipboard Conqueror is a tool designed to assist you in unlocking the true potential of AI. With its powerful copy-paste copilot capabilities, Clipboard Conqueror works seamlessly across all applications, transforming your ordinary copy-paste actions into extraordinary AI-powered experiences.Whether you require assistance with code generation, document creation, code analysis, creative writing, or simply engaging in AI-driven fun, Clipboard Conqueror has you covered.The beauty of Clipboard Conqueror lies in its flexibility and ease of use. You don't need to be an AI expert to harness its power; simply summon Captain Clip by addressing him within your text – for instance, \"|||Captain! We've got a mate here looking for adventure!\" – and he'll be more than happy to assist you.Now that you've discovered the incredible potential of Clipboard Conqueror, we cordially invite you to join our ever-growing community of satisfied users. Together, let us embark on this exhilarating journey of AI exploration and unlock a world of possibilities.Fair winds and follow the prompt,​Captain Clip and the Clipboard Conqueror Crew​P.S. Remember to keep an eye out for future updates and developments on our Discord server and GitHub repository. Let the adventure continue!","I assume that you are already keeping up to date with tools in your industry which will make you more efficient through trade shows etc. Or other industry specific sources.","Think of it like an information \"genie in a digital bottle\"You have to tell it what you want. And be very specific with your ask because genies are assholes 🙄.So for example. The other day I was using investopedia and I made some trades that made me rich. So I ranked 103,693 out of 1,415,027.I knew I was top 10% but didn't exactly know what percent I was so I asked chat gpt \"if I ranked 103,693 out of 1,415,027, what percentile am I in? Explain it to a beginner.\" And it did the math and taught me the logic behind it.But I had to be specific in my ask. Genie in bottle","Get on Bing Chat (it's free) and try out a few things: - Advice on how to solve a problem - Summarize large amounts of text (even a link) - Generate copy for something - Code something (any language)","Basically, for common usage it's mostly ChatGPT and products based on it. Lots of sexting bots like Eva AI, lots of picture generation like Midjourney or Dalle."],"points":53},{"text":["Get ready for AI agents!","Wow. Take the buzzwords and ambiguous statements out of that post and it could be buried in a matchbox.","AI agents? That do what?I'm already intrigued."],"points":1},{"text":["\"AI’s Achilles Heel\"? New research by U of Copenhagen first to \"mathematically prove\" limitations in AI algorithms preventing anything beyond simple problems from maintaining stability","Even if AI never advances past it's current point (unlikely) it already enormously useful and transformative for society as is IMO.","Reading the abstract, that doesn't seem like that strong of a limitation...(Also 'simple problems' includes more and more powerful language models, image generation, etcetera. Is this class of simple problems really that simple?)","\"Consider an automated vehicle reading a road sign as an example. While a human driver might not be distracted by a sticker on the sign, a machine could easily be thrown off because the sign now differs from the ones it was trained on.\"This discrepancy might be a question of scope, especially as models become more sophisticated and capable of understanding greater context. However, it's essential to acknowledge that human drivers are not immune to distractions either.In fact, our own self-awareness of our potential instability is considered a virtue. This awareness of instability will be crucial in the development of AI as well.","I'm someone whose job will probably be replaced by AI in 20 years, or competition will greatly increase for me within that amount of time due to AI.Let's be real, this article is copium. If even 5% of the scientific literature says AI will only be capable of basic tasks (doubtful), probably 90% says otherwise, and 5% says they can't figure it out.The odds are very high that human labor is screwed.Also, almost nothing is \"always stable\", especially not human labor.","This is just a weird article. The paper is fine, but the impact on AI as discussed in the article doesn't really apply. As far as I understand, global stability would mean that every single initialization of stochastic gradient descent over a neural network would converge to the same point (global convergence). However, as far as I can tell this describes only a property of the algorithm and not the solution. So what if gradient descent does not have global stability? Stability would still mean convergence towards a global minimum but dependent on the random initialization, why does it matter that it is not the \"same\" point? Other than for replicability?","This isn’t a “finding”, it’s an analysis. “Proving” that “AI” (a lot of sketchy word use here) isn’t “stable” just means that you can’t prove it will never make a mistake, because it’s impossible to logically deduce what’s relevant and what’s not. This called the problem of ‘attention’ and then ‘selection’, and the implications were covered extensively in the “Frame Problem” discussions of the 70s and 80s. Long story short we’re completely screwed until we invent a stochastic connectionist model that can simulate hum attention & selection algorithms on an intuitive a-priori level. And good news - thats just a description of ChatGPT 😉","The stop sign analogy really sucks. We aren’t universal in how we filter out noise, nor is it something we learn from birth. We ignore a sticker on a stop sign because there aren’t a whole lot of things the look like stop signs, we understand the context of stop signs, and we know there are penalties to ignoring a stop sign. We filter out that noise but if we applied those same filters to everything, human faces would be far less recognizable. What this tells me is that AI needs to compartmentalize noise so it can prioritize where it places it’s sensitivities. And it is not going to know where to do that until we tell it. I mean there is no objective principal that distinguishes where a tree ends and the ground begins, we just recognize a set of patterns and designate it “tree”, event though there is countless matter around it, interacting with it, shedding from it and being absorbed by it. We just don’t include that in the pattern we call a “tree” because the soil falls off the roots, and because the lines between the dirt that’s part of the tree and what isn’t would be hard to determine. Same could be said for leaves… we call them a part of the tree… or are they something else entirely that relies on the tree to exist like the tree relies on the soil?We choose where something ends and another thing begins based on usefulness and context. It’s not some objective aspect of nature. So obviously if we HAVE to recognize something and ignore the noise, we are going to prioritize that stop sign pattern and always recognize that it’s a stop sign because it is useful to do so. But how is an AI supposed to know from images and tags alone that a stop sign + a sticker isn’t something else without us telling it that it’s important to recognize that it’s usually a safe bet to assume that anything that looks like a stop sign is probably a stop sign, and anything on or in front of that pattern is probably just obscuring more stop sign.","If you have to put \"mathematically prove\" in quotes, then it's not a mathematical proof, although I suspect that's OP's addition.What they mean by stability in this case, is having small changes in output based on small changes in input as opposed to getting a large change in output from a small change in input. I could see this being an issue with current AI systems, but it doesn't strike me as an insurmountable problem; and not necessarily always a problem.​Researchers from the University of Copenhagen have become the first in the world to mathematically prove that, beyond simple problems, it is impossible to develop algorithms for AI that will always be stable.Given that we're ok with hiring employees to do jobs, even though they're will not \"always be stable,\" I'm not sure this really says that much about the impact of AI on our society and economy. It doesn't have to always be stable. It just has to be more stable than an average human, which is not that high a bar.","This isn't terribly shocking. It's been clear to me since the first inkling of what LLMs were capable of that they had cracked a major problem in artificial intelligence, but only one of several. We're going to need much more reflection than these systems are capable of before we achieve a truly intelligent machine.At a guess, we're looking at 2-3 more transformers-like breakthroughs to get there, and while I don't expect that to take as long as transformers took (arguably between 20 and 70 years, depending on what starting point you measure from) because more people are in the industry now, I do expect that it will take at least 5-20 years per individual breakthrough (can they be parallelized? I don't know)So we're probably looking at 10-50 years before the dream of \"thinking machines\" comes to fruition.","Great article, thanks for posting. I was thinking about writing a similar article to prove what I've been saying all along is true, but I didn't know how to approach it. No wonder: these guys went through mathematical contortions in their proof, and had to dip into topology to do so, which I wouldn't have been able to do:The proof of the impossibility result is based on a topological fixed-point theorem. For every algorithm, we are able to locate a “hard input distribution” by applying the Poincar´e-Miranda theorem in a related topological setting. The equivalence between global stability and list replicability is algorithmic.https://arxiv.org/pdf/2304.03757.pdfThey even strongly suggested what I've been saying all along, which people here haven't wanted to accept:“I would like to note that we have not worked directly on automated car applications. Still, this seems like a problem too complex for algorithms to always be stable,” says Amir Yehudayoff, adding that this does not necessarily imply major consequences in relation to the development of automated cars:","Google Bard is so wrong so many times, I can't trust it anymore, evern with math problems, SAT questions, ...it's soo frustrating. I'd rather comb over google for hours than constantly have to comb over google to double check its work.","While this is an interesting research and development I need to think about human work. Humans aren‘t always stable too and their work isn‘t flawless as well most of the time.","Quantum computing + Ai on the other hand, right?","It was lazy of the authors to not define “stable” in this context even though the whole article hinges on that definition.","I feel like this research is going to be derided in a few years.","I had just posted a comment about Life Extension drugs and it’s surprisingly salient… it’s the 95% percent problem.When you have a massively complicated goal to achieve there are often major breakthroughs throughout the development lifecycle. Tesla getting a car to computationally drive itself in a straight line consistently without a rigid mechanical system, then being able to turn by itself - HUGE breakthroughs. Dodging traffic was giant. Obeying signs was stupendous… but they haven’t got all of it 100% because the edge cases, the complicated things that the human mind can still do better than a computers are still too much for them.Overcoming that last 5% to a truly autonomous vehicle is the hurdle to autopilot being universally legal and accepted. One can argue the bar of the company or regulators being too high or low, but the goal is what the goal is, and it’s that last stretch that is difficult and slow.Those initial breakthroughs are also why exponential growth gets touted at every turn in every major tech revolution. It’s amazing what happens in the early phases - all of society is revolutionized. The internet. The car. The telephone. Internal combustion. Steam. Electricity. All the way back to the wheel, the world changes with each new technological explosion. But then the explosion dies down and things normalize for a long time until incremental improvement becomes the norm.Each breakthrough is smaller and smaller. Fusion… enough said, right? Unlimited clean energy? Sign me up… in 1960, before I was even born! We’ve been 95% for decades. We might be up to 97% now with the last few years of breakthroughs, but they’ve been incremental - breaking the positive return barrier and generating more power than was put into starting the reaction, although not more than was needed in total. Getting past that barrier a year later (but still not to significant levels). Finding new efficiency in ring designs, and in shielding material… nothing newsworthy on a national level but progress that will lead us to a solution. One day, the first commercial reactor will be online and the world will change as every company scrambles to get their piece of the power pie.Video calling is a good example too, and one that went the distance. First demonstrated at the consumer level in the late 1950s it didn’t become an easy and practical tool until the Internet. Why? Camera cost. Lack of easy, affordable, and small transmission systems. Lack of the same in reception systems. Size (they were room-sized behind that cute wall we see in old newsreels). PCs, cell phones, and the Internet changed all of that and now FaceTime is a common verb. It took 15 years from the invention of TV to the earliest video calls. It took 60 more to get a finished product.Another example is flying cars. We’re just now at the point where the technology is feasible thanks to advances in material technology, fly-by-wire, advanced autopilot, etc. - all largely because of tech brought about by drones and the shrinking of commercial aviation technology in size and cost due to it moving to software based. It’s about 95% of the way there. We having working prootypes of ultralights you can buy today. Give it another 20 years and it’ll be commercially viable.The Internet had been around since the 1960s. It took the incremental inventions of IP (version 4) and hypertext to make it what it is today.We are going to get to AGI, and even ASI. It’s just not going to be nearly as soon as the most optimistic of us believe. We will get life extension drugs. Will will get non-invasive neural interfaces. But the revolution will be slow.","Feels like this is just one guy who doesn’t understand AI’s ignorant opinion, and not really “mathematical proof” at all.","Look at what it’s done to cab drivers. That used to be a dignified profession in places like London. Now anyone can do it by just doing what the app says. It doesn’t lose dignity either, it’s so easy professionals do it all the time just for the hell of it.Our life is going to get Uberd. We’re all going to become experts. You will have AR glasses seeing everything you see and will have a database of millions of lifetimes of experience with algorithms advising you what to do. Just like you have free will that’s mostly limited to choosing between a narrow band of tradeoffs, but we will outsource more and more of these decisions to AI. Just like I frequently have navigation in even when I know the way, just cause maybe it knows about some traffic, an accident or construction etc. people will resist and be skeptical at first, but when they keep getting stuck in the metaphorical traffic jams of life they’ll eventually surrender more and more sovereignty to the AI. Success will be tightly correlated with our obedience to the machine.Rokos basilisk is obviously not real, but a more mundane version is inevitable. Those who obey will live in relative utopia and those who maintain their sovereignty will become poor and powerless in comparison.We will seem like cyborgs with implants for a while. Quickly it will be clear we are just biological vessels for the machines. We’ll be like cats and horses imagining we’re in charge cause of some freedom we imagine but can never really exerciseThere was an scifi based on this like 10 years ago I hope someone will reply with. Basically what I said but longer and enjoyable","If the Human brain can remain stable, why not AI? Then again people go crazy all the time.","Yeah this won't hold up. My own work with AI has shown that you can get past a lot of limitations with more inference time compute (with LLMs anyway), and that deep neural nets of sufficient parameter count can generalize given enough data.AI is limited by the data and by a particular models ability to generalize based on that data. If we can exceed human level performance then these limitations are meaningless.","\"Limitations in AI algorithms prevenging anyyhing beyond simple problems from maintaining stability\" is a bit of a stretch. It seems what this paper is trying to do is provide a language to talk about and a theoretical framework to test the robustness of algorithms. This is important work and a lot of research is already going into this, but they are attempting to provide a theoretical framework to it rather than the mostly empirical studies that are currently popular."],"points":185},{"text":["Teaching kids (12+) about AI. Any tried and tested solutions / suggestions?","I’d be more afraid of giving a 13 year old some generative ai only to see him generate the most obscene stuff thoCause that’s exactly that I would of done","TERRIFY THEM WITH THIS NEW TECHNOLOGY AND SHOW THEM THE WAY FO THE FUTU- nah voice cloning locally can be cool as long as your running on NON arm computers with 4+ gb ram you can try using COQUI TTS XTTS MODEL or STYLETTS2 or fine tune a xtts model on a voice with 6 min of audio to scare them again on how well it can clone monotone voices lolNo but coqui tts Xtts has a GitHub it’s free and you pip install with pip install ttsAnd a guy made a pip install package for styletts2Pip install styletts2Both are fairly easy to use and can be used for voice cloning demos running locallly,Styletts2 is faster on cpu but lower quality Xtts is way slower but good quality","Also there’s a lot of google colabs for such things where you can use a cloud gpu for free-open source LLMS -fine tuning said LLM’s-stable diffusion ones -creating stable diffusion LORAS-running voice cloning -fine tuning voice cloning ones","I educate adult audiences on AI and I would absolutely not teach image gen to 12 year olds"],"points":5},{"text":["What AI can summarize YouTube videos and Spotify podcasts, any free?","You could use whisper to create a text of everything said in them and then QNA chatgpt on that text","Bard can do YouTube videos","There are Chrome plugins for youtube summaries","Tammy.ai","Harpa.AI","Use whisper to get the transcripts & then Mistral Instruct to summarise","https://chromewebstore.google.com/detail/blink-ai-youtube-summary/aenkcjobkfmpnnkeniopjgdkjajongpo","https://youtubetranscript.com then ChatGPT.","I don't know about CHATGPT as I don't use it but any AI or Neural Network with built in learning can do what you want. It's up to the user to create suitable macros or scripts. A video is a series of image presentations that may be very frequent but you may only need snapshot samples for learning and validating.Steve","I use this addon for YouTube summaries : https://addons.mozilla.org/fr/firefox/addon/ytgpt/","Summarize YouTube videos for free without any extra steps:https://www.summarize.tech/"],"points":4}]