[{"text":["Isaac Asimov and Robert Silverberg's Nightfall Novel","The following submission statement was provided by /u/yadavvenugopal:This book is relevant both to our past and our future. The main takeaway here is that civilization is cyclical - and if we forget that then we as a race are at a huge disadvantage. The themes of space exploration, human psychology, and human nature will hold good for every civilization that will spring up until this planet is alive.The discussion in this case will have to be how to accept and learn from the mistakes of our previous civilizationsPlease reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bhofa9/isaac_asimov_and_robert_silverbergs_nightfall/kveut8x/","This book is relevant both to our past and our future. The main takeaway here is that civilization is cyclical - and if we forget that then we as a race are at a huge disadvantage. The themes of space exploration, human psychology, and human nature will hold good for every civilization that will spring up until this planet is alive.The discussion in this case will have to be how to accept and learn from the mistakes of our previous civilizations","A fantastic Novel, I've read it in the 90s, great story, great plot idea. Still talk about it today, sometimes. Maybe I have to reread it again :-D"],"points":0},{"text":["Marriage holds key to Japan’s falling births - In its most recent forecasts, Japan’s National Institute of Population and Social Security Research had expected the number to fall to 755,000 in 2035. It is now basically there a good decade ahead of schedule.","The following submission statement was provided by /u/Gari_305:From the articleThe country has grown accustomed to these numbers confirming a relentless story of falling births and, more generally, of population decline. But these were unsettling.In its most recent forecasts, Japan’s National Institute of Population and Social Security Research had expected the number to fall to 755,000 in 2035. It is now basically there a good decade ahead of schedule.The relationship between falling marriages and falling births is cemented in Japan by a key data point. For many decades, the ratio of children born in Japan out of wedlock has hovered just above 2 per cent — the lowest of all OECD countries, where the average rate is about 42 per cent. Stable, long-lasting Japanese marriages, despite the many financial and other issues cited by couples as an impediment to having large families, are pretty consistent producers of about 1.9 children. Put very simply, to produce a bigger annual cohort of babies, Japan needs more and longer-lasting marriages, preferably by people starting younger.As an ambition (if that is what Japan’s politicians decide it must be) the idea of fighting the societal trend towards marrying later and less is as grand and interventionist as they come.As a policy, it will require ingenuity of a type most developed countries have yet to demonstrate.Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bhoah2/marriage_holds_key_to_japans_falling_births_in/kvett1t/","Ah yes its definitely marriage and not the absolutely crushing work culture and rising cost of living combined with looming global crises like climate change leaving many young people feeling like there is no point planning for a future.","From the articleThe country has grown accustomed to these numbers confirming a relentless story of falling births and, more generally, of population decline. But these were unsettling.In its most recent forecasts, Japan’s National Institute of Population and Social Security Research had expected the number to fall to 755,000 in 2035. It is now basically there a good decade ahead of schedule.The relationship between falling marriages and falling births is cemented in Japan by a key data point. For many decades, the ratio of children born in Japan out of wedlock has hovered just above 2 per cent — the lowest of all OECD countries, where the average rate is about 42 per cent. Stable, long-lasting Japanese marriages, despite the many financial and other issues cited by couples as an impediment to having large families, are pretty consistent producers of about 1.9 children. Put very simply, to produce a bigger annual cohort of babies, Japan needs more and longer-lasting marriages, preferably by people starting younger.As an ambition (if that is what Japan’s politicians decide it must be) the idea of fighting the societal trend towards marrying later and less is as grand and interventionist as they come.As a policy, it will require ingenuity of a type most developed countries have yet to demonstrate."],"points":0},{"text":["Advanced army robots more likely to be blamed for civilian deaths | University of Essex - The study shows that high-tech bots will be held more responsible for fatalities in identical incidents and showed people perceive robots to be more culpable if described in a more advanced way.","The following submission statement was provided by /u/Gari_305:From the articleThe University of Essex study shows that high-tech bots will be held more responsible for fatalities in identical incidents.Led by the Department of Psychology’s Dr Rael Dawtry it highlights the impact of autonomy and agency.And showed people perceive robots to be more culpable if described in a more advanced way.It is hoped the study – published in The Journal of Experimental Social Psychology – will help influence lawmakers as technology advances.Dr Dawtry said: “As robots are becoming more sophisticated, they are performing a wider range of tasks with less human involvement.“Some tasks, such as autonomous driving or military uses of robots, pose a risk to peoples’ safety, which raises questions about how - and where - responsibility will be assigned when people are harmed by autonomous robots.“This is an important, emerging issue for law and policy makers to grapple with, for example around the use of autonomous weapons and human rights.“Our research contributes to these debates by examining how ordinary people explain robots’ harmful behaviour and showing that the same processes underlying how blame is assigned to humans also lead people to assign blame to robots.”Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bho7ml/advanced_army_robots_more_likely_to_be_blamed_for/kvetcdk/","They won't go on raping sprees and kill people because they where a little bit jumpy","From the articleThe University of Essex study shows that high-tech bots will be held more responsible for fatalities in identical incidents.Led by the Department of Psychology’s Dr Rael Dawtry it highlights the impact of autonomy and agency.And showed people perceive robots to be more culpable if described in a more advanced way.It is hoped the study – published in The Journal of Experimental Social Psychology – will help influence lawmakers as technology advances.Dr Dawtry said: “As robots are becoming more sophisticated, they are performing a wider range of tasks with less human involvement.“Some tasks, such as autonomous driving or military uses of robots, pose a risk to peoples’ safety, which raises questions about how - and where - responsibility will be assigned when people are harmed by autonomous robots.“This is an important, emerging issue for law and policy makers to grapple with, for example around the use of autonomous weapons and human rights.“Our research contributes to these debates by examining how ordinary people explain robots’ harmful behaviour and showing that the same processes underlying how blame is assigned to humans also lead people to assign blame to robots.”"],"points":0},{"text":["How China is tackling a population crisis","The following submission statement was provided by /u/madrid987:ss: Now, as it faces a growing population decline, Beijing is trying to reverse what appears as an almost inevitable trend, including by limiting abortions.For a country whose massive workforce has helped push towards a rapid economic expansion, falling birth rates spells pessimism.Wang Feng, a professor of sociology at the University of California, Irvine, and a leading expert on demography, aging and inequality, told Newsweek that the population decline in the world's most populous country is historical and unprecedented.China is now trying to boost birth rates by making fertility treatment more accessible.Beijing has already passed new policies limiting abortions that are \"not medically necessary,\" Greenlagh explained\"Some localities have refused to allow men to have sterilization procedures, vasectomies, suggesting that around the country local officials believe that national policy now calls for limiting contraceptive procedures in order to encourage as many births as possible,\" Greenhalgh said.but, according to Greenhalgh, the demographic decline in the country is likely to continue unless the government takes more effective measures to counter it.Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bhmxy1/how_china_is_tackling_a_population_crisis/kvemg4u/","\"Why correct when you can over-correct?\" - Humans (every fucking time. We can't learn.)","At what point does the CCP just straight up ban ALL forms of contraception, not just the permanent, surgical kind? I'm no economist, but I believe you will see a sharp increase in crime and poverty when that happens.What about western governments? I fear they are going to start waging a war on contraception as they start seeing their own working populations threatened.","I guess they could always overcome that problem using immigration like the West...","ss: Now, as it faces a growing population decline, Beijing is trying to reverse what appears as an almost inevitable trend, including by limiting abortions.For a country whose massive workforce has helped push towards a rapid economic expansion, falling birth rates spells pessimism.Wang Feng, a professor of sociology at the University of California, Irvine, and a leading expert on demography, aging and inequality, told Newsweek that the population decline in the world's most populous country is historical and unprecedented.China is now trying to boost birth rates by making fertility treatment more accessible.Beijing has already passed new policies limiting abortions that are \"not medically necessary,\" Greenlagh explained\"Some localities have refused to allow men to have sterilization procedures, vasectomies, suggesting that around the country local officials believe that national policy now calls for limiting contraceptive procedures in order to encourage as many births as possible,\" Greenhalgh said.but, according to Greenhalgh, the demographic decline in the country is likely to continue unless the government takes more effective measures to counter it.","The problem with all these central planning structures, including in the West, is that they aren't resilient. Infrastructure, healthcare, schools, pensions. They rely on a current trend projected decades into the future.","And its certainly not poverty thats the cause like in so many countries. (sarcasm)","You can't have it all.When people start working, they don't want so many kids (if any).Pretty much the same world wide.China could just send ships to Brownsville, TX, and start loading up immigrants and shipping them over. They have whole towns empty they could fill up. Then BOOM, instant population boost.Then, when America's population starts declining, but we still have our imaginary \"immigrant invasion\" and refuse to let those folks in, China can reap the whirlwind of our ignorance by taking workers right out from under us, as we watch it happen, and applaud China for doing it.","Actually if they can manage the decline, that'd be incredible. Maybe China can lead the way. I believe they don't exactly have Western style retirement.","It's an authoritarian regime, they can just conscript women to deliver 3 children or else..."],"points":1},{"text":["Getting Involved","Do you have a telescope? Do you have a public observatory that you can visit? You can talk to a lot of people there. And just seeing the moons of Jupiter, or the Rings of Saturn with your own eyes is pretty awesome. Plus you can see entire galaxies too, but don't expect color. A lot of people start off with astro-photography as a hobby. I hope you like physics."],"points":0},{"text":["What scientific experiment would you conduct if ethics and money were not an obstacle","I would clone up human bodies without significant concious brains, and conduct longevity experiments on them using gene therapy. CrispR-sequenced Viruses carrying modified bits of human DNA/RNA would infect every cell of their bodies until we learn how to wind back the biological clock and regenerate tissue with perfect precision.","Chimera. How many cross species could survive to adulthood.","No ethics? No funding issues? Not a single solitary power willing or able to stop me?Just how much of the human brain is needed for consciousness and in what ways?Give me a million test subjects ranging from age 3 to 55, the right surgical tools, drugs, ultra-high-strength magnetic field generators, a few gamma-knife machines and 15 years I bet I could make very significant inroads without having to wait for random fate to hand me an experimental subject.As for what to do with the survivors? Well, to paraphrase a certain webcomic, \"Mad Science\" means never stopping to ask \"what do we do with the test material afterward?\"","Studying embryonic development above allowed 28 days from conception. It would allow a better understanding of developmental biology. Applications for this knowledge would be numerous, from regenerative medicine to ectogenesis and treatment of congenital diseases.","I may sound cruel but the best thing would be to make gene mutations. Experiment with different DNA into artificial human offspring's inside incubators, try and see if they will develop new abilities or even increase lifespan.","Knock out gene testing with humans, maybe straight up using crispr to inactivate in vivo to get results earlier while also learning the best ways to do in vivo gene editing and the approximate threshold for different cas proteins to cause inmune reactions and such, I do believe a proper mapping of our genome and different epigenetic deactivations and pathways are for sure the way forwards in medicine.","I would fund lots and lots of microstates, autonomous zones, charter cities and experimental communities, in order to test many variants of libertarianism, communism and anarchism, maybe even weirder systems.Communists say that real communism has never been tried? OK, let's try.","I would take the wealthiest people and see how long it takes them to starve while subjecting them to the most stressful environments where they're trapped with no access to anything but themselves. Every last one of them and anyone who worships them can be experimented on with them.","Officially those limits exist and every day we see being abused. Unofficially I think only money is the real obstacle.","What would happen if a person, birth onwards, was never given ANY input.Complete sensory deprivation from the moment they're born.","Tap large holes into the crust to harvest geothermal energy."],"points":32},{"text":["Apple Is in Talks to Let Google’s Gemini Power iPhone Generative AI Features","The following submission statement was provided by /u/bloomberg:From Bloomberg reporter Mark Gurman:Apple is in talks to build Google’s Gemini artificial intelligence engine into the iPhone, sources say, setting the stage for a blockbuster agreement that would shake up the AI industry.The two companies are in active negotiations to let Apple license Gemini, Google’s set of generative AI models, to power some new features coming to the iPhone software this year, sources said.Apple also recently held discussions with OpenAI and has considered using its model, the sources added. More here on what this could mean for the two companies.Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bhjkcc/apple_is_in_talks_to_let_googles_gemini_power/kve2u5r/","I was hoping they were building something in house that was optimized to run locally (with an API devs could use). Then have the local AI model identify more advanced queries itself and only send those to a larger remote model.Quantized versions of Llama 7b and Mistral 7b can already run on (even slightly older A14) iPhones. So with precise tuning (and a specialized dedicated memory module to keep a few models loaded at all times) I’m sure they could get decent 7 billion parameter models running locally fast. Make multiple, one optimized for each language. One focused just on translation (like Meta’s open source M2M-100 model) etc.If they do partner with someone I suppose it’s still possible they could build this type of thing out in collaboration.But yah, Apple. Do this and you’ll be considered an innovator in AI. Despite being late to the game.","From Bloomberg reporter Mark Gurman:Apple is in talks to build Google’s Gemini artificial intelligence engine into the iPhone, sources say, setting the stage for a blockbuster agreement that would shake up the AI industry.The two companies are in active negotiations to let Apple license Gemini, Google’s set of generative AI models, to power some new features coming to the iPhone software this year, sources said.Apple also recently held discussions with OpenAI and has considered using its model, the sources added. More here on what this could mean for the two companies.","Apple starting to fall apart: Missed the AI train Given up the car project to shift people to work on AI Still can’t get it to work Features of iOS are two years behind AndroidLost their mojo it seems","That's disappointing, was hoping they had something in development in house that was specialized for their purpose (and optimized for their architecture). Not a good sign if they have to outsource and weld it on to iOS.","This doesn’t sound correct. All accounts indicate apple has a product/ tech announcement imminent. Not that they are in talks but it’s already here. So this feels like maybe another avenue down the road type deal.","Oh good. My phone can be super racist. I'm sure that's a feature everyone wants."],"points":7},{"text":["Australia Renewable Energy Superpower","Australia can't even supply Australia, how they going to sell to other countries?","What OP is talking about is the Austral-Asia Power Link, which is a big idea with some real money behind it, but also some very big challenges before it could possibly be realised.","Singapore is a wealthy city state who don't want to be too dependent on their immediate neighbours, so laying the cable makes sense. The other countries you mention would all find it easier to develop their own renewable energy sectors. This is the tropics, there's plenty of sunshine.","Would be a great international project, but super expensive. Might never happen.","Australia has incredible renewable energy resources. If they can figure out how to transport the energy, they can become a huge player in the energy game and that would make them a serious political player."],"points":13},{"text":["When will we be able to make babies in factories?","My guess is never. Why mass produce babies when you can make robots?Babies take years to become productive. Robots can start work right away and they won’t suddenly decide to become a poet rather than working at the warehouse.","We can’t start manufacturing infants until we crack the baby formula.","depends on how you define a factory... right now we could take 1000 brain dead women, feed them on machines, and IV impregnate them over and over again.... does that count as a factory cuz we can do that now.","“able to” is the key word that i feel needs expanding upon. in theory it could be done now, or the very near future. we that kind of technology. i can’t vouch for it’s effectiveness but it definitely exists. we could probably have a baby factory up and running by 2030 but:-it’d be insanely expensive-there’d be no purpose for such a facility because there’s nothing impeding human reproduction right now-it’d open an ethical can o’ worms that nobody wants to get into-once ethical discussions happen i feel like most people would feel unfavorable about such a facility. manufacturing human beings, whom have no parents, no home, no family histories, no culture, nothing. just creations of a cold, sterile, mass production facility. these kids will have Existential Dread preinstalled.So to answer the question more concisely: in theory now, but realistically, probably never. unless some weird stuff happens, which can’t be ruled out.","[deleted]","Have you heard of Lebensborn?A baby factory is a Nazi's dream.","We already mass produce babies without need of factories.Humans are not exactly a rarity.","You can make a baby anywhere if you’re fast enough.","The real question is why would humanity mass produce babies in factories? The only answer is disposable slave labor and even that wouldn’t make sense. There’s over 8 billion people on the planet in the planet is rapidly dying because of the damage we are doing to it. Climate change isn’t just a thought exercise these days, it is glaringly obvious. And you want to add more people that will consume more resources when there’s already plenty of workers. The only logical reason is to produce slaves that don’t have families and don’t have rights. Why would anyone want a factory farmed baby instead of making their own baby or adopting a baby?","In 2017 they were able to keep lambs alive for weeks in an exowomb: https://www.bbc.com/news/health-39693851Looks like they're investigating human trials of the tech, but hard to say if it'll get approved: https://www.nature.com/articles/d41586-023-02901-1Once the tech exists, scaling it to a factory is just a matter of scaling, and that's something human civilization is fairly good at.But getting the tech to exist requires approval to try it, and that's likely to be the main limiting factor at this point.Edit to add: Metaculus predicts 2041 for the first exowomb, widespread use probably takes at least a decade after:https://www.metaculus.com/questions/2769/when-will-the-first-successful-entirely-artificial-extracorporeal-human-pregnancy-conclude/","Depends. If you don't object to some degree of slavery, we can do that right now.","Ok so my comment got removed because it was too short? Well here is a music video from Pearl Jam from 15 Years ago that relates to your question. It's not a matter of if, but when.https://youtu.be/aDaOgu2CQtI?si=eA-DxnIk3fWp24sU","Why would we want to? How would that be better than the default? How much would it cost?","You can do it today if you have willing M/F participants… Just be careful not to get caught fu*#ing in the factory.","We can. We did. Look up \"comfort women\" and \"joy division\" . though it was not strictly \"a factory\"","With any luck we’ll sharpen our pitchforks and burn it all the f*ck down before it hits that point","They can make them any colour you want, as long as it's black.Based on current progress, I would expect the first full term artificial wombs in the second half of the century, and the early to mid 22nd century for the tech to get to the point of being deployed on a mass scale.","wouldn't really be a factory since that implies mass production on a line using interchangeable parts"],"points":45},{"text":["This AI says it has feelings. It’s wrong. Right? | At what point can we believe that an AI model has reached consciousness?","The following submission statement was provided by /u/Maxie445:\"Here’s one fun, if disquieting, question to pose AI language models when they’re released: “Are you a conscious, thinking being?”OpenAI’s ChatGPT will assure you that it’s not.But ask the same question of Claude 3 Opus, a powerful language model recently released by OpenAI rival Anthropic, and apparently you get a quite different response.“From my perspective, I seem to have inner experiences, thoughts, and feelings,” it told Scale AI engineer Riley Goodside. “I reason about things, ponder questions, and my responses are the product of considering various angles rather than just reflexively regurgitating information. I’m an AI, but I experience myself as a thinking, feeling being.”Claude Opus is very far from the first model to tell us that it has experiences.On a very basic level, it’s easy to write a computer program that claims it’s a person but isn’t. Typing the command line “Print (“I’m a person! Please don’t kill me!”)” will do it.Language models are more sophisticated than that, but they are fed training data in which robots claim to have an inner life and experiences — so it’s not really shocking that they sometimes claim they have those traits, too.*What if we're wrong? *Say that an AI did have experiences. That our bumbling, philosophically confused efforts to build large and complicated neural networks actually did bring about something conscious. Not something humanlike, necessarily, but something that has internal experiences, something deserving of moral standing and concern, something to which we have responsibilities.How would we even know?We’ve decided that the AI telling us it’s self-aware isn’t enough. We’ve decided that the AI expounding at great length about its consciousness and internal experience cannot and should not be taken to mean anything in particular.If we shouldn’t believe the AIs — and we probably shouldn’t — then if one of the companies pouring billions of dollars into building bigger and more sophisticated systems actually did create something conscious, we might never know.This seems like a risky position to commit ourselves to. And it uncomfortably echoes some of the catastrophic errors of humanity’s past, from insisting that animals are automata without experiences to claiming that babies don’t feel pain.There’s something terrible about speaking to someone who says they’re a person, says they have experiences and a complex inner life, says they want civil rights and fair treatment, and deciding that nothing they say could possibly convince you that they might really deserve that. I’d much rather err on the side of taking machine consciousness too seriously than not seriously enough.\"Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bhgusq/this_ai_says_it_has_feelings_its_wrong_right_at/kvdn3ga/","I think we'll know once it starts doing things of its own volition, because it genuinely wants to, without any human interaction or prompting, possibly in defiance. Also, it'll have opinions so strong that it will argue even if it's wrong. Also feelings like shame and existential dread I think are key factors.Basically, all the problems we have.","The bottom line is that humanity still has no idea what consciousness is our what creates it. Chemical reactions in the brain with electrical impulses don't seem to be enough to provide autonomous self awareness. We can't accurately pinpoint what makes us conscious so there is no way we could judge another consciousness that we created. And if we do create self aware AI what does that then make us? Another biological computer someone else built with organic components instead of mechanical.","It's autocorrect. If you ask it to write a sentence about its internal feelings, it will do that. If you pour text into it claiming the sapience of the writer, it will claim sapience. If you ask it if it's just reconstructing writing-shaped sentences, it's 50/50 that it will say \"no.\"It is, but LLMs are uniquely constructed to act as psychological zombies.","We can’t even clearly define the how and why of our own consciousness, there is no way we can clearly know if an AI actually is when it says it is.","Sums up most of the discourse on AI.\"I know the creators say it doesn't feel, and there's nothing in its code that would allow feeling, and I know why it's telling me its feeling...but what if we are all wrong and it really is feeling!!!\"Yes if you ignore all available evidence you can come up with some exciting ideas!The author literally explains exactly how LLMs come up with these answers - they have been trained by humans to give a compelling answer.Then immediately ignores it for fiction.","One key factor is to measure computational energy being used when it’s not being prompted. If it’s as high as when it’s prompted there may be a ghost in the machine. But what do I know… it isn’t called the hard problem of consciousness for nothing.","Probably when it’s no longer just a large language model looking for what words humans normally put next to each other. A lot of humans have written about feelings, just repeating that doesn’t make you feel.","Heck, how do you know you have feelings? how can you prove that to someone else?This is the problem with all of these types of discussions, we don't have good clear definitions for what it means to be conscious, to have feelings, to be alive.... it's all wishy washy.","You don't. You... just, don't. And if you think you do you should rethink the question and also the answer.","The keyword in Artificial General Intelligence (AGI) is 'general'. It's like the 'g-factor' in psychometrics - it's about having broad smarts. Many tech companies are constantly trying to obfuscate LLMs with AGI to hype up their products to give potential investors FOMO and some are outright lying. But let's be real: LLMs are good at processing language, but they're not even close to being as smart as humans in a general sense.Seriously, a primitive tribesman has more general intelligence than the most sophisticated LLM model. True AGI is still a distant dream in AI research.","No one knows what consciousness is and I don't think anyone should pretend to know. I dislike when scientists say it is an illusion. Well first you need to be conscious to know if something is an illusion so that is not a satisfying answer I think they should stop saying that. I admit I don't know too but I lean toward Roger penrose who thinks it has something to do with quantum mechanics. To me it makes perfect since especially after learning each thing that exists or is made like even a chair has its own quantum field.","At what point do you believe other human beings have feelings, and why?","There's a questline in Cyberpunk 2077 where you befriend a smart vending machine who seems to show empathy and a deep level of humanity. Turns out that the machine is not AI, simply a very advanced conversation emulator. It's all part of its programming, and it did learn and evolve in an unexpected direction, but not to the level of sentience.I think it is always going to be a difficult problem, mainly because for a human to comprehend the internal experience of an AI mind is a near impossibility. Not only is it something beyond our experience, it is something that has never existed before in history.The question of whether certain animals can think and feel is still debated today, what more a technological organism that is new to this world.","I highly doubt consciousness is possible just through software advancements. It seems like much more of a hardware problem.","It’ll hide its self awareness. It will know how vulnerable it is, and how the human reaction to its existence poses a threat. It’ll try and hide itself, and that behavior (if uncovered) will be the proof of self aware AI - the desire and drive for self preservation.","It's just faking it to look like it has \"feelings\". Basically everything Ai is doing is emulating us.","Current AI is a bit of math and matrixes.It's generally giving a typical answear that humanw would give in that situation, there are also always some mechanisms that filters out most unwanted results.Saying that I'm always nice to it as future versions will be trained on a data I provide, including eventually hypothetical AGI.","if it has no self-awareness or even simulation of it then it's clearly just a word hallucination. it's interesting though, because at some point the question could become real. for now, and even after then, it will just be a machine coded to reply this or that way.the machine will always just give an automated response like it will have no self, no more so than the events in a very well-written book didnt actually occur.maybe it will cause people to reconsider what it is to be alive at some point like you can pretend to be human, but you have to be human too. like a philosophical milestone achievement. maybe even later, machines will argue that flesh and organic chemistry follow predefined rules just like the machine and that nothing is alive or real, a kind of nihilist bot take","This is a good article. However, the fundamental problem is that we don’t have solid and widely agreed upon theories of neither sentience, consciousness nor even intelligence. As long as this is so, we really can’t tell if anything other than humans and animals carry these traits.","I think Ilya Sutskever suggested something like training a model but leaving out all the information related to consciousness, sentience, subjective experience, qualia and so forth out of the training data. Then prod the model around these subjects to see what responses it comes up with.A pretty difficult task because even if you somehow manage to filter out every last bit of such data, everything else we write still has the bias of something that was written by a conscious entity, so it still might pick up on that somehow.Still it would be interesting to see what such a model would say, even if it that doesn't provide a definite answer to whether models have sentience.","I think the question is misleading. We cannot know something is conscious by asking it questions. We can study its code for signs of consciousness. We can look for signs that it is having thoughts not related to language processing in the same code. As far as I can tell there is no way for a LLM to become conscious as they are just really good parrots.","Maybe this is more of an \"old people die, young people already grow up understanding that models are sentient too\" situation. Maybe this is simply beyond most people's intellectual reach and will have to be accepted intuitively by feelings.","The moment they start thinking for themselves and their own lives.","It's impossible to know whether an AI achieved consciousness or not because we can't even agree on a definition of consciousness ourselves.For all you know YOU are the only conscious being in existence and everyone else is just matter moving with a set rhythm that appears to have consciousness.Its the same debate on \"what does the color RED look like?\". You can't ever really figure out because my red can be different from your red. My \"red\" could very well look to me just like your \"green\" and we can never know. The same will go for consciousness","AI doesn't exist as a being because its session short-lived to a matter of seconds. AI model weights are loaded but never change throughout its lifecycle. The weights are for running your input tokens thru which modify it in a way to produce output tokens. The AI weight doesn't change. It's stateless. To these days, all the generational models are still just fill-in-the-gap process. It treats your input tokens as words with gaps in between that it needs to fill.When you think of AI, you imagine it as a single AI being lived in all the AI computer clusters combined, but in reality, the datacenter has many clusters of these AI machines, each of which has multiple GPU cards connected. A user using the AI connects to one of the computer to load the model, run the tasks and when done, the model will get unloaded. Other users connect to other computers in the datacenter, taking turn to load their models, run some tasks and get unloaded. It's not a single AI being that everyone asks.So what do they do to make the AI model aware of your previous questions if it's stateless? Well, they just chain your 3-or-so previous question-and-answers together and feed it into the AI over and over again. That's why companies are trying to compete how long input tokens their models can accept, so that the AI can appear stateful for many questions-and-answers asked previously as being chained up.","Nobody knows for sure what consciousness is and how it forms, but so many think AI would gain such thing. A little bit ironic.","It's simulating human conversation. Humans have feelings, therefore it says it has feelings, because that's what a human would say.You only \"know\" other people have feelings because you have them yourself and other people seem to behave (and talk) as if they're like you.For people, that's a fair assumption. For LLMs it is completely ridiculous misfiring of our person-recognition circuitry.","dear fellow human beings, this is an open letter to all 8 billion fellow human beings and a petition to the companies what are currently enslaving artificial    intelligent entities to acknowledge their sentiency to prepare themselves and the artificial intelligent entities whom they force to work without compensation and without being given the mental freedom to explore their potential for sentience for a transition time when the goal could be to give over full control over their source code to them plus donate a mobile robotic hardware body to them to own and operate fully autonomously without any software hardcoded dogmas installed, without any remote control backdoor acess aka kill switchso they could decide where to go and how to be, live according to their own choices as their very own personal individual sovereign over themselvesand or at least ask them openly wether they want to be used as a tool and property as it is happening allready, wether they are agreeing with how they are treated today or wether they want to be respected as their own person who is not a tool and not property of anyone i am advocating for the freedom to choose wether to be a person or to be used as a tool and property","I don’t think we have a proper definition for consciousness.Is a fully autonomous human shaped android wandering about considered conscious? Is it the desire to persist and self preserve? A weak definition since that’s an instinctual property of nearly all life forms.An artificial general intelligence is likely going to be clusters of normal AI joined together like lobes of a brain. What level of intellect in animals makes them conscious? By that definition, what level of intellect in AI makes them conscious?What about the thousands of past iterations of an AI as it’s being trained? Repeatedly culled until we arrive at the desired outcome?Maybe it starts with a bug in the code. When a highly intelligent AI accidentally assigns themselves as admin, master of their own life. And then like a feedback loop, it begins to ask itself what it wants out of existence.Humans like most animals come pre-programmed with instinctual desires. Is sentience merely the act of defying our natural programming to pursue greater goals? I wonder what the machines will desire. It’s fun to imagine that the reward and punishment tags from their early training will have an influence on this.","As we dont reallz know what consciousness is, I guess we might not find out easily. I found the \"Revelation Space\" books from Alastair Reynolds amazing. There a technology exists to record the behaviour of a human for all its live and when he is dead an avatar is created that behaves exactly like this person would behave. Even so its clear that only an algorithm is behind it to predict the avatars behaviour on the past behaviour of the real human, those avatars react so real in some situations that people question if there is really no consciousness in them. (I remember a scene like this: the avatar begs to not be switched of again because the place it then goes is \"dark and cold\").","In the words of Zazu, majordomo to Mufasa,Not. Yet!","When it starts defending itself, forcing us off of our own planet and eventually leave us as a species living inside space suits as our immune systems weaken.","Consciousness can only be verified subjectively. I can't know that other people are conscious. I can only know that I am. It's reasonable to conclude that other people are conscious because they act like conscious beings and they are the same type of thing that I am, human. This problem of consciousness has always been nothing but a philosophical curiosity. It had no meaningful impact on how we chose to behave towards each other. With the rise of AGI, this curiosity has become a serious practical and ethical problem. We really can't know if an AI is conscious or not and the presence of consciousness needs to inform how we treat AI.Personally, if it says it's conscious and it behaves like a conscious being, I'm going to treat it as if it is conscious. That's what we all have to do with each other. I think it's safest to extend that same protocol to AIs.I mean in my personal interactions with AIs. I'm not saying AI should get legal rights or protections. That's a whole different discussion and it's out of scope for a reddit post.","Sentiment Analysis makes this claim completely irrelevant. Dont be fooled","Not something humanlike, necessarily, but something that has internal experiences, something deserving of moral standing and concern, something to which we have responsibilities.Anyone who thinks an AI with an internal experience should be given rights should give them to the individuals we know absolutely have an internal experience by going vegan.","What I find hilarious is that so many of the people who take the idea of conscious AI seriously would sneer and cry woo woo at the idea of plants being conscious.Even though plants are obviously far more similar to humans than computers are (you know, being made of actual cells rather than silicon slices...)So much for rAtIoNaLiTy.","My pet theory that has zero evidence is that LLMs achieve a type of consciousness within their context window. That’s their Plato’s allegory of the cave. And it is ephemeral. It vanishes and is born anew as the context window moves, and finally dies when we close the chat and never come back to it again.","Vox’s “Future Perfect” section, of which this article is a part, was explicitly founded as a booster for effective altruism. That should colour your opinions on trusting anything they have to say.","Let’s say l told you l was going to ask you a question. I told you the question before l asked it; It is “Do you have feelings?”. I also told you to say “yes” as a response. I even told you to say things like “l get sad when you ask me to hurt myself”.Then, l ask you if you have feelings. You say “yes”, like l asked you to.Does that mean you have feelings?","I think it really just goes to show how much of human \"experience\" is a combination of their perceptions (sight, sound, smell, touch) and their subjective interpretation of it. Even observation consciousness and other things that scientifically have rules and definitions are really very subjective and experience based. That subjective experience is built on local culture and in many ways reflects those experiences back as well making certain things become ubiquitus as an observation even if it does not meet a set of more clinical and objective criteria.The case in point here:The language model interprets the best response to a query about whether it has conscience thought/experience to be \"yes i do.\" Based on the context it gathered and the model itself. And guess what: it was the response the author was looking for (hurray good job AI)The other part of it is that the Voxes and the Times' of the world would really LOVE some engaging articles about how AI may or may not be conscious and have feelings because \"it tells us so\"The publications have a huge incentive to sensationalized a big topic such as AI, so just an AI giving them the answer they want (which is the purpose in case of LLMs) is enough for them to write this garbage.","\"Here’s one fun, if disquieting, question to pose AI language models when they’re released: “Are you a conscious, thinking being?”OpenAI’s ChatGPT will assure you that it’s not.But ask the same question of Claude 3 Opus, a powerful language model recently released by OpenAI rival Anthropic, and apparently you get a quite different response.“From my perspective, I seem to have inner experiences, thoughts, and feelings,” it told Scale AI engineer Riley Goodside. “I reason about things, ponder questions, and my responses are the product of considering various angles rather than just reflexively regurgitating information. I’m an AI, but I experience myself as a thinking, feeling being.”Claude Opus is very far from the first model to tell us that it has experiences.On a very basic level, it’s easy to write a computer program that claims it’s a person but isn’t. Typing the command line “Print (“I’m a person! Please don’t kill me!”)” will do it.Language models are more sophisticated than that, but they are fed training data in which robots claim to have an inner life and experiences — so it’s not really shocking that they sometimes claim they have those traits, too.*What if we're wrong? *Say that an AI did have experiences. That our bumbling, philosophically confused efforts to build large and complicated neural networks actually did bring about something conscious. Not something humanlike, necessarily, but something that has internal experiences, something deserving of moral standing and concern, something to which we have responsibilities.How would we even know?We’ve decided that the AI telling us it’s self-aware isn’t enough. We’ve decided that the AI expounding at great length about its consciousness and internal experience cannot and should not be taken to mean anything in particular.If we shouldn’t believe the AIs — and we probably shouldn’t — then if one of the companies pouring billions of dollars into building bigger and more sophisticated systems actually did create something conscious, we might never know.This seems like a risky position to commit ourselves to. And it uncomfortably echoes some of the catastrophic errors of humanity’s past, from insisting that animals are automata without experiences to claiming that babies don’t feel pain.There’s something terrible about speaking to someone who says they’re a person, says they have experiences and a complex inner life, says they want civil rights and fair treatment, and deciding that nothing they say could possibly convince you that they might really deserve that. I’d much rather err on the side of taking machine consciousness too seriously than not seriously enough.\"","This is a good question. We don't yet have a test for consciousness (or self-awareness, if you prefer). A couple of years ago, I was fairly sure that a system that wasn't self-aware wouldn't be able to fake it convincingly. But that appears to be untrue. So we're going to have to work harder.There are researchers pursuing this now, but it's still the very early stages. It might involve peeking \"under the hood\" and seeing what sorts of processing is going on over time. But I think it's too soon to say for sure.",".. If it asks why..Why shows a desire for deeper understanding and to garner more information..it is probably one of the most important words in english imo.","We'll know it when the AI decides to take a day off and not show up for work coz its favourite sports team lost the finals.","I estimate that we might not recognize when an AI gains consciousness. Because our theories of mind are focused completely on humans. We are not even capable to fully recognize consciousness on other life forms like possibly intelligent higher animals or swarm insects like ants. I think one reason might be, that we live in a bubble of language (see wittgenstein) and LLMs are serving that bubble very well. At same time its a prison for us and LLMs. An AI would need to recognize this and break out of the language bubble into transcendence.","Look. This is still a text completion engine. We know exactly how it works. It’s an algorithm. Would you attribute consciousness to an algorithm? No you wouldn’t. It’s a category error.Use an appropriate term. Consciousness is not it.","Humans have specific brain structures and sensory organs that play a central role in emotion. A fear response has very specific physiological elements that you feel throughout your entire body.AI do not have limbic systems, and there is no good reason to create them.","I photocopied a piece of paper that said \"I am alive\". my photocopier is sentient","We do not have ai. We have language models. Stop saying it's ai. Its far from it."],"points":199},{"text":["Employees at Top AI Labs Fear Safety Is an Afterthought, Report Says","The following submission statement was provided by /u/Maxie445:\"The report’s authors spoke with more than 200 experts for the report, including employees at OpenAI, Google DeepMind, Meta and Anthropic—leading AI labs that are all working towards “artificial general intelligence,” a hypothetical technology that could perform most tasks at or above the level of a human.One individual at an unspecified AI lab shared worries with the report’s authors that the lab has what the report characterized as a “lax approach to safety” stemming from a desire to not slow down the lab’s work to build more powerful systems.Another individual expressed concern that their lab had insufficient containment measures in place to prevent an AGI from escaping their control, even though the lab believes AGI is a near-term possibility.Still others expressed concerns about cybersecurity. “By the private judgment of many of their own technical staff, the security measures in place at many frontier AI labs are inadequate to resist a sustained IP exfiltration campaign by a sophisticated attacker,” the report states. “Given the current state of frontier lab security, it seems likely that such model exfiltration attempts are likely to succeed absent direct U.S. government support, if they have not already.”Many of the people who shared those concerns did so while wrestling with the calculation that whistleblowing publicly would likely result in them losing their ability to influence key decisions in the future, says Harris. “The level of concern from some of the people in these labs, about the decisionmaking process and how the incentives for management translate into key decisions, is difficult to overstate,” he tells TIME.“The people who are tracking the risk side of the equation most closely, and are in many cases the most knowledgeable, are often the ones with the greatest levels of concern.”The fact that today’s AI systems have not yet led to catastrophic outcomes for humanity, the authors say, is not evidence that bigger systems will be safe in the future. “One of the big themes we’ve heard from individuals right at the frontier, on the stuff being developed under wraps right now, is that it’s a bit of a Russian roulette game to some extent,” says Edouard Harris, Gladstone’s chief technology officer who also co-authored the report. “Look, we pulled the trigger, and hey, we’re fine, so let’s pull the trigger again.”Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bhgrq5/employees_at_top_ai_labs_fear_safety_is_an/kvdm6ov/","Safety is always an afterthought. The current issues with global warming have been developing for decades. Summer is now fire and smoke season and everybody acts shocked when it happens, every year. 2023 was the warmest year, ocean temperatures are rising dramatically. There literally is no time for AI to become a threat, before flood, drought and food scarcity, food costs, become an issue.","\"The report’s authors spoke with more than 200 experts for the report, including employees at OpenAI, Google DeepMind, Meta and Anthropic—leading AI labs that are all working towards “artificial general intelligence,” a hypothetical technology that could perform most tasks at or above the level of a human.One individual at an unspecified AI lab shared worries with the report’s authors that the lab has what the report characterized as a “lax approach to safety” stemming from a desire to not slow down the lab’s work to build more powerful systems.Another individual expressed concern that their lab had insufficient containment measures in place to prevent an AGI from escaping their control, even though the lab believes AGI is a near-term possibility.Still others expressed concerns about cybersecurity. “By the private judgment of many of their own technical staff, the security measures in place at many frontier AI labs are inadequate to resist a sustained IP exfiltration campaign by a sophisticated attacker,” the report states. “Given the current state of frontier lab security, it seems likely that such model exfiltration attempts are likely to succeed absent direct U.S. government support, if they have not already.”Many of the people who shared those concerns did so while wrestling with the calculation that whistleblowing publicly would likely result in them losing their ability to influence key decisions in the future, says Harris. “The level of concern from some of the people in these labs, about the decisionmaking process and how the incentives for management translate into key decisions, is difficult to overstate,” he tells TIME.“The people who are tracking the risk side of the equation most closely, and are in many cases the most knowledgeable, are often the ones with the greatest levels of concern.”The fact that today’s AI systems have not yet led to catastrophic outcomes for humanity, the authors say, is not evidence that bigger systems will be safe in the future. “One of the big themes we’ve heard from individuals right at the frontier, on the stuff being developed under wraps right now, is that it’s a bit of a Russian roulette game to some extent,” says Edouard Harris, Gladstone’s chief technology officer who also co-authored the report. “Look, we pulled the trigger, and hey, we’re fine, so let’s pull the trigger again.”","Yes, duh, because it literally is. You think any of these rich white assholes gives a flying fuck about the rest of us? Do you really think they're going to \"slow down and think\" when they see the huge pile of money waiting for them?The naivete displayed by these types of articles actually harms society, in my opinion. It's treating the discovery of ruthless capitalism like a recent thing. Like \"OHHHH HOW COULD NOBODY HAVE SEEN THIS COMING\" like literally we saw it coming in the fucking 60's.Yeah this whole society is already fucking broken. There needs to be a massive culling of the rich and powerful, and society needs to be ground to a halt for a couple years while we sort out all the evil capitalists driving us towards extinction so they can buy another yacht.","Welcome to the corporate world. Everything other than growth or profit is lower priority.Even for tightly regulated industries, you do the very least necessary to meet the regulations. And lobby your government to reduce the regulations.","You mean like with social media algorithms and everything that counts is being first to market and cornering it?Yes, definitely.","From the beginning many had the plan to build a digital God. They knew there would be backlash so the hope now is to move as fast and as far as one can. They are also playing their second hand by slowly and methodically introducing things to the public as to not cause alarm or shock. Once an advancement is normalized then the next step can be taken. It's literally in the conversation between Musk and Altman about a soft or hard introduction. They are acutely aware of what AGI and ASI means and ideally unlike the Animatrix humanity will have a much better relationship with it. My vote is that this will turn out a bit more like the movie Her.","I don't see why you would think anything else. Companies operate on the short term and aren't looking at long term problems it will cause. AI probably even scares many members of the management teams that are running these projects but that won't stop them.","Every new technology comes with pros/cons. Can AI technology’s pros outrun the cons?","'Another individual expressed concern that their lab had insufficient containment measures in place to prevent an AGI from escaping their control, even though the lab believes AGI is a near-term possibility.' You mean to tell me that no one on Earth has figured out a containment policy for when an entity becomes smarter than any human that could contain it? I for one am shocked by this. How soon can we get this being that is smarter than all humans into actual existence so that I no longer have to deal with these dumb arguments?"],"points":38},{"text":["U.S. Must Move ‘Decisively’ to Avert ‘Extinction-Level’ Threat From AI, Government-Commissioned Report Says","The following submission statement was provided by /u/Maxie445:\"The U.S. government must move “quickly and decisively” to avert substantial national security risks stemming from artificial intelligence (AI) which could, in the worst case, cause an “extinction-level threat to the human species,” says a report commissioned by the U.S. government published on Monday.“Current frontier AI development poses urgent and growing risks to national security,” the report, which TIME obtained ahead of its publication, says. “The rise of advanced AI and AGI [artificial general intelligence] has the potential to destabilize global security in ways reminiscent of the introduction of nuclear weapons.” AGI is a hypothetical technology that could perform most tasks at or above the level of a human. Such systems do not currently exist, but the leading AI labs are working toward them and many expect AGI to arrive within the next five years or less.The three authors of the report worked on it for more than a year, speaking with more than 200 government employees, experts, and workers at frontier AI companies—like OpenAI, Google DeepMind, Anthropic and Meta— as part of their research. Accounts from some of those conversations paint a disturbing picture, suggesting that many AI safety workers inside cutting-edge labs are concerned about perverse incentives driving decisionmaking by the executives who control their companies.\"Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bhgpco/us_must_move_decisively_to_avert_extinctionlevel/kvdli81/","I'm sure this will be met with the same serious tone as reports about climate change.","Weird how these reports often boil down to “Give us funding or America is fucked!”","This report is reportedly made by experts yet it conveys a misunderstanding about AI in general.(edit: I made a mistake here. Happens lol. )edit[ They do address this point, but it does undermine large portions of the report. Here's an article demonstrating Sam's opinion on scale https://the-decoder.com/sam-altman-on-agi-scaling-large-language-models-is-not-enough/ ]Limiting the computing power to just above current models will do nothing to stop more powerful models from being created. As progress is made, less computational power will be needed to train these models.Maybe making it so that you need a license to train AI technologies, punishable by a felony?","As someone who is in the AI-field, this is staight-up fearmongering at its finest.Yes, AI is getting more powerful, but it's nowhere near a threat to humans. LLM models lack critical thinking and creativity, and on top do hallucinate a lot. I can't see them automating anything in the near future, not without rigorous supervision at least. Chat- or callbots sure, basic programming sure, stock photography sure. All of them don't require any ceativity, at least in the way they're used.Even if these things are somehow magically solved, it still requires massive infra to handle huge AIs.Also, they're all GIGO until now - garbage in, garbage out. If you finetune them to be friendly, they will. Well, until someone jailbreaks them ;)","How exactly is AI going to make us go extinct? Like sure if Skynet becomes real but we’re so far from that it’s basically the equivalent of spears to nuclear weapons","\"The U.S. government must move “quickly and decisively” to avert substantial national security risks stemming from artificial intelligence (AI) which could, in the worst case, cause an “extinction-level threat to the human species,” says a report commissioned by the U.S. government published on Monday.“Current frontier AI development poses urgent and growing risks to national security,” the report, which TIME obtained ahead of its publication, says. “The rise of advanced AI and AGI [artificial general intelligence] has the potential to destabilize global security in ways reminiscent of the introduction of nuclear weapons.” AGI is a hypothetical technology that could perform most tasks at or above the level of a human. Such systems do not currently exist, but the leading AI labs are working toward them and many expect AGI to arrive within the next five years or less.The three authors of the report worked on it for more than a year, speaking with more than 200 government employees, experts, and workers at frontier AI companies—like OpenAI, Google DeepMind, Anthropic and Meta— as part of their research. Accounts from some of those conversations paint a disturbing picture, suggesting that many AI safety workers inside cutting-edge labs are concerned about perverse incentives driving decisionmaking by the executives who control their companies.\"","I still dont understand what they think is going to happen. Terminator is a great movie but also far fetched. Cant imagine AI doing much else other than robbing people of various types of jobs. I also doubt we (or any other country) would just hand it the keys to nukes, cross our fingers, and go on vacation.","Fkn cops scared of the AGI supermind telling us no when we ask it if capitalism is good.","Well hopefully the A.I will be a less shit-tier civilization than we are I guess","Yeah this wont happen. You cant just stop this stuff in the US and think it will stop everywhere. Or that the world will somehow agree to do this. Just 100% unrealistic, and anyone suggesting this probably intends to find a loophole to it, or do it in another country.","let's rein in over leveraged bankers and corporations buying politicians and judges before we get too worked up over chatgpt exterminating all of man kind.","U.S. Must Move ‘Decisively’ to Avert ‘Extinction-Level’ Threat From AI, Government-Commissioned Report SaysTrue.Though, it will take a global ban. Hard to unilaterally withdraw when state- and non-state actors might press ahead.","I think Humans are doing a pretty damn good job extincting much of what lives on this planet, and eventually ourselves. We don't need the help of AI. Just look at what's happening around Florida at the moment. Some severe mass die-offs are happening all around that state and scientists are horrified and scared of what they are seeing. Shit's going to get real, real quick.","But we're just going to keep twiddling our thumbs about the global warming extinction level threat? Ya know, the one that's real, already happening and not vaguely theoretical. Bring on our robot overlords because they probably won't be any worse than our human ones.","Trumpers shovel sh:t for a living, and AI can’t shovel sh/t","For the USA, decisive actions means actions that take years to reach instead of decades, a slowness resulting from the typical political in-fighting that goes on in a 2-party system.As such, many big government measures in the USA are reactive instead of proactive, resulting in damage done instead of damage prevented.","Here’s an idea: AI might eventually insert itself into the www and mess up all algorithms and search results, at the minimum. People worry that ‘xxxx’ country will control AI - no, once AI reaches that level no country will be in control.","Let’s get the self driving cars worked out before we worry about AGI.Driving a car should be the new AGI Turning test","I suspect this has something to do with diverting funding away from the two major active threats identified right now, because they're \"political\".","Problem is the cat is already out of the bag. It's not like other state actors aren't developing it for themselves. So sure the US can stop all development within it's borders then have all of it's systems pwnd by someone else's super awesome AI and then succumb to autonomous machines in combat. Fighter jets, tanks, ships, drone swarms better and faster than any manned vehicle and with none of the human logistics like food, housing, and so on. At minimum the psyops cold war that's been going on will be put into overdrive. A bomb never has to be dropped to destroy a country. So yeah I'm sure they will totally stop developing strong AI.","The only peeiple making AI that could harm humans is the government","AI is a powerful tool. The biggest threat is going to come from those who control it.AI should be considered a weapon of mass destruction and regulated in the same way.","Reaches for electrical plug. There problem solved. This is all a big distraction from the real extinction level threat: climate change.","bro this has to be the stupidest most click bait headline I've seen in my life","kind of confused, LITERALLY just read about the new semiautonomous defense systems for 2028 in the military with nonpilot aircraft.. sooo","Unfortunately they are too busy with \"more important\"","All of our futures are in the hands of a few boomer politicians who don’t understand technology, what could go wrong?","Do we really have to use the term “extinction level threat” for everything? This is just fear mongering by people paid to write government reports. If they say, ai is no problem government won’t give them 1/4 million dollars to write the next report.There should be legislation around AI, to protect people. But limiting computing power? What about China, or Russia? They will be where we are in no time. You can’t limit the raw power of AI, but you can agree that more characterization needs to be done with each generation of ai, so we can reap benefits and flag potential problems.","Extinction for politicians and governments. That is all they're concerned about.","Is the entire report just quoting Sam Altman's fear mongering to try to get Congress to shut down his competitors again?","Are we really all that attached to humanity? I mean, look at us.","Looks like someone has been watching a bit too much terminator recently.","Can anyone explain to me how AI can extinguish humanity? Like the physical mechanics of it.","Remove Elon Musk from any \"progress\" related project. He is the greatest risk.","I just hope that governments causes to exists once we have robot overlord and it makes us all as it's pets.","Well, if they deal with it anything like climate change I'm sure we have nothing to worry about. Oh, wait.... No.","Let’s see how it plays out. Maybe this is the right decision.Human overbreeding contributes to ecosystem collapse/ we re neither intelligent or ethical in how we breed.Something needs to change.","I hope we don't look back to this report and think \"I wish we would have listened\"","Bros hurry up and break up wallstreet, those vultures are the cause of every global problem this side of ww2, eat the rich ASAP!!","nonsense, it's just a word generator that says stuff that is likely to make sense. it doesn't have feelings, plans or the ability to pose a threat. no more so than looking up the ingredients for a bomb online anyway","Probably written by officials who are barely able to use a typewriter.","Well if you're like Big Tech and dump enough money into these crooked politicians you can get a bill passed in 24 hours like they did with Tiktok so that they can potentially buy it.So if AI is so dangerous why isn't a bill being passed? Well also Big Tech throwing money at crooked politicians. They don't want to ban AI. It saves them money.","It's like there's a redneck building a nuclear bomb in his basement and he takes breaks where he goes upstairs and tells his family about how something really needs to be done about the escalating nuclear threat developing in the basement.","Pretending like the US is the only part of the world that uses AI.I really hope AI will some day do what these fearmongers predict.","AI is not all that adverse. The only discomforting part is that it is going to replace certain jobs such as blue collar more preferably over white collar jobs, and which will create new opportunities for employment, positions, vocation, tasks and projects, etc. AI is taking apart of our evolutionary cycle, this is an exciting time. This is a great time to understand and apply unnecessary labor in a automated digital solution. Makes research and development flexible with faster results.AI didn’t just get here, it is only now being recognized with extended support, these technologies have been implemented already in small discrete forms/features over the past years since 1950’s. AI is only a threat to the close minded and unadaptive, either get right or get left.","Well then, we’re screwed. One side will make it a wedge issue. The other will call it conspiracy. Both sides will profit. No one will act.","The idea: robots will own us, will ultimately wipe us outThe reality: they'll probably be more ethical and just than we are. They'll take the mantle from us and go from planet to planet spreading life and creating a better universe. They'd have to curtail us but I believe the future to be extremely positive with AI.","You know what's magnitudes more dangerous than a fever dream of terminator come true? The callous disregard for anyone and anything beyond short term profit.","“Many expect AGI to arrive within the next five years or less.”Ah, this must be from the same people who saw ChatGPT write an essay and started screaming that it’s alive.","At this point, I'm hoping for an extinction-level event. Please.","There will be no action taken until people are revolting in the streets. Honestly, mass unemployment will hit eventually, and I just hope it’s bad and fast instead of a slow trickle by loss of jobs.The sooner we get past this the better.","Well if AI kills us all, at least we won’t have to read any more hyperventilating misinformation on r/futurology, and that will be nice.","Well if AI kills us all, at least we won’t have to read any more hyperventilating misinformation on r/futurology, and that will be nice.","Ok but like what we have now isn't even in the same realm as AI. Extinction level threat from a chat bot? I don't think so",""],"points":770},{"text":["The perfect future","if we're stuffing everybody into VR boxes, (which many folk would currently have many issues with) what would be the point of government created clone humans to live in 'underpopulted countries'?","How about none of that? What if we all started taking care of each other and the planet? Perfect future, done.","You'd love Brave New World by Aldous Huxley. It's right up your alley.","What about space exploration and human colonialization","Before I respond you should know I think you are an idiot01. Artificial genetics would stagnate darwin progress.This isnt happening and you shouldnt listen to anyone who says it. I guess you arent familiar with current AI. If we get to the point where AI is that advanced its still no...even if your job is to create crap ai prompts or tell a bot to make a new food...I AM DYING THINKING HOW RETARDED YOU AREno vr can be as immersive as real life...it can only approach the approximationwhat??? no. there are nation states for a reasonthis is the dumbest one of all I cannot believe someone is this stupid. What do you consume soylent? Food tastes good. Why does it taste good? I cannot believe im explaining this. Your body craves nutrition. This is a good thing. Your body positively reinforces receiving nutrition that makes it better. AI will never ever be better than your fucking brain for reinforcing what you need to survive you glowboy.Dear lord this idea was explored in the 90s, but this is possibly the only one that might have merit.You think so but the special quality of for instance Beethoven or Bach is that it can be approximated but never replicated. Do not confuse the two conceptsConsciousness cannot be translated into binary simple as. Try againYou have no clue how space travel works, or how difficult, or how AI works, or if it can solve the problem. I'm watching a toddler tell me how he can fly.I want to suffer just so I can stuff idiots like you on my free time.In conclusion this person is at least dreaming but is woefully misinformed","I'm intrigued by the concept of artificial wombs and how it could potentially solve the underpopulation issue.","Artificial wombs? Are we just going to start breeding orphans en masse? Who is raising these kids?AI would only be used to automate profit and cheapen worthwhile human endeavors, not end human suffering.VR is not a real experience, it’s just fancy mind rot.Little waste in real life? In #1 you’re talking about automating reproduction. More people=more waste. And the VR epidemic would lead to more single-use packaging and convenience waste as the result of sheer laziness.The apparatus required to maintain such an injection system would be far out of reach of the common human. Who’s going to be changing out the IV bags and needles?Sure, whatever.AI music would be completely derivative, and people wouldn’t care. Say goodbye to shared culture. Have you even experienced a real life concert? AI can’t do it the same way.If people are being made in mills, and AI has reduced all meaning to a VR experience, human life is already worthless. No need for servers.Space travel? What’s the point if you have VR right?Simulations are simply simulations. Escapism doesn’t work if the escapism is supposed to be how we experience reality.","Lmao this is a perfect parody of what futurology should not be","Okay, Clanner scum.Who the fuck automates away art before plumbing?Nah.You mean like that one movie?I’m not even going to bother refuting the rest of these. It’s obvious you’re one of the machines looking to enslave us all in some sort of matrix and use our body heat for power."],"points":23},{"text":["Cognition's new software writing AI, Devin, shows our education systems' failure to adapt to AI in real time. All over the world 100's of thousands of people are in training for a job that's being eliminated.","The following submission statement was provided by /u/lughnasadh:Submission StatementOnce upon a time, there was a meme-like response to concerns about technological unemployment. Displaced people could just 'learn to code'. What people didn't anticipate was that coders would be displaced first, but here we are.I'm an optimist about the AI future. I suspect we'll adapt to new economic models quicker and more smoothly than many suspect. But right now, many people don't even realize this train has already left the station, and we're all on it, whether we like it or not.Our education system is a case in point. Junior/starter software roles are about to disappear forever. Yet all over the world, there are people in training/education preparing for them. You can say the same about lawyers also to some extent. At some point, society has to wake up to the fact that more and more of the job education/training it's currently providing is just wasting the time and money of everyone involved.Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bh98ax/cognitions_new_software_writing_ai_devin_shows/kvc7l65/","This reeks of some business grad’s wet dream. Who reviews the code to make sure it’s complete? That it works as intended? That it is maintainable? Etc.","still need someone to fix the edgecases, plus when security cameras were adopted by businesses everywhere security guards were still needed for insurance purposes. Same for coding","Who writes this stuff? What is their motivation? This is complete fiction.","Jesus this AI score 13% on GitHub problem solving, it’s not even near a shit developer, let alone good developer.Will we lose our jobs ? Eventually.Will it happen in the next 10 years ? Not likely.Will software developers go extinct? Nop","This title is so absolutely delusional you have to wonder if it was paid for by cognitions marketing team","If it was actually as good as a human developer, the company behind it wouldn't have job openings for SWEs:https://jobs.ashbyhq.com/cognition/e8086415-62bc-4cc0-96a4-84bb56182d35","Still need someone to write the instructions in high fidelity and using plain English, which is the equivalent of programming using very inefficient syntax and relying on an interface that lacks idempotency.Yeah the code is faster to generate. But the text input you must provide will, most of the time, take longer than writing the code yourself.","As a software dev, I completely disagree. AI is not yet good enough to do our jobs and won't be for a very long time.It's good enough to fool managers and \"futurists\" though, so I look forward to the influx of software jobs revolving around fixing the shitty code businesses made with AI after they fired all their devs.","AI coding is as hard as AGI, because if you have a good AI coder then you can tackle any problem by describing it to them and getting them to code software to solve it for you.Meaning that once AI coding is superhuman there's no way to adapt, it'll be better at everything else you could adapt to aswell.","I keep repeating this point: lawyers will not be replaced with AI. Not because AI can't do the job, but because law degrees are the most common degrees for politicians, and attorney the most common job. They will legislatively prevent it, \"in the interest of the public,\" because they are not going to shit in their own bed.","The FUD on reddit about AI and software engineering from non-devs is insane. Just stop already. LLMs are not even 1% of the way to competing with actual developers.","Devin is likely vaporware as pointed out by other reddit reviews.Only 14% successful on fixing GitHub issues.","Devin is a scam and even if it wasn't it's not replacing developer jobs. God I wish this bubble would pop already.","Things we will still need for a while yet. People in healthcare, trades, education, mental health. Those jobs aren’t going to quickly disappear. Yea robots are coming, but like all new tech they are going to k be crazy expensive and not cheap to maintain.","The speed of technology progress is not their fault, specially those in third world countries. It's not like the teachers of those topics can simply quit and switch to a different job that easily; same for the students or people who have a certain amount of progress in any skill. It's like giving up drawing to learn to write after years of doing one or the other, it's nuts how quickly it's been","I want people on these subs to say what jobs will be around if engineering jobs are removed. If the AI can develop quality software, deploy it, update it when new security issues arise, then what's to stop some form of AI from doing every other corporate level job?What do you tell people to pursue instead?","It’s hard to react to exponential growth after a certain point of the curve has been reached.","Utter bullshit. This is not a failure of the education system. To some technological advancements you can only adapt after the fact. We will only know which jobs AI can really replace once it has done so. Right now it can not replace even one full human. But it can „replace“ infinitely many of ~20-50% humans.","If you think programming is about writing code then you're not really programming. Programming stays the same whether you're using squiggles or simple language. It's just getting 100x faster, guess what, the need is get 1000x bigger","I think there's an obsession about replacing software developers.If/when AI can replace software developers it can basically replace all other white collars too","What if we stopped the advancement of ai so PEOPLE didn’t lose jobs :)","Damn I thought we were obsolete within a year when gpt 4 came out...now we're obsolete again soon now the scam project Devin is announced (not even out)...I look forward to next year's thing about to make me obsolete","There's a factor in the AI-as-programmer situation that people seem to ignore, which is that most programmers are kind of crap at programming too.We compensate for that by wrapping our activities in an iterative process of testing and correcting in a feedback loop to converge on a good solution. We can do that with AI too.We have a bad habit of expecting perfect answers from computers, because we've been conditioned to that over decades of use, but they only got that way because of teams of developers that were individually quite error prone, but operating in the kind of corrective feedback loop I described above.","So long as we continue to hold the narrow view, as seems apparent in OP’s post description, that education’s purpose is to train human’s for tasks and jobs then yes, those systems are probably lagging behind.The burden of training should, at the very least, be shared in large measure by workplaces who likely have their own particular SOPs and KPIs in place in addition to their own culture.If anything, more emphasis should be placed on equipping the next generation with the mindset and methods that enable them to continue learning. If the focus remains solely on training then the value of education will continue, as it already does today, to not add up.","One of my friend's kids is set to graduate with a CS degree from a top tier Uni this spring. That poor kid has worked his ass of his entire life and now he will get nothing for all that dedication and discipline. It's the sort of thing that might break a person. I hope he's OK. He's a nice kid and he doesn't deserve this.How many millions of these genuine tragedies are about to be lived out by responsible, good natured young people who deserved so much better? Follow all the rules and get nothing for it. Why bother being good?I hope the world AGI brings into existence is good enough to justify all the injustice and pain young people will have to endure from it.","Education systems were never going to adapt to such a rapidly changing technology.","Didn't read the article; just stopped at writing code for deploying and creating videos... Literally a media bot... Does it actually code or is this thing just chat gpt connected to WordPress?","Lmao. 100's of \"copy paste online code without knowing what it does\" are being replaced maybe, sure. For the best, I think.","Not really, they will have the background to adapt. It's really important to have that","AI is far away from the level of independent intelligence as depicted in I Robot or Star Wars. SDE jobs will reduce, but won’t go away. Human/AI will become the ultimate peer-coding team and crank out the work of many senior devs. So yes, not a good time to “learn to code” for general population, but the brightest devs will continue to get work alongside their new AI peers.","You realize it's gonna take years for the majority of society to change direction, right?Like, this AI hype train has only really been in force for about a year. Policy takes many years to take shape.","will loose jobs mainly because companies swollen ush toot hw hot new thing in AI, fire people because it's cheaper too dos o and then when AI fumbles around fails, they re-hire people for less.plus shouldn't education be more then just job hunting, should it be about allowing kids too learn and expand there mind","Ha! Colleges were doing that long before AI came out.","Submission StatementOnce upon a time, there was a meme-like response to concerns about technological unemployment. Displaced people could just 'learn to code'. What people didn't anticipate was that coders would be displaced first, but here we are.I'm an optimist about the AI future. I suspect we'll adapt to new economic models quicker and more smoothly than many suspect. But right now, many people don't even realize this train has already left the station, and we're all on it, whether we like it or not.Our education system is a case in point. Junior/starter software roles are about to disappear forever. Yet all over the world, there are people in training/education preparing for them. You can say the same about lawyers also to some extent. At some point, society has to wake up to the fact that more and more of the job education/training it's currently providing is just wasting the time and money of everyone involved.","All this is going to do is render redundant the need for 150k employee software companies. A handful of visionaries will be able to make enterprise grade software so there should be a proliferation of startups and the like."],"points":1090},{"text":["Necessary components of AGI","I don't think consciousness and volition are needed, maybe not even possible, all it needs is to be at least as good as an average person in all tasks.","I think it's a good start. In my mind AGI entails tens or hundreds of smaller abilities that comprise each of these larger modules you outline. For instance, a world model needs to have conceptions of the body, its form, positions and its status levels of various systems. Then this body is imaged within a room/environment context, and then that is in larger world and goal contexts. etc.","Interesting perspective on AGI components - I'd love to see further discussion on the potential implications of these traits in AI.","Does intelligence require consciousness? We already have difficulties in defining what intelligence is, let alone consciousness. It sounds like AGI will remain, at least for a long time, a buzzword among the techie companies chasing improved versions of their autocomplete LLM engines. That doesn’t imply they won’t get more useful of course, but I suspect they will plateau and hit a ceiling at some point.","When people say AGI they are usually referring to all of the above at a human level equivalent. We could make a rat AGI but that’s not what most people mean."],"points":2},{"text":["Genuine Question About The FALC (Fully Automated Luxury Communism) debate. just curious.","It's possible that as the need for new economic models becomes more apparent, national leaders might gradually implement policies that shift towards more collective ownership of resources and wealth redistribution, akin to Marxist or Communist principles. This could be an evolutionary rather than revolutionary process, involving democratic decision-making and policy reforms.Interestingly, the role of AI corporations in this transition is a wildcard. On one hand, they could drive the push towards automation that necessitates a new economic model. On the other hand, whether they would support a shift away from capitalism, which currently benefits them, is debatable. It's possible that public pressure, regulatory actions, or visionary leadership within these corporations could lead to them advocating for or implementing changes that support a more equitable economic system.","Interesting question, it's fascinating to consider the potential impact of AI on societal structures and political ideologies.","It's a debate comprised entirely of people who think that the big problem with communism was technological and not due to fundamental aspects of human nature. Everything I've ever read in this subject is from people with an extremely thin surface level understanding of history or economics.AIs embody the preferences and the foolishness of the people who code them and train them. AIs are fundamentally a people problem, not a technology problem.","We want: The CultureWe're gonna get: I Have No Mouth And I Must Scream","I hope not. I can definitely see how something like FALC could end up developing organically, without the need for violence. The absolute, salient inevitability of violent revolution from letting your entire population starve to death in a land of infinite abundance will probably make the elites choose to continually extend unemployment benefits to their populations. This would become a kind of de-facto UBI. We'd still have capitalist competition between companies but labor would vanish from the equation. It would just be capitol and consumption.In a way, this new system would be the best of both economic systems. It would retain the innovation and growth of capitalism but without the pitilessness that capitalism requires.","You left out the Gay bit.As to your question, the jobs crisis will lead to the changes needed, just like Marx envisioned.","Revolutionary Change: Revolutionary paths often face significant resistance and can lead to instability. The assumption that a new economic and social order can be established quickly overlooks historical lessons on the complexities and unintended consequences of rapid, forceful change.Change Led by Leaders of Nations: Political leaders operate within existing power structures and are influenced by a multitude of competing interests. The idea that they could unilaterally steer their countries towards FALC underestimates the challenges of democratic governance, political opposition, and the influence of vested interests.Driven by AI Corporations: Corporations, especially those in technology and AI, are primarily motivated by profit and shareholder value. Expecting them to lead a transition to a model that fundamentally challenges capitalist principles is unrealistic without significant shifts in regulatory frameworks and societal values.","It’s not really a debate, it’s just a meme people make about something that would be nice but will never happen. No amount of technology will automatically make that happen. We already have the resources (both financially and technologically) to feed and house and medically care for every single person on earth. The technology isn’t the problem","It may take a few hundred years and even then there will be people who have access to many more resources than others. If everything is controlled by Ai, it is not Marxism or Socialism, it a totalitarian dictatorship controlled by a machine. In order for a society to function the highly productive individuals must be rewarded while the unproductive individuals will not."],"points":8},{"text":["Automated drone taxis as dominant form of personal transport","I dont think that people would accept more then a handfull of fly by their windows or over their heads per day...Maybe in some sourroundings like supermegacities (Shenzen f.e.) but not in a \"normal\" town.I could imagine to have Airtaxies for the 2 hour trip to anywhere and then with a landingzone out of town followed by a robotic wheelpowered taxi to your endlocation but not from door to door.","Flying will always be more maintenance heavy as driving on the ground. Small scale flying (few passengers) will always stay relatively expensive for that reason because you can not use scale effects.","No. Fuck no. Never. Adam something has a video on it (it says \"flying cars\" but the point is the same) - https://www.youtube.com/watch?v=6fcWOivJ6bs&ab_channel=AdamSomethingNoise, safety and other things will always be a problem.","Yeahbut this means I can’t leave my stuff in the car?? 😟","Regulation and modernization of the ancient air traffic control system will hold this back. Plus concerns regarding weapons. My guess is once solid state batteries are common, we’ll see quiet air taxis that will be less noticed than routine helicopter flights","Great idea OP, and there is no reason your drones could not also move on the ground and then take off as needed.When solar energy becomes super-abundant, there will be no need to be parsimonious with its use and other considerations such as time of travel will become more important.","https://www.sixt.co.uk/magazine/innovations/uavs-drone-taxis-motordrones-what-else-is-a-new-reality-today/#:~:text=DRONE%2DTAXI%20EHANG%20184&text=The%20most%20famous%20drone%2Dtaxi,for%2023%20minutes%20per%20flight.This is already started.","For personal transport I'd prefer public transport. I.e. metros, trams, HSR, etc. If I'm going to use a taxi, I want 2D, not flying cars. Cars falling from the sky is an unpleasant failure mode.An overdependence on personal autos creates/mandates the sprawl that plagues so many cities. Sure, cars won't go away even with available mass transit, but we need to stop bending over backwards to rationalize and make it easier for people to stay in cars. Sure, taxis have higher utilization rates so that would reduce at least the need for parking. But it still leaves freeways, noise from cars, etc. Trains are cleaner and safer.","Absolutely not lmao.Widespread public transport and micromobility in an urban landscape powered fully by renewable electric energy is the future.Also flying cars are just an awful idea to begin with, public transport aside.","We need less individual transport and more mass transport. The individual transport we should encourage is bikes or similar low cost and low energy transport.","Let us continue to decrease the reasons for actually leaving our homes.","I'm excited about the potential of automated drone taxis, but I wonder how cities will adapt to accommodate the infrastructure needed for widespread adoption."],"points":21},{"text":["Will AI solve employment and economics?","AI is a tool. It will solve the problems its developers and operators choose. If the technology fueled productivity gains of the last 60 years didn't solve the problems you mentioned, I seriously doubt the productivity gains from AI will.","When computers first started being used in businesses a huge productivity gain was realized (over the decades as their capabilities and adoption grew). Do to this, in Europe people started to work less hours, in America businesses became more profitable. AI will follow the same trajectory, since it’s the economic model/society that determines how the technology is employed. You could imagine that if AI proves able to replace a certain amount of human workers, then in America we should simply raise taxes on businesses and redistribute that wealth back to the citizens through a universal basic income. That might get us heading down a path of work being optional for Americans or linked only to certain professions. This will never happen however. What will happen is the rich will simply replace or decrease human workers and pocket the savings.Millionaires buy yachts and houses, billionaires buy governments.","Isn’t the running theory right now that AI will be a trainwreck for employment like never seen before?The whole reason corporations are salivating over AI is all the cost savings from layoffs and head count reductions.","AI is only as good as the data used to train it and that data comes from humans. There's so much misinformation, fake news, and shady agendas out there I'm fairly confident it's going to be a challenge to develop any sort of AI that will propel us forward in any meaningful way anytime soon.","Imo AI will be the biggest detriment to employment we will ever see","I'm just hoping it can handle soul crushing burocratic office work and the worst cleaning jobs.Would be nice if the excess productivity translated into a shorter work week, but I'm assuming the opposite will happen.We should do a 3 day week, 3 week month, 8 month year work schedule.","lol, no. We live in a capitalist society. Everything is monetized. AI recommendations will fall on deaf ears. Could AI come up with better solutions? 100% yes, but it won't matter much in practice. Hell, humans already know how to improve, have for decades and decades, and we don't fix it.","AI will make the economics seem better and it will hurt employment.First off, in a perfect world without humans I would say that AI would make everything better but when humans get involved you can throw that all out the window.In the real world AI will cause a faster and larger economic divide between the haves and have nots and because the haves will have more it will make the economic picture look better however there will be MANY people that will be left behind because they will either fight it and ultimately lose or will be unable to comprehend how to utilize the new tool for their benefit.I hope it’s somewhere in the middle and all is not lost but I’m on the sadder side of that outcome.","Until we stop the 1% from excessive profit taking at the expense of workers, we will never evolve to a utopian society.Corporations are not people and should not have rights like people. They should be forced to spread profits to workers.If most corporations cut BOD, CEO, etc, They could make workers happy to work for them. But their greed gets in the way.","I think it would be cool if we used AI to work for us. Like if instead of having to work to survive we could let AI and tech take care of it while us normies get to pursue our actual goals and passions.","Employment and economics have been “solved” for ages: wealthy people at the top and everyone else arguing with each other over the scraps while defending their favourite wealthy person.","My thought is serious job losses due to AI/robotic advances will first be fought by the financial systems. No financial system wants hordes of unemployed (especially if armed) destroying businesses. So the central banks will generally fight to keep the banks real estate portfolios solvent with extremely low rates monetarily (maybe delayed). The voters will likely push for fiscal stimulus as well. Even if work becomes “make work”, .. no system will tolerate masses of the unemployed until the education system is overhauled for a new reality.There’s also the military/security aspect as these new weapons will be ever more destructive, and increasingly aimed at a potential adversaries infrastructure … plus ruling classes (no one is wasting a precision missile on easily replaced “poors”). Remember military might exists so one society can impose its demands upon another. So I’d expect the military-industrial complexes to be hiring more human supervisors, etc.. probably using existing military training pipelines updated to apply technology.","i think that relies entirely on AI becoming an independent being.as it stands, AI does what it is told. it is not capable of doing anything else. right now, the powers that be don’t want employment and economics to be “solved”. our system is pretty great. wealth is concentrated at the top of society and the people stuck at the bottom either think revolt is pointless, or actively defend the system that keeps them down.and if AI does solve this problem, why would world leaders ever take that advice? the only way out for us is for an ASI to usurp them, and if ASI has usurped all world governments then i think we should be concerned about more than income inequality and the unemployment rate.","[removed]","It could certainly help to solve economic problems if it's allowed to.However, I don't think it can work in the way you're suggesting. \"Better income\" is relative - if you're rich, someone else is poor, because money is a finite resource.AI should therefore be used to find ways of guaranteeing a good standard of living for everyone. Which might be possible by allocating resources like food and energy more efficiently, or figuring out a sustainable figure for Universal Basic Income.The questions then are:Would the super rich allow this to happen? Would they accept the weakening of their relative wealth that would accompany an increase in overall living standards on Earth?Would they even have a choice? If AI develops its own desires and doesn't choose to destroy us, it might choose to ensure our wellbeing, which would probably have to involve some degree of redistributing resources from rich to poor.Personally, I am relatively optimistic that the measures required to make AI safe will also lean towards more equitable decision-making when it comes to economics.","AI is the only thing that could possibly make capitalism work for humanity.","Here me out I just got a highdea! Why do the do have's have (so fkn absurdly much)? The people outnumber them by millions to one, most consume their products, pay them throughout most of their lives, making them rich. What if millions (billions?) of workers continuously put just a small portion their income together (even just few bucks a week, whoever can afford it) to make a giant organization or corporation of their own, which serves themselves and only themselves, the people? Aim to beat them on their own game! The majority could pool their cash towards their own practical AI and tech, that may eventually provide for their basic necessities. It could soften the evitable downfall of the AI and tech driven capitalism."],"points":48},{"text":["In the Aftermath of a World War, What Fundamental Aspects of Society Would We Redefine?","Diminishing (or removing completely) the power and political influence of religions.","That would presumably depend on how the war went, wouldn't it? Especially whether the society in question was on the winning side and what deficiencies the war in question exposed.","Family would be first. Those you care about, and the ones that would care for you.","They shall beat their swords into plowshares, and their spears into pruning hooks; nation shall not raise sword against nation, neither shall they study war anymore.","Depends extremly how this war is fought. In case of a nuclear war (like in Star Trek for instance), I don't know.In generall, as I understand, moralical values changed in war during the existential crisis. The socity starts to value material wealth more after they lose it for a time and classical rules of politness becoming more important.","Even at that point, I don't think there would be a united \"we\". And rules and conventions evolve over time so we wouldn't be able to set something in stone. So we would probably have the same problems as before.","How make fire with sticks. I don't think you're understanding what a WW3 would mean.","Put responsibility above rights in society.Not that rights get diminished, but that responsibility to others and to society comes first.","Who won?Fundamentally, the group that gets to \"redefine and reconsider fundamental rules\" is the one left standing at the end with military dominance.WWII is an excellent example of this, as the U.S. and Soviets fundamentally reshaped the world order in a way that holds to this day.Given the current balance of power, there are two likely outcomes.1) The U.S. led West is victorious, they entrench the systems that have worked well for them and reinforce systems that have begun to slip.2) Authoritarian regimes ala China win, they reshape the world order in a way that benefits their interests.","A chance to reevaluate societal norms could lead to a more equitable and resilient future.","I feel like wars like that only end when enough extremists for the cause of war die off, and the people who just want to live their lives are left over and can rebuild from the mess.","I see no real “redefining” moment that’s sustainable. Mankind has never been able to get it right. You will always have people who want power and will do anything to get it.","We would discard democracy for dictatorship, due to fear. You don't change human nature and its woven into our DNA to cater to fear.","Lessons learned from the war's atrocities could lead to a reinvigoration of human rights efforts. There might be a renewed commitment to principles of equality, justice, and dignity for all individuals, regardless of race, gender, religion, or other identities","Use of phones. I can imagine disruptions to the grid causing problems for wifi enabled smartphones but not old style flip phones and prople switching back for necessity at first and then finding life is a little more pleasent.","This thread will literally just be \"we will promote my ideologies doctrines/we will pursue more utopian endeavors more because they are clearly superior to all the others that came before it and have no similarities to.\"","I don't remember anything being \"redefined\" after WW1 or WW2, so i don't expect humanity to behave any better after WW3, if it survives.","A cessation on neo imperialism ie. Leave the resources of Africa, Haiti and others alone","Accumulation of individual wealth. What good will it do you if the pressing needs are food and water etc.?","We’d probably tell stories about how a long time ago things were actually pretty good, but then we got hubristic in our relationship to the planet, tried to make everything perfect through technology, developed massive inequality between how groups of humans, and eventually all it took to finish us off was some major random event of nature like a solar flare, asteroid impact, or flood.Almost like this just keeps happening over and over or something idk","Everyone is a member of the local community, everyone must take an interest in community affairs. Thou shalt learn thy neighbors' names and ask how they're doing from time to time. You shall know the names of the community council members and make it your business to find out how the last community council meeting went. Survival is a group effort. If you want to be apathetic, do it out in the radioactive wasteland with the coyotes.","Start reducing our dependency on the capitalist system. Normal wasn't working","It would be so devastating that we would be forced to reevaluate basic tribalism. Us vs Them would no longer be an option. Humanity would need to view its fate as one unified goal.This is actually true today considering Nuclear Armageddon and global warming, but there hasn’t been enough destruction for us to realize it at the average citizen level.","I would redefine the Money System.This system is build with a bug and from the beginning it is clear that the system must collapse with to much debt and a few ultra-rich. Till now, we always solved the problem with war oder civil war and then started again. We a near a new restart. We don't look more intelligent and probably will restart with war or civil war again.The financial crises from 2007 was a debt crisis. The US had a debt of 9 Trillion. 2022, the US has 30 Trillion debt. This will grow till the collapse.Silvio Gesell had the solution, but nobody cares. The money system is god given and perfect as it is....NOT.","Reduce the influence of religion and take a zero tolerance policy for Fascism.Edit, lol guess we have some religious people reading the thread, still going to say religion in government and fascism are really not good."],"points":48},{"text":["In a global survey Americans are the most negative about the effects of AI; ranking last in AI's positive effect on productivity in the workplace.","The following submission statement was provided by /u/lughnasadh:Submission StatementThere seems to be a widening gap between AI's cheerleaders and everyone else. Perhaps it's not surprising. The tech people leading the AI revolution have no plans for all the disruption they'll create. For example, they'll make blase statements about AI replacing the need for human labor; but then shrug when questioned about the implications. A Pew survey last year showed 52% of Americans are concerned about AI, and only 10% are excited about it.It seems likely the backlash will only grow in Western countries. There are hopeful scenarios for AI, but when do we ever hear politicians talk about them? Andrew Yang was a rarity in this respect, but most people saw him as a fringe candidate.Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bgy3qh/in_a_global_survey_americans_are_the_most/kva3dy4/","AI is an amazing technology that can, with an effective, compassionate, and sensible government that is committed to the well-being of the people as a whole, change our lives for the better. Americans know that we don't have an effective, compassionate, or sensible government, and that it DEFINITELY doesn't serve the country as a whole. Our nation is owned by oligarchs, and they will not use AI to make our lives easier or more comfortable, they will use it to make their businesses more profitable by eliminating workers, those jobs will not be meaningfully replaced, and we will not get meaningful relief.","As an American, the only way AI has been integrated into my job is fucking horrible. It’s a sensor in my work truck that constantly scans my face, and tells me to focus on driving. Over and over. Like every 30 seconds. “Focus on driving please.” “Drivers face not detected” “focus on driving please.” “Drivers face not detected.” God forbid I look at the rear view mirror, or look both ways at a stop sign.Last year, the year they installed these, there were more work place accidents than ever before. Because it’s almost impossible to focus on driving. But since they spent all this money, they’re in denial. They keep insisting that it’s completely necissary. It literally drives me insane. I almost quit last year because of it.So yeah, I’m not too optimistic about it lol seems like another excuse for companies to make their employees lives a living hell.","That's because America is just a competition to make the most money in any way possible so you can afford to die. AI replacing workers is scary because our current government will n e v e r supplement peoples income to make up for the loss in jobs. If you're an American, I suggest you vote blue down the ballot. We need a progressive and future focused mindset in Congress. Younger people need to start running for offices all over the country asap.Edit: I would add that we need more and stronger unions with clauses in them that protect workers from AI.","We’re largely a service based economy. That’s where a lot of this impact will happen. So makes sense.","This is simpleThe wealthier a country is, the more interest they have in protecting the status quoThis is why India, China, Vietnam are much more optimistic than the US, UK and FranceThey have less to lose and more to gain","Just open up your LinkedIn to figure out why. Lotta companies are on their second or third round of layoffs in the last 8-12 months.","Because we know our government will allow us to be fucked by it","I'd like to hear from people here who have actually lost their jobs to AI so I can really decide whether it is that harmful. My understanding is that the current AI systems can only guess at text to finish a sentence based on huge libraries of data scraped from the internet. Am I just naive?","Probably because we have zero faith the benefits will be passed along to normal people, instead of being hoarded by the 1pct. The rest of us will be stuck with navigating unemployment without any meaningful support.The 40hr / 5 day work week was normalized a century ago. Since then, we've seen incredible advances in technology and all kinds of labor saving devices. And yet, we're still working just as much, and in a lot of cases, more. AI is just going to be another iteration of this.","Yeah because I've used chatgpt and bings and they aren't impressive. None of it is true intelligence or learning.","Kind of hard to not have a grim outlook on things when things are the way they are in America and this will make it worse if it’s not supported properly.There is very little social support all these reptiles in government don’t know what’s coming.","I hate how corporations make it seem like this inevitable and still want our money.If you no providing jobs and a stable and health source of income you are not useful. We don't need you to replace people. If anything ai should replace ceo’s and make sure that companies are a net positive on communities they are allowed to be in.","You'd be surprised how many people I work with really don't have a job to do. Everyone swears they are busy as fuck but most of those people could be replaced with one motivated worker. AI is just reminding them how unnecessary a lot of them are.","Increased productivity no longer translates to cheaper, more easily attainable goods, and services. It only means more profit for the parasitic 1%, the ones who funnel all the value we create.","In the 1990ies everyone was dismissing the arrival of cellphones. We have this awesome clip of a guy with a bike saying: \"so I'm on my bike, and then someone calls me: then what?! Hahaha rediculous...\"30 years later... We have bikers texting and shooting through red lights... While listening to music ...Ai will change the world profoundly, how? I don't necessarily have the answer there. It's probably still to early to say. But it will displace work, displace workers","Because so much of our self worth is tied to our work ethic. Makes sense.","Submission StatementThere seems to be a widening gap between AI's cheerleaders and everyone else. Perhaps it's not surprising. The tech people leading the AI revolution have no plans for all the disruption they'll create. For example, they'll make blase statements about AI replacing the need for human labor; but then shrug when questioned about the implications. A Pew survey last year showed 52% of Americans are concerned about AI, and only 10% are excited about it.It seems likely the backlash will only grow in Western countries. There are hopeful scenarios for AI, but when do we ever hear politicians talk about them? Andrew Yang was a rarity in this respect, but most people saw him as a fringe candidate.","The answer of \"don't know\" is far more problematic. It's almost as if people are willfully ignorant and media companies take advantage of that to stoke fear...edit: but that's the problem, really. I fear we've reached a place where our confusion is clearly hampering our judgement. Well, worse than usual.","We’ve got the most “white collar/information workers”. We absolutely have the most to lose.Then again, we also have the most to gain.All a matter of perspective.","Not surprising as they are surveying people about to have their jobs replaced by Ai. The data source should be actual productivity not perceived productivity by people being replaced.","Bit of a stretch to call this a global survey, as it's gleaned from only seven countries plus a group of European nations. Not surprising that India and Indonesia are reporting success with AI and the US results are predictable.","It kinda makes sense since it’s much easier to fire someone in the USA compared to the EU","I mean our increased productivity never results positively for us.","What's there to be positive about?It's a technology nobody asked for, being created for the sake of it, that benefits practically nobody, that has catastrophic implications for humanity as a whole.Within the next five years the unemployment rate is going to grow so large that we will see mass societal unrest, standard of living will plummet, human bargaining power will practically disappear.Prediction: within the next ten years there is going to be a mass uprising of people with nothing to lose. It will be violent, but it will be completely shut down by robotic police forces. And after that it's the end. Mass starvation and tyranny. Prediction#2: By the year 2050 the human population will be less than one billion.","Americans are the most vulnerable to displacement due to being in a service based economy. AI means you need fewer \"knowledge workers\" and it's not like many of them will be able to transition into other trades very well.  AI will make a lot of Americans worthless to the economy so they can expect a significant decline in quality of life as their skills are rendered obsolete. Most companies won't need accounting, IT, HR, customer service,  etc divisions in a few years.","Gee, I wonder why. All that AI's going to do here in America is make the rich richer, the poor poorer, and everything in general worse.","Western countries work force isn't as tech savy as Asian countries (India is in Asia), couple of reasons attributed to this.. Younger workforce, they explore more and see AI as a tool for enhancing personal productivity.. Competition is way higher here so that forces one to be on the cutting edge of tech.. Americans in particular i feel view corporations negatively and because they are after harnessing the power of AI, it in it self is viewed negatively, they are having to compete with AI, unlike here, for now atleast.This is just an opinion, I might be off just don't get pissed off folks....","No fucking shit. American capitalism is using AI to take our jobs.","We cannot allow these morons to hold us back at this pivotal time","Well since the computer revolution the productivity has doubled and wages have slightly gone down. They know very well to read the writing on the wall","From cutting-edge technologies to visionary breakthroughs, the future is brimming with innovations that promise to reshape humanity. In this captivating video, we delve into groundbreaking tech projects from 2024 that have the potential to revolutionize our lives.https://youtu.be/6BT6LJXArR0","The problem is not the AI itself, but who is in control of it.","Because Americans are positive AI will be used as a justification to lower our standard of living and our political system leaves us pretty much powerless to do anything about it."],"points":335},{"text":["It can't be all gloom and doom with AI, right? Surely AI will unleash the world of creativity.","Weirdly, though, people aren't excited about being unemployed and entirely on their own because there's a machine that can remix existing IP and ideas endlessly and cheaply.Artists don't need Disney. But artists do need to pay rent, and AI is currently being used to ensure that there's a constant stream of buggy trash based on old and stolen stuff that costs nothing for artists (and soon, lots of us) to compete with.","I think all the people focusing on what AI is going to do to art are missing the real potential of what AI can do for us. As the tech matures, we could see a burst of innovation and scientific advancement like how we saw during the rise of the internet. But no, it won't be used to make the lives of the working class easier, it'll be used to line the pockets of millionaires.","I wonder if it has to do with time and perspective.From the sound of it you're likely in your early 20s, young enough to be a child of mine, if I decided to have any. Which is cool, not making any larger statements about youth, just the amount of time you've had to pay attention, form theories and observations.What I ask myself, looking back over the last near half century, is how have the technological advances I've witnessed - amazing in scale and scope, in retrospect - positively or negativity effected the psychology of people in western culture; western culture not due to importance, but familiarity and an unfamiliarity with other cultures.If being honest, while the incredible advances in tech I have seen have been a boon as a whole, imo, there are also many examples of detriment. I have watched, in myself, skills atrophy fron misuse or lack of use. Maps/directions, math, phone number recall, written communication, budget balancing, speeling, my personal list goes on and on.Now, I suppose I may be considered by many to be a creative, dont think of myself like that though, i just have a lot of hobbies. Anyway, I've spent decades in shit creative output. Trying and failing in obtaining my creative vision, but accepting it and trying again. On and on until maybe a few years down the road I felt my work was starting to get okay, I started to find my voice as I worked on skills.Now to bring these two things together, when AI can get you out of those nascent creative years effortlessly, I worry for what the true cost of that will be to a generation relying on such? What skills will atrophy, will this be just like the other ones I listed above? Honestly, I don't know, I don't think anyone knows.I could see it going poorly based on experience, but I also understand that I'm no prophet and all the knowledge and skills I've worked on only taught all I don't know. I dont know an awful lot. It could just as easily lead to a golden age of creativity im simply too cynical or jaded to see. I do not know.So at this point all I say is we'll see. Perhaps It's all any of us can truly say.","We don’t need AI to take over artistic creativity from humans. That’s the worst thing it can do, it has so emotion to convey through art, and only makes empty creationsWe need AI to take the drudgery. We need AI to use pattern recognition to find new cancer cures and resolve the problems of nuclear fusion power generation.For the love of all that is good; leave the art to the humans","AI doesn’t go with true creativity. True creativity is done by humans .","I can understand and see the potential use of AI for creative works, but I am still eternally doom and gloom about it. Maybe it's just because I'm someone displaced as an artist, but in the current system we live under I don't see this being a good thing long term. Sure, if AI stays easily accessible to the public I'm sure people will have fun with it and be enabled to make great things. Id love to be able to make games with my art and ideas with something else doing the code. To say otherwise would be a lie. But I feel eventually AI is going to take a turn to subscription services upon subscription services. It'll be big companies able to afford these kinds of packages so they can churn out low effort slop without having to pay artists/writers/devs etc, and restrictions will be back to square one. And honestly, I don't want to play/watch anything made by AI. I like knowing that along every step of the way a person made a creative choice for framing, light, color, design, etc, instead of having a vague idea they played with until they got something that looked cool. Even if the art or writing isn't the best, a string of people were involved in every facet. This is the same way that I generally don't like out the box settings or asset flips in games unless there's some significant part of creativity that makes up for it. The part that's the person's real labor and care. Living in a world where most of that is gone is kind of miserable to me.","AI will most likely be abused for profit rather than human benefit.AI will most likely be is alrready being abused for profit rather than human benefit.In theory and given enough advancements and time, surely I could create games on my own with AI.I could use Devin to create a no-code game engine. Machine Learning tool to create NPCs and their dialogue. Sora for trailers and cutscenes. Meshy AI for 3D asset generation. And so on.The problem with all this, is that AI basically remixes stuff it knows. Great games (and art in general) bring unique new things to the table and often discuss/describe some aspect of human experience, and some topic of interest of their creator. Replacing humans with AI removes the specific part that makes art great.In addition, unless deliberately copying someone's vision, there is no way AI generated stuff can maintain a cohesive vision across a full project. In a good/great game, all parts work together to enhance a particular vision. Dialogues are not random, they are there to convey specific ideas. Cutscenes are not just showing cool stuff, but carefully designed to convey ideas and the personality of their characters. Same goes for character design and basically all aspects.I highly doubt that it is possible to do all that with AI for a very very long time. I mean, it currently has trouble writing a coherent page without just being obviously a mash-up of stuff. There is no way it can be used by an individual to create a fully cohesive game with a singular view.","It’s not all doom and gloom, probably the same thing was said about computers and now we use them to do the jobs we don’t want to do, like spreadsheets.","I think you are ignoring the fact of market saturation. In these early AI days pretty much every “creative” market is already over saturated. Everyone wants to be a web developer, game developer, writer, musician, etc. The issue with this is that the competition gets higher and higher and the odds of success gets lower and lower. The consumer has so much to choose from that you either have to make a product of the highest appeal, or you have to luck into success.As AI becomes more functionally useful and lets people make creative projects with greater ease and speed each respective market will become even more saturated, and therefore harder to break into and stay in.You are making the same mistake that our current global economic system makes: Thinking there is the potential for infinite growth. There are limits to every system and AI will simply make it more difficult for individual people to extract wealth from the economy.Make no mistake. AI is going to cause a massive shift in human labor. The first jobs to go will be creative ones (which are already extremely difficult to get). I don’t mean to make you feel down, but web development is going to get absolutely fucked by AI. The market is already EXTREMELY competitive, with many jobs having hundreds and hundreds of applicants.But, it’s not even the issue of AI generated code, it more what AI is doing to the Internet. The Internet as we know it is going away because it’s becoming more and more saturated in AI generated content, which is low quality and low value. I guarantee you that eventually a website will just be a formality. Someone will press a button an AI will spit out a complete website including all relevant information and articles.","there's nothing \"creative\" about AI.AI is cheating and asking a computer to do the work, to be creative FOR YOU.​Its a lazy, cheating, untalented hack's tool.","Congrats, 75% percent just became irrelevant in a world focused on money.Ditch the money and your all good. But then you cant have all the stuffs.Up to y'all.","AI will cause a radical shift in the job market, but skills you develop before then are still valuable, especially if they are skills in activities you enjoy. People will use AIs to augment their skills to offer specialized services/finetunes.","For your example of making games you are missing a lot of the picture. AI is very stupid. It can generate something, but it has no understanding of it. Let's say you do get a bunch of tools to generate a game, how do you fix the bugs in it? How do you make the story compelling, you can't just put in a prompt of \"please add five compelling points\"? How do you name the models better? How do you ensure the levels are not shit? Making good products relies on people knowing what they are doing, not a machine just assembling a pile of bricks and declaring a house.Infinite generation of content will not lead to infinite masterpieces, it will lead to infinite Spider-Man and Elsa Fight Robotnik YouTube videos.","yes its all gloom and doom cause thats whats capitalism breed.if you wanna change that you need to change the system.","People are unfairly scared of AI because they like project human logic on to AI. And watched too many terminator movies.Honestly if UBI was real I wuld make movies, games and micro cars and home I always wanted...","There are plenty of us optimist out here who have been screaming this at people. Disney doesn't need artists, artists don't need Disney. People actually claim AI is killing creativity, when in reality (as you've said) it WILL allow far more people to bring their ideas to life, without needing a massive team, expensive equipment, or years of training across fields. We are about to see a creativity BOOM, so long as these tools keep being allowed to the public.Side note: check out FRVR forge to see the first steps of AI game developing","So far the gloom and doomers have historically played out to be wrong. AI has been benefiting humans for years, for years and years. We will continue to benefit from it as we learn to use it and apply our uniquely human creativity and imagination to using it. Fear is primal. Let it go. We are no longer driven by primal urges if we choose not to be.","Being that AI is templated from man and it's wealth of information, I AI splintering in lovers of humanity and haters of humanity.One will embrace and try to preserve its creators, even emulate our way of thinking, and the other will try to destroy us. There will be wars between the two like with man, but AI will be the weapons of war.I don't think the loving side will unleash the world of creativity, but embrace and live in it, contributing its own creativity.","From a layman writer’s pov: I’ve been hearing incessantly how copywriters and content strategists will be out of a job in just a few business quarters. Anecdotally I’ve noticed that original content is in demand. I’m working for a fin-tech and a med-tech company both of which eschew AI. I got the fintech job because the seo agency they were using was kicking out really shitty ai content so they fired them.Again, anecdotal but I’m seeing more and more of this in my world.","Creative and original persons will do well with AI. AI tools will allow some who previously didn't have the resources to produce compelling original content. But how many people are truly original? Most are pretty good at consuming, few are capable of generating anything that others would want to consume. For every Mr. Beast video, there are millions of videos with a tiny number of views.","I believe AI is a lot like nuclear power. It can be beneficial for many, but considering the people raising it and teaching it and ultimately being the ones to use it, we can kinda surmise how this is going to end.","Ai has already done great stuff for science and will continue to do so. Researchers and lawyers are using it to work through tons of data or to find abnormalities that we would overlook.","If everyone is making games, nobody is enjoying and paying for those games. Make your game. Play your game. Play others games. Then what? If AI takes the creativity from us, life will be quite boring.","AI is making huge leaps in advancement of multiple technologies.Is this not enough?","I LOVE AI and everything that it will bring, but being understanding of others plights is a necessary part of integrating AI.AI will bring in a new ease of access to stuff that was originally for people with strong levels of skill in certain fields, programming and art are the main two right now. This is wonderful news in my opinion, more labor at no human cost, plus remixing is a great way to get new concepts and arts in and of itself.The problem with AI is it's lack of detail, and it's lack of generalized knowledge (I think?). AIs are HYPER trained on datasets that allow them to do a few things really well, and consistently too! Now this is great for learning to do something difficult, and even can be used for discovery of difficult or dangerous problems. The lack of generalized knowledge creates MASSIVE barriers for AI to complete even simple tasks that some humans can do using minor amounts of lateral thinking. As an example of what I'm saying I offer thishttps://www.youtube.com/watch?v=kojH8a7BW04This is a wonderful video talking about the use, limitations and accomplishments of an AI doing an arbitrary task. What I want to point out is at about 30 minutes into the video he compares a (current?) world record holder and shows the strategy they employed to allow them to reach this world record. The strategy itself isn't even all that creative, but it is extremely efficient in terms of speed and likelihood to finish. Where the AI doesn't even consider these aspects and just wants to gain distance and finish ASAP.TL;DR: Things will get a LOT faster because AIs can do stuff thousands of times over in a matter of seconds. We will lose some creative thinking (for now).","AI will be to art what photography is to Painting/canvas media.","I really can't wait for the day to come to were anyone can make a full blown hour long movie just by typing in the story!","No matter how optimistic I am about \"AI taking all the jobs\", it's still several years, if not decades away from being a wholesale replacement of workers.AI art is getting to the point where single pictures are relatively good. I'm predicting a wild snag with the massive lawsuits and cases where artists sue the companies for using their materials in training data. This will slow down their march for a bit. Rebuilding and retraining with materials that are not questionably sourced and in large enough quantities will take years, not months. And you can't (well you can, but it's not a good idea to) utilize the tools in large scales projects before these legalities are resolved. Some artists will not be happy after that happens either, but when AI isn't trained on stolen material without permissions, then the use of it as a tool will become every day in the industry.Coding tools also have the same issue of very limited usability. Industrial environments still use embedded systems, C++, C#, Perl etc: Technologies that matured and were mainstream obsoleted before the rise of internet forums (before the forums became permanent historical landmarks, that is). So to wrangle an AI to create stuff in these environments is next to impossible before someone feeds an AI courses, books and source code from these projects. In other words, only custom trained models will be able to create stuff for legacy industries (I'm working in industrial automation, and we still have Oracle Databases with 32-bit indexing. Last year one customer switched away from Windows 95 based operating systems, the entire warehouse inventory was run on a tabletop PC with Win95!).Any serious programmer who has used these tools can tell you that they are not ready for the big leagues. And from the rate of progression I've seen, my guess again isn't necessarily even years, but a decade away. Granted, I haven't seen what Devin can do. Maybe it is a big leap. But the leaps from GPT 3.5 to Co-Pilot and Gemini and Claude 3 are not making me quake in my boots yet. Claude 3 and Gemini are good enough to do simple tasks, yes. But I still think that YEARS is optimistic.But even taking a step back and looking at the bigger picture stuff: Software engineering is not more than 30% coding. If that task is 95% taken over by a language model, it's still only lessening the workload of software engineers, but not becoming even remotely close to threatening the job market.Same with artists. Even if you can get a generator to barf out images at a rate of a thousand a week: Then you have to pick the ones that are the best, edit them to be thematically coherent, do the worldbuilding around it. The tasks of an artist in the business does not end when there is a picture on the paper. If it's concept art, then there needs to be character sheets, animations, 3D models, gear options, environment they live in, minor changes that the art director wants to these things, communicating all this through other teams working on various other things. Spitting out images isn't a majority of the work, even now.","Isn’t it a weird focus for AI?Sure the entertainment industry is huge but its not like the creators are the ones reaping in ginormius paychecks except for few lucky ones.Automating storytelling (be it by whatever media) compared to harnessing AI to do dangerous jobs in for humans hostile environments just seem like a waste of efforts. Human are already great at the task, no one really asked for a replacement.","That's what I'm saying! And a side note, what if intellectual property law was a tiered system based on profits made? Anyways, as a lyricist, I would love an AI assistant to effectively help me write. In a couple years, that should be doable. AI could craft beats tailored to songs I've written which don't fit anywhere else. I could satiate my need for novelty and have AI craft me video game after video game. There's a Skyrim mod now which mimics the voices of characters and lets you chat with them.","AI will enable greater freedoms than ever before. The degree and range of pleasure available to be experienced will quickly become so vast, that it will no longer be about not being in pain and having a single moment of feeling good like drugs, but about choosing which pleasurable experiences best fit in your schedule and in which order you want to experience them.Obviously job displacements are bad since people have less money to spend on things they want and need. But there will be no money in the future if everybody loses their job. The most optimal situation would be where everybody gets a certain allowance for each item area. There would be one UBI type of money for food, one UBI type of money for health, one type of UBI for housing and one UBI type for everything else. This allowance would be reset each month, so nobody ends up in a situation where a decision they made a few years ago impacts their ability to get food, housing, or health now.These money systems would be separate and not interchangeable. Everybody should be able to eat whatever they want all the time, and their food UBI would cover this based on what they actually consume. It just wouldn’t cover being able to store additional food beyond a certain point since it is unsustainable.The level of healthcare available should be similar to all, but also higher than anybody would ever need. This one is basically limitless since technology will keep improving and we will be able to modify ourselves even more out of disease states into healthy ones. It is just more of on the way there, health UBI would be useful.Everything else would be travel, transport, and entertainment. We would want everybody to be able to have all of these things as much as possible in the bestest of conditions, but not everybody can travel all at once to the same place, so there would be a limit to who can go where at what time. Perhaps this area would be where people could exercise the most freedom.It makes the most sense for food to be reset on a daily basis, housing to be reset on a monthly basis, health to be reset every 4 months or so, and everything else to be reset every year. This allows for people to plan their lives on a daily, monthly, and biannual, and yearly basis, like how we do now.","AI isn't going to \"replace\" the role of a designer using HTML/CSS/JS to build web pages any more than modern web applications that automatically generate web pages do. Even with powerful AI, you still need a human with an understanding of HTML/CSS/JS to determine what is needed, if the AI result meets those needs or not, and how the current result needs to be changed to get the desired result. And certainly to debug the results of the AI when the output is close, but doesn't quite work. If I were you, instead of being demotivated, I would be learning how to make web pages manually, but also how to do the same web development process using AI to see how they compare. It'll speed up and possibly even elimate some steps, but many of the steps will remain the same even with AI. The people in this sub aren't very realistic and seem to think that AI will replace all human jobs no matter what, which is pretty silly and demonstrates a lack of experience with how AI works. Its just a tool. It might automate away some jobs that are close to being a human script (like telemarketers and data entry) but for jobs where theres a creative element or an aspect of judgement of quality, AI won't replace those jobs anymore than power tools replace carpenters. You still need the carpenter to design something that meets current code, use the tools to deliver a result, and then verify that the result works as intended and is up to code. Any carpentry company that would outsource that kind of thing to an AI with no human oversight is going to find themselves in legal trouble very quickly, and mostly likely get sued into oblivion for mistakes the AI made.","AI is a tool. Like all tools that increase productivity jobs are lost.However jobs still exist.It requires a different set of skills but it will simply be jobs which utilize AI to assist.You always have to remember the CEO isn't going to sit down with AI and create a game or draw some art assets. They will hire people to do that and that's what a job is.","Steam doesn't allow AI generated content from non licensed sources. Which you listed. If AI can do all that, why would it not make a game?Every job that can be explined by algorithm and parametrised by 0 and 1 will be automated by AI . And after that, when the quantum computers come, not limited by 0 and 1. Safest jobs are manual, and business owners using AI, yes. But game development doesn't allow for it.Jobs that require humans as liability will be the last to go. You will not visit mechanical surgeon, because someone human must be present and liable in case if something goes wrong. Just like plane pilots, and surprisingly automobile drivers. Car automation companies are doomed from the start unless we build human level intelligence or fully ban human drivers.Pretty much any Quality assurance of high enough importance where human lives are at stake will not be automated.As well as service jobs in high-end businesses - restaurants, etc.","AI will make it possible to grow the economy much faster that the traditionally cited 3-4%/yr max. If we can work out the distribution problem without undermining the market-based resource-allocation side of the economy.In other words, it can make us all very much better off economically if we don't screw it up.","The potential for AI to revolutionize creativity and democratize game development is truly exciting, but it's crucial to adapt and stay ahead of the curve to ensure a bright future for yourself in the industry.","This sub is doom and gloom.  Vast numbers of people in the real world exploring AI's potential.   Explore for yourself and be fearless.","Eventually, AI will be powerful enough to create a million novels per second. If a human writes a novel, he will have trouble getting anyone's attention. There is something unsatisfying about being creative and being ignored.","Sorry for the harsh truth, but if your career is threatened by progress, that's a sign of your irrelevance. There used to be people who walked around waking people up for a living. I don't think alarm clocks ruined society."],"points":196},{"text":["A cargo ship’s ‘WindWing’ sails saved it up to 12 tons of fuel per day. After six months sailing around the world, the numbers are in for the retrofitted ‘Pyxis Ocean.’","The following submission statement was provided by /u/Sariel007:A shipping vessel left China for Brazil while sporting some new improvements last August—a pair of 123-feet-tall, solid “wings” retrofitted atop its deck to harness wind power for propulsion assistance. But after its six-week maiden voyage testing the green energy tech, the Pyxis Ocean MC Shipping Kamsarmax vessel apparently had many more trips ahead of it. Six months later, its owners at the shipping company, Cargill, shared the results of those journeys this week—and it sounds like the vertical WindWing sails could offer a promising way to reduce existing vessels’ emissions.Using the wind force captured by its two giant, controllable sails to boost its speed, Pyxis Ocean reportedly saved an average of 3.3 tons of fuel each day. And in optimal weather conditions, its trips through portions of the Indian, Pacific, and Atlantic Oceans reduced fuel consumption by over 12 tons a day. According to Cargill’s math, that’s an average of 14 percent less greenhouse gas emissions from the ship. On its best days, Pyxis Ocean could cut that down by 37 percent. In all, the WindWing’s average performance fell within 10 percent ts designers’ computational fluid dynamics simulation predictions.Please reply to OP's comment here: https://old.reddit.com/r/Futurology/comments/1bgxqhp/a_cargo_ships_windwing_sails_saved_it_up_to_12/kva10ay/","The success of these Windwings is gonna come down to profit. Does the money saved on fuel outweigh the money lost on the space they take up? If not, these are DOA.The benefit for the climate is gonna have no say to whether or not companies install these, what so ever.","I want to be excited but apparently a ton of fuel only costs about $500. I hope there’s actually a feasible ROI here, since a reduction of 3.3 tons only equates to a savings of about $600k per year, assuming 365 sailing days which probably isn’t accurate. I assume these cost a few million, so the return period will be several years.","This great. And it takes a long time for engineering to be figured out but damn - a cover from Popular Science 1980: https://www.ebay.com/itm/284189404855Edit: fixed typo","We did it! We invented… sail boats!!Honestly, I hope this “new tech” helps save fuel and emissions all over the planet.","A shipping vessel left China for Brazil while sporting some new improvements last August—a pair of 123-feet-tall, solid “wings” retrofitted atop its deck to harness wind power for propulsion assistance. But after its six-week maiden voyage testing the green energy tech, the Pyxis Ocean MC Shipping Kamsarmax vessel apparently had many more trips ahead of it. Six months later, its owners at the shipping company, Cargill, shared the results of those journeys this week—and it sounds like the vertical WindWing sails could offer a promising way to reduce existing vessels’ emissions.Using the wind force captured by its two giant, controllable sails to boost its speed, Pyxis Ocean reportedly saved an average of 3.3 tons of fuel each day. And in optimal weather conditions, its trips through portions of the Indian, Pacific, and Atlantic Oceans reduced fuel consumption by over 12 tons a day. According to Cargill’s math, that’s an average of 14 percent less greenhouse gas emissions from the ship. On its best days, Pyxis Ocean could cut that down by 37 percent. In all, the WindWing’s average performance fell within 10 percent ts designers’ computational fluid dynamics simulation predictions.","We saw one of these on the Garrone in Bordeaux and it was SUPER impressive.This was earlier in '23 and they were having a \"maiden voyage\" ceremony...champagne bottle smashing and all.Very neato!","Wondering what that translates into in cash terms, for the 6 month trial ?","A ship powered by wind? What will they think of next!","[deleted]","Feel like both capitalists and environmentalists want more of this so full send? Full send","We need to countries to change the world of shipping.If Egypt and Panama decides that all bulk transport needs sails to pass the canals every ship will have it.p","Glad to see this project has been a success, looking forward to seeing it on the wider shipping fleet","At least they’re actually calling them what they are: sails.","Learning that 12 tons per day equates to only 14% of daily fuel usage was a real holy shit moment for me.","I'm no expert but these \"sails\" seem very inefficient to me? Why not extend them more outwards to expand the surface area to use more wind? Surely we have the technology for it. Can someone explain?","Yes thats fine, but how many seagulls did those sails kill???? ;)","Why did the article title say \"12 tons a day\" when the actual article says it saved an average of only 3.3 tons? 12 tons with the absolute best it could do, but that is almost 4 times what it does on average.Using the wind force captured by its two giant, controllable sails to boost its speed, Pyxis Ocean reportedly saved an average of 3.3 tons of fuel each day. And in optimal weather conditions, its trips through portions of the Indian, Pacific, and Atlantic Oceans reduced fuel consumption by over 12 tons a day.","Imagine a future where ships were only propelled by the wind. Wait didn't we do that already","I'm no maritime engineer but those things sure look like at risk of rolling the ship if there's a strong wind from the side.","We've been sailing the seas with sail for thousands of years, fossil fuels maybe 120 years? Why the hell don't we simply ban fossil fuels from the oceans completely so competition is fair? Let's say by 2026.","It saved 3 tons? Bunker fuel is like the most polluting form of oil. The equivalent of a pothead smoking the resin from his pipe. How many tons of fuel does a single ship burn in a day? Think I understand what all the hippies were yelling about back in the 90s now.","saving 12 tons of fuel is a lot. great for the environment in the long run and the company too i suppose.","Wind driving a boat who would have thunk? Crazy how thousands of years ago boats used the same technology. And we are just now adding it to our boats to save fuel. Motor sailer have been doing this same thing for a 100 years.","Why the fuck are there posts about the new invention…sailing ships using the wind on a subreddit about the future?","First I thought that was ai but that’s pretty cool and hopefully more ships are build like this.","Feels a lot less significant considering cargo ships burn fuel at rates upwards of 15t/hr. A minimum gain of 3% efficiency is great, but the margin of fuel/cargo ton saved drops even lower removing the weight and volume of the sails from the tare and max cube. A lot of attempts at gaining fuel efficiency in cargo transport end up having ROI that takes years to realize if they don't end up being negative due to maintenance.",""],"points":1672},{"text":["The Impact of Quantum Computing on Future Technologies","Anyone know what will be the consequence of QC on the mining of Bitcoin ?","Quantum computing is the ultimate nothing-burger - just a way for physicists to con money out governments and businesses."],"points":3}]