[{"text":["AI-Powered To-Do List Apps to Boost Your Productivity"],"points":0},{"text":["8 AI Tools Every Project Manager Needs In 2024"],"points":0},{"text":["My GTX 3090 Burning AI Candles in Hell makes my Soundcard sound like Bubblewrap.","Burning AI Candles in Hell = mining bitcoin, run stable diffusion, or RVC Training, etc."],"points":0},{"text":["AI tools to compare PDF","chatpdf"],"points":0},{"text":["Pa da pish.","It may be that everything beneath the quantum level is made of cheese."],"points":1},{"text":["AI Music Research Questions from an Undergraduate!"],"points":0},{"text":["DubbingAI making weird sounds?"],"points":0},{"text":["Any other real-time avatar streaming options?"],"points":0},{"text":["One-Minute Daily AI News 1/30/2024","Thanks for sharing"],"points":0},{"text":["What's a good AI tool that helps you compare travel destinations?"],"points":0},{"text":["best free ai question solver i can use on iphone."],"points":0},{"text":["Restarting My Life: Mastering A.I.","For some fun initial exploration, watch a bunch of youtube vids on free AI tools and try some of them out.For learning to use LLMs like chatGPT, you want to learn \"prompt engineering\", which is how to structure human language questions to the AI that result in the best answers. There are apparently even jobs for this. (one of my favorite playlists on this.)I'll let others advise you on image/animation/voice stuff, as I haven't spent much time on those.Regarding hardware, there are two general things AI uses hardware for - training new models on huge datasets, and running a model in an interface that allows humans to interact with it. Training requires immensely powerful and expensive hardware and you won't be doing any of that.However, running the model can be done either remotely or locally. Most AI apps run the model on their servers and provide a web or mobile app interface to it that you can use. They still require the internet though, but can be used with low-powered hardware.Alternatively, you can run the model locally on your own computer using various tools like GPT4All, and downloading models from the main public repository HuggingFace. See the subreddit /r/localllama for a large community exploring this. If this interests you, there are three criteria you want to look for in your computer hardware:Highest possible data bandwidth between RAM and CPU or GPULarge amount of RAM (or VRAM, which is RAM embedded on the GPU/video card)Highest performance GPU or CPUAs you've heard, the Nvidia 4090 GPU is the best consumer-level choice atm, but the 3090 is also capable. Alternatively, Apple's new M1, M2, M3 Apple Silicon Macs (Mini, Studio, MacBook Air/Pro) are also capable of running local LLMs (I've only tried text LLMs on mine, haven't tried image/video/audio stuff). Just make sure to get one of the Pro or Max models with maximum 400GB/s memory bandwidth (see tech specs page before buying), and at least 32GB of RAM (ideally 64GB though).Here are a few of the cheapest Apples capable of this:Refurbished Mac Studio Apple M1 Max Chip with 10‑Core CPU and 24‑Core GPU 32GB RAM (keyboard/mouse/monitor not included). $1529 (strongly recommend selecting the RAM upgrade to 64GB for +$350)Refurbished 14-inch MacBook Pro Apple M2 Max Chip with 12‑Core CPU and 30‑Core GPU 32GB RAM - Space Gray. $2339.Refurbished 14-inch MacBook Pro Apple M1 Max Chip with 10‑Core CPU and 32‑Core GPU 64GB RAM - Space Gray. $2899.For the Apples, it matters less whether it's M1, M2, or M3 or how many cores, and more whether it has more memory and the maximum 400GB/s memory<>CPU/GPU bandwidth. I strongly recommend at least 64GB Memory if you can afford it at all. Apple's new \"Apple Silicon\" CPU/GPU is so good it will last you 10yrs at least. If you run out of hard drive space during that time you can extend it with an external hard drive, so you can skimp on the hard drive cost up front. But you can't increase the memory/RAM, so it's good to splurge on that up front if at all possible. It will be worth it in the long run, and also in the short term if you want to do local AI stuff with it.","See GPT4’s response below. I think it’s ok. I’d add Synthesia or Murf. +1 descriptMY PROMPT: You are an expert in the business application of AI tools.What is the best tool, resource, and link to learn each of the following tasks in order to become an AI master? 1 chat gpt / AI bots  2 image generators like dalle or mindjourney etc  3 ai animations  4 ai voice creation / trainingANSWER: To become proficient in these areas of AI, it's important to access the right tools and resources for learning. Here's a guide for each task:Chat GPT / AI Bots:    - Tool: GPT-4 by OpenAI.    - Resource: OpenAI's official documentation and tutorials.    - Link for Learning: OpenAI's blog and documentation page (https://openai.com/blog/).Image Generators (like DALL-E or MindJourney):    - Tool: DALL-E by OpenAI, MindJourney, or similar.    - Resource: Online courses and tutorials focused on generative adversarial networks (GANs).    - Link for Learning: Websites like Coursera or Udemy offer courses on GANs, which are fundamental to understanding tools like DALL-E.AI Animations:    - Tool: Adobe's Character Animator or similar AI-based animation software.    - Resource: Online workshops or tutorials on AI-driven animation tools.    - Link for Learning: Websites like Skillshare or LinkedIn Learning have specific courses on AI animation techniques.AI Voice Creation / Training:    - Tool: Tools like Google's Text-to-Speech or similar.    - Resource: Comprehensive guides on speech synthesis and voice AI.    - Link for Learning: Google Cloud's Text-to-Speech documentation (https://cloud.google.com/text-to-speech/docs) provides a good starting point.Remember, mastering these tools not only requires understanding the software itself but also the underlying AI and machine learning concepts. Therefore, a combination of practical tool usage and theoretical learning is key.","Following","Ask this same question to chatgpt for a decent jumping off point. The tools are brain dead easy to use. Truthfully, even if you learn them, they're so easy to use that even this job market is going to be over saturated and competitive. I'd spend some time networking while learning.","Your Everyday AI podcast and newsletter has a lot of good stuff. It's free, and they offer a free ChatGPT course. I took it and found it helpful. Sometimes the podcast says in 30 min what could be said in 10, but I still learned a lot.https://www.youreverydayai.com/","Similar thoughts here - I'm turning 50 this year.I found lots of the free online courses (e.g. Coursera) around AI to be excellent quality.I've also returned to university, in my 3rd year of a part-time online Master of AI course.I feel like understanding the underlying mechanisms and maths will be more useful long term, as the tech is changing constantly and quickly.","First off, it's inspiring to see your determination to pivot and master AI technologies! For learning ChatGPT and AI bots, consider starting with online courses from Coursera or edX, which offer foundational to advanced lessons. For image generators like DALL-E or Mindjourney, check out their official documentation and tutorials on YouTube for practical insights.For AI animations and voice creation, Adobe offers some beginner-friendly tools, and platforms like Descript can be a good start for voice work. While a high-end GPU like the 4090 boosts performance for AI tasks, it's not strictly necessary for learning. Look for laptops with a decent GPU (like the NVIDIA RTX 3060 or above), a strong processor (i7 or Ryzen 7), and at least 16GB RAM for a balance between performance and cost. This setup should allow you to explore most AI tools without being tethered to a desktop.Remember, the tech is just a tool; your creativity and understanding of these platforms will be the real game-changer. Best of luck on your journey to becoming an AI master!","For any free local running voice cloning I would go with XTTS from coqui tts or styletts2 there’s a pip install for both","r/stablediffusion is funRandom link I grabbed but they have some great tutorials and I’ve had fun with automatic1111https://www.reddit.com/r/StableDiffusion/s/XER6dD063w","Your idea for \"master of Al\" is simply to use some applications that use AI under the covers to create images and audio. This is not much of an achievement and considering they are cloud based services you just need something that will connect to the Internet.You can also use something https://colab.research.google.com/ to do AI stuff like tensorflow, again you don't need anything other then something to connect to the Internet.Then we get to using the stuff coming from nvidia and PhotoshopAI and all the stuff coming out of Adobe, yes you need something powerful and soon as you add a GPU to a laptop the price goes way up. Desktops are way cheaper. But realise you are not becoming the \"master of AI\" you are just using software that under the covers that you will never see it may be using AI","IYH FWIW same generation, computer security field and same corporate realization and job going poof \"they quickly learned that Al can do all these things, not great but good enough and for almost no money.\"","Go for it!","I do not know jack about consumer behavior, I concede that argument all day long. \"How to become a master of Generative AI\", that is really what ya'll want to buy? You could have anything, that is what you choose? Just making sure. Posts like these and the fact they get upvoted right away leads me to believe these things are true and I am just an idiot for not seeing them.","Why ask people when you can just ask chatGPT to give you links to resources and create guides? You can also ask it about what laptop/desktop you might need for video/voice."],"points":27},{"text":["FRANKIE'S FEARS ARE VALID. 🤡 Stream Cake Boss for free on my new Warner Bros. TV Sweet Escapes channel!","I would rather hammer my fingers into my hands than ever watch cake competition","Anal","Bure-nya~","This shit sucks 🔥🔥🔥","⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠄⠄⠄⠄⠄⠄⠄⠄⠙⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⠄⠄⢀⣀⣀⣀⡀⠄⢀⣠⡔⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣰⢿⣿⣿⣿⣿⣿⣿⣷⡆⢠⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⡏⣻⣟⣿⣿⡿⣟⣛⣿⡃⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣧⣿⣾⣿⣷⣿⣷⣿⣿⣿⣷⣽⣹⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⡟⣟⣿⣿⠺⣟⣻⣿⣿⣿⡏⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⢿⡝⠻⠵⠿⠿⢿⣿⣿⢳⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣯⣧⠈⣛⣛⣿⣿⡿⣡⣞⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡧⠄⠙⠛⠛⢁⣴⣿⣿⣷⣿⢿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⡿⠟⠉⠄⠄⢠⠄⣀⣠⣾⣿⣿⡿⠟⠁⠄⠈⠛⢿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⡟⠉⠄⠄⢀⠠⠐⠒⠐⠾⠿⢟⠋⠁⠄⢀⣀⠠⠐⠄⠂⠈⠻⢿⣿⣿ ⣿⣿⣿⠋⠁⠄⢀⡈⠄⠄⠄⠄⠄⠄⠄⠄⠁⠒⠉⠄⢠⣶⠄⠄⠄⠄⠄⠈⠫⢿ ⣿⣿⡟⠄⢔⠆⡀⠄⠈⢀⠄⠄⠄⠄⠄⠄⠄⢄⡀⠄⠈⡐⢠⠒⠄⠄⠄⠄⢀⣂ ⣿⣿⠁⡀⠄⠄⢇⠄⠄⢈⠆⠄⠄⢀⠔⠉⠁⠉⠉⠣⣖⠉⡂⡔⠂⠄⢀⠔⠁⠄ ⣿⡿⠄⠄⠄⠄⢰⠹⣗⣺⠤⠄⠰⡎⠄⠄⠄⠄⠄⠄⠘⢯⡶⢟⡠⠰⠄⠄⠄⠄","⠀⠀‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎⠀⣠⣤⣤⣤⣤⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⢰⡿⠋⠁⠀⠀⠈⠉⠙⠻⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⢀⣿⠇⠀⢀⣴⣶⡾⠿⠿⠿⢿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⣀⣀⣸⡿⠀⠀⢸⣿⣇⠀⠀⠀⠀⠀⠀⠙⣷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⣾⡟⠛⣿⡇⠀⠀⢸⣿⣿⣷⣤⣤⣤⣤⣶⣶⣿⠇⠀⠀⠀⠀⠀⠀⠀⣀⠀⠀ ⢀⣿⠀⢀⣿⡇⠀⠀⠀⠻⢿⣿⣿⣿⣿⣿⠿⣿⡏⠀⠀⠀⠀⢴⣶⣶⣿⣿⣿⣆ ⢸⣿⠀⢸⣿⡇⠀⠀⠀⠀⠀⠈⠉⠁⠀⠀⠀⣿⡇⣀⣠⣴⣾⣮⣝⠿⠿⠿⣻⡟ ⢸⣿⠀⠘⣿⡇⠀⠀⠀⠀⠀⠀⠀⣠⣶⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠁⠉⠀ ⠸⣿⠀⠀⣿⡇⠀⠀⠀⠀⠀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠟⠉⠀⠀⠀⠀ ⠀⠻⣷⣶⣿⣇⠀⠀⠀⢠⣼⣿⣿⣿⣿⣿⣿⣿⣛⣛⣻⠉⠁⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⢸⣿⠀⠀⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀ ⠀⠀ ⠀⠀⠀⠀⢸⣿⣀⣀⣀⣼⡿⢿⣿⣿⣿⣿⣿⡿⣿⣿⡿⠀","Pussy bitch grow up","Franky? From One Piece?","Penis"],"points":1},{"text":["Poetroid Open Source Poetry-Printing Camera.","Hah! Thats a fun idea, well done."],"points":0},{"text":["I'm searching for a AI personal assistant that matches some requirements.","Currently nothing close to that, but Amazon is working on a paid alexa service that might do it."],"points":0},{"text":["The New York Times is building its own ChatGPT","What's with the title of this post? The screenshot says nothing like that.It's no secret that every news organisation is currently experimenting with an apparent low-hanging fruit: Take the articles from press agencies who provide factual, unbiased news reports, police reports, etc., and automatically generate an article in the writing style of the respective news organisation with an LLM. Ideally, it is slightly biased toward things that catch the attention of the audience of the respective medium.This is nothing about making their own ChatGPT, GPT, or training anything at all. They can take an existing LLM model or use the OpenAI APIs.In some sense, it's the most unsurprising and un-innovative use for this technology.","\"funniest thing I have ever seen\"You should probably get out more","Firsthand source: We're building a team that wants to learn how to use GenAISecondhand source: We're building a team that wants to make GenAIThirdhand source: We're building a team that wants to make ChatGPTFourthhand source: a misleading version of the 3rd sourceand on and on...","I presume with no blackjack nor hookers ?","Brings new meaning to the term RAG.","“Yeah, well... I'm gonna go build my own ChatGPT, with blackjack and hookers!”","But... NYT is famously terrible with tech coverage. Isn't Cade Metz their senior tech writer? He's the worst \"successful\" journalist in the business. I don't understand what they hope to gain from this. Their name recognition will let them continue to fool the ignorant masses. Their utter lack of capability isn't going to change, so they won't be attracting the informed audience. Who is in the middle that this move is meant to assuage?","What's funny about this? Journalism has been a known low paying/slim prospect major for over 20 years.","If they can transfer the expertise of their processes and analysis it could become something.","Good idea. This way the New York Times can tap that VC money since VCs love giving to other tech companies that lose hundreds of millions per year.Sounds like a 4D chess move by Andrew Ross Sorkin fresh out of Billions.","It would work for them since they're fine with made up stuff.","No they’re not. And they’re not claiming to."],"points":90},{"text":["Tagging using 70k terms","Look into how embeddings work. For example word2vec","Use Open AI embeddings API, get embeddings for everything, then a vector similarity measure can give you which ones are related. \"software\" and \"coding\" will be close whereas \"software\" and \"sandwich\" are further apart. You will need a little coding though."],"points":1},{"text":["Image generating AI similar to Dreambooth from Stable Diffusion"],"points":0},{"text":["AI needs similar constraints to the human brain to evolve, argues University of Cambridge research scientist","This reads like an advertisement for Nature Machine Intelligence. Which is, okay fine fair, probably worth a read. The linked article basically says nothing though. Moore's law is a thing and has a limit. Are we at the limit? Maybe, maybe not. When we get to the limit will it be important to focus on ideas outside just computing capabilities, yes. So what? That seems quite obvious. And it seems obvious to push the limit of compute until it goes no further, and then, and only then, look elsewhere."],"points":0},{"text":["Is there any AI that can make lyrics videos of existing songs for free?","whispher?HOW TO Use WHISPER AI TRANSCRIPTION To Transcribe ANYTHING (youtube.com)"],"points":0},{"text":["Best 2D Image to 3D AI?"],"points":0},{"text":["Reformatting Research Papers with AI for Audio"],"points":0},{"text":["Best way to make consistent character with the controll over the pose?"],"points":0},{"text":["Best way to make consistent character with the controll over the pose?"],"points":0},{"text":["LlamaEdge 0.2.9 is released! More LLMs supported. Shell script now work with any of the 3000+ GGUF repos on Hugging Face.","From the github:The LlamaEdge project makes it easy for you to run LLM inference apps and create OpenAI-compatible API services for the Llama2 series of LLMs locally.The Rust+Wasm stack provides a strong alternative to Python in AI inference. * Lightweight. The total runtime size is 30MB. * Fast. Full native speed on GPUs. * Portable. Single cross-platform binary on different CPUs, GPUs, and OSes. * Secure. Sandboxed and isolated execution on untrusted devices. * Container-ready. Supported in Docker, containerd, Podman, and Kubernetes.The LlamaEdge project supports all Large Language Models (LLMs) based on the llama2 framework. The model files must be in the GGUF format. We are committed to continuously testing and validating new open-source models that emerge every day."],"points":0},{"text":["Will there be a day in the future when we can easily design and train our own AI models? (Even for zero-experience user like me)","I think one of the hardest parts of training an AI model is getting a good quality, sufficiently large dataset to train with.","Yes. When is the question. Even with current state non-AGI AI we are seeing automation of any repeatable tasks locally and across nodes. Anything that can be done once can be observed and done again. Originating novel more efficient less wasteful methods and curating quality still requires a human.","there are plenty of guides online but as far as I know the only thing stopping the average person from 'training' a model is willpower and cost. its expensive!!","My guess? 6 years. In 6 years you'll think about that thing in your pocket as an AI and not as a phone. It will know you, it will be your friend, it will look things up, it will serve up videos and products based on your wants and needs. It will shop for you (\"AI, add to walmart cart\") etc, etc, etc.","not SOTA models, but yes.","Yes and no, AI will always advance and we as a consumer will always be playing catch up. It will be more like Stable Diffusion where you get hold of the check points and mod them by injecting you take into it."],"points":8},{"text":["Elon Musk's Neuralink implants brain chip in first human","None of that bullshit. Neuralink is a weaker version of a system used for quadriplegics since 90'. What AI exactly? Is everyone here just straight delusional :D","This marks a significant milestone in the development of brain-computer interface technology.What is the milestone then exactly? Be specific.The aim of Neuralink is to enable people with paralysis to control devices like smartphones or computers with their minds.We've been able to do this for decades now. There are non-invasive procedures that allow people to control BCIs. This isn't new, it's been around for ages.Neuralink has previously demonstrated this technology in animals, showing its potential.You mean like this monkey controlling a robotic arm 15 years ago?Human implantation represents a major step forward in this cutting-edge field.Nope, it's been happening since 2004","Wish musk was the one they experimented on","Neuralink was not founded by Elon Musk. Like all of his other companies, he bought a controlling stake and drove everyone else out.","Noble motive to hide a wicked agenda","I wonder why he wasn’t the first human? Surely it would cure his cocaine addiction if it did what he claimed.","If smartphones and computers were impervious to attack or having penetrable attack surfaces then I would think this is a good idea, but since they're not, it would not be hard to send a \"raise clock speed\" command or edit it's rom remotely to do so and then reboot to the asic so they explode in someones brain.This is a super dumb idea that ignores everything we know about computer security","RIP","It's like trying to sew with a double-handed greatsword. I hope the person enjoys playing pong with their mind because that's all it is good for.","So, he'll surely be able to read tougts and end with the last privacy frontier?","That’s crazy"],"points":51},{"text":["Google Update Reveals AI Will Read All Your Private Messages","The level of patronizing though... “to tailor its responses to your mood and vibe.” As in, by default I'm not capable of expressing myself based on my \"mood and vibe\"? 😖","happy nsa noises","Privacy has been dead for YEARS. Snowden explicitly told us that all of our messages are being read already. All of our calls are being listened to. This changes nothing for anyone who has actually been paying attention.","Who didn't see this coming?? Surveillance capitalism needs to run off a fucking cliff","Probably already trained Bard on it, and this is just an admission rather than a warning","The article discusses some important aspects.AI reading your messages is not google reading your messages, nor does it connect those messages to you (anonymous). The goal is that when phones get powerful enough, all of your data is stored and processed locally on your phone. These days, as the article mentions, even when companies like Apple release their version of generative AI into iPhones, we still need cloud computing for advanced AI computing. This is because phones aren’t powerful enough. The application for AI doing everything with your data is that, in the case of private messages, the AI learns your style, preferred method of communication, and more, which means you have a phone that knows everything about you and only your phone. But the company doesn’t know anything about you (except for your internet traffic, which anyone can infer a lot about).This is actually a good thing for privacy (sort of, if more data is entrusted into a localised AI) and increases your phones usefulness, but I’m not hesitant to suggest that this is going to be a given nor will we understand the consequences. But the idea is sound.","As opposed to them already reading it? I will see ads and receive emails based on anything I’ve typed. At this point I’ve sadly come to expect they know everything about me…except what’s in my journal in my tiny secluded cabin in the woods.","Boomers: \"They're going to read all your private shit!\"Everyone else: \"Can't they do that already if they want to?\"Boomers: \"Wait...they can see what I do on my phone?!?\"","Cute that Google thinks everybody gets.. private messages.","One more reason to buy an iphone instead of an android_)","oh no","\"We already are, we're just letting people actually know about it now\"","I am going to switch to an alternative mobile OS for my next phone. I am tired of Google and Apple.","To think your messages are private on any google product is naive."],"points":116},{"text":["FRANKIE'S FEARS ARE VALID. 🤡 Stream Cake Boss for free on my new Warner Bros. TV Sweet Escapes channel!","I would rather hammer my fingers into my hands than ever watch cake competition","Anal","Bure-nya~","This shit sucks 🔥🔥🔥","⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠄⠄⠄⠄⠄⠄⠄⠄⠙⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⠄⠄⢀⣀⣀⣀⡀⠄⢀⣠⡔⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣰⢿⣿⣿⣿⣿⣿⣿⣷⡆⢠⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⡏⣻⣟⣿⣿⡿⣟⣛⣿⡃⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣧⣿⣾⣿⣷⣿⣷⣿⣿⣿⣷⣽⣹⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⡟⣟⣿⣿⠺⣟⣻⣿⣿⣿⡏⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⢿⡝⠻⠵⠿⠿⢿⣿⣿⢳⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣯⣧⠈⣛⣛⣿⣿⡿⣡⣞⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡧⠄⠙⠛⠛⢁⣴⣿⣿⣷⣿⢿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⡿⠟⠉⠄⠄⢠⠄⣀⣠⣾⣿⣿⡿⠟⠁⠄⠈⠛⢿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⡟⠉⠄⠄⢀⠠⠐⠒⠐⠾⠿⢟⠋⠁⠄⢀⣀⠠⠐⠄⠂⠈⠻⢿⣿⣿ ⣿⣿⣿⠋⠁⠄⢀⡈⠄⠄⠄⠄⠄⠄⠄⠄⠁⠒⠉⠄⢠⣶⠄⠄⠄⠄⠄⠈⠫⢿ ⣿⣿⡟⠄⢔⠆⡀⠄⠈⢀⠄⠄⠄⠄⠄⠄⠄⢄⡀⠄⠈⡐⢠⠒⠄⠄⠄⠄⢀⣂ ⣿⣿⠁⡀⠄⠄⢇⠄⠄⢈⠆⠄⠄⢀⠔⠉⠁⠉⠉⠣⣖⠉⡂⡔⠂⠄⢀⠔⠁⠄ ⣿⡿⠄⠄⠄⠄⢰⠹⣗⣺⠤⠄⠰⡎⠄⠄⠄⠄⠄⠄⠘⢯⡶⢟⡠⠰⠄⠄⠄⠄","⠀⠀‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎ ‎‎‎‎‎⠀⣠⣤⣤⣤⣤⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⢰⡿⠋⠁⠀⠀⠈⠉⠙⠻⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⢀⣿⠇⠀⢀⣴⣶⡾⠿⠿⠿⢿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⣀⣀⣸⡿⠀⠀⢸⣿⣇⠀⠀⠀⠀⠀⠀⠙⣷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⣾⡟⠛⣿⡇⠀⠀⢸⣿⣿⣷⣤⣤⣤⣤⣶⣶⣿⠇⠀⠀⠀⠀⠀⠀⠀⣀⠀⠀ ⢀⣿⠀⢀⣿⡇⠀⠀⠀⠻⢿⣿⣿⣿⣿⣿⠿⣿⡏⠀⠀⠀⠀⢴⣶⣶⣿⣿⣿⣆ ⢸⣿⠀⢸⣿⡇⠀⠀⠀⠀⠀⠈⠉⠁⠀⠀⠀⣿⡇⣀⣠⣴⣾⣮⣝⠿⠿⠿⣻⡟ ⢸⣿⠀⠘⣿⡇⠀⠀⠀⠀⠀⠀⠀⣠⣶⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠁⠉⠀ ⠸⣿⠀⠀⣿⡇⠀⠀⠀⠀⠀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠟⠉⠀⠀⠀⠀ ⠀⠻⣷⣶⣿⣇⠀⠀⠀⢠⣼⣿⣿⣿⣿⣿⣿⣿⣛⣛⣻⠉⠁⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⢸⣿⠀⠀⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀ ⠀⠀ ⠀⠀⠀⠀⢸⣿⣀⣀⣀⣼⡿⢿⣿⣿⣿⣿⣿⡿⣿⣿⡿⠀","Pussy bitch grow up","Franky? From One Piece?","Penis"],"points":1}]