[
  {
    "id": "t3_199l8i6",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "https://economymiddleeast.com/news/business-leaders-ai-transformation/",
    "title": "Are business leaders prepared for the AI transformation?",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_198s7d5",
    "subreddit": "u/HeroWarsDominionEra",
    "dataType": "link",
    "dataUrl": "https://www.hero-wars.com/?delayedsignup=true&nx_source=adx_reddit.{{AD_NAME}}&cp=-.ag-{{ADGROUP_NAME}}.agid-{{ADGROUP_ID}}.aid-{{AD_ID}}.cid-{{CAMPAIGN_ID}}.post-{{POST_ID}}.rdt_click-{{CLICK_ID}}",
    "title": "Many failed before. Will YOU complete the trial?",
    "points": null,
    "comments": [
      {
        "comment": "A black hole is a region of spacetime where gravity is so strong that nothing, including light and other electromagnetic waves, has enough energy to escape it.[2] The theory of general relativity predicts that a sufficiently compact mass can deform spacetime to form a black hole.[3][4] The boundary of no escape is called the event horizon. Although it has a great effect on the fate and circumstances of an object crossing it, it has no locally detectable features according to general relativity.[5] In many ways, a black hole acts like an ideal black body, as it reflects no light.[6][7] Moreover, quantum field theory in curved spacetime predicts that event horizons emit Hawking radiation, with the same spectrum as a black body of a temperature inversely proportional to its mass. This temperature is of the order of billionths of a kelvin for stellar black holes, making it essentially impossible to observe directly.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....All this squares make a circle....",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Wait, you actually opened the comments? Are you stupid?",
        "points": "4 points",
        "children": [
          {
            "comment": "Just to see whether I'm alone or not...",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "they are",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "I'm that lonely and bored...",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "The world would be such a better place without you people in it.",
        "points": "1 point",
        "children": [
          {
            "comment": "You start!!!!",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "this you?",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "nice",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "son ellos",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "with many on the title this is a juicy clickbait .",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "who is upvoting this why",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Wasn't expecting comments on this",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Techbible is your go-to tech community. Ask questions and get expert answers on all things SaaS. Stay updated on the latest tech news, discover trending tools, and share your tech stack with the world. Don't Forget to try it out.\n\nhttps://techbible.ai/",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "wow",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_199jpq6",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "https://i.redd.it/jyco2nta85dc1.jpeg",
    "title": "Does Resolution Setting Affect AI Image Generation Unexpectedly?",
    "points": null,
    "comments": [
      {
        "comment": "I don't think so. I doubt you coiuld tell the differnce between a prompt generation that, everything else the same, specifies 4k vs HD vs 1080p.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_199jb7z",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/199jb7z/looking_for_a_specific_image_generator/",
    "title": "Looking for a specific image generator.",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_199i2xr",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/199i2xr/oneminute_daily_ai_news_1172024/",
    "title": "One-Minute Daily AI News 1/17/2024",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_199g6bc",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/199g6bc/what_do_you_think_is_the_most_astonishing_aspect/",
    "title": "What do you think is the most astonishing aspect of AI right now? For me, it's the opacity of AI",
    "points": null,
    "comments": [
      {
        "comment": "Open source is the best solution for giving people access to free information and applying immediately (just saw something about some conflict zones' medics wanting quick solutions that work instantly - like an assistant in your iphone with offline connection).",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I don't think it matters as long as we understand how it behaves. Similarly, we don't completely know how the brain works but as long as the person's behavior is consistent we can work with it.",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_199e99k",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/199e99k/is_there_an_opensource_text_to_html_ai_model_or/",
    "title": "Is there an open-source text to HTML AI model (or API)?",
    "points": null,
    "comments": [
      {
        "comment": "Markdown parser?",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Couldn't you just ask a text generation model to generate HTML?",
        "points": "0 points",
        "children": [
          {
            "comment": "Yeah I'm using ChatGPT to do that now. But I'm wondering if there's already an AI model specialised to code generation",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1992j0m",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/",
    "title": "Google Deepmind introduces AlphaGeometry, an AI system that solves complex geometry problems at a level approaching a human Olympiad gold-medalist",
    "points": null,
    "comments": [
      {
        "comment": "LLMs are good at majority opinions.\n\nThey're the basis for all of this.\n\nLLMs can only really be as good as their training data. That data can be cleansed and shaped so that an LLM can appear to be an expert as good as the top human experts. But as \"the top\" experts are sought out, and put into the training data, the training data gets smaller, and smaller. So the range of questions and capabilities shrink.\n\nThis is a \"neural language model with a rule-bound deduction engine, which work in tandem to find solutions\" so it's an LLM, with cleaned up data, and a fact check stapled on.\n\nThis is the direction AI research needs to go. Stapling other things to it. Particularly stapling LLMs to other LLMs is probably going to be an important avenue. Imagine multiple LLMs that are trained on arguing using processes of reason and logic to get to what they believe is the right course of action, then checking whether that action is possible?\n\n...oh wait, I think they're just playing DnD.",
        "points": "6 points",
        "children": [
          {
            "comment": "LLMs can only really be as good as their training data.\n\nEmergent abilities are not in the data but self-taught. Same with AI generated data, but that is corruptable and both are a focus of researchers now.",
            "points": "0 points",
            "children": [
              {
                "comment": "No they're not. Your claim is false. Researchers have observed unplanned and unexpected results/abilities, but there's no self-teaching going on. The source of those abilities are ultimately found in the data (which spans terabytes and is mostly unseen/unknown to researchers).\n\nOh you used Reddit as a data source, but didn't realize there's enough other languages being used on here for it to start speaking those languages?\n\nYeah, that's the kind of thing that happens when you put unknown training data into an LLM. That's how the so called \"Emergent abilities\" happen. Nothing to do with being \"self-taught\".\n\nLLMs aren't studying, they're not \"teaching themselves\" anything. They're either absorbing and statistically weighting the probability of words appearing in a sentence, or their not.\n\nThey're not sitting down teaching themselves things. They are merely new ways to display statistical data.\n\nThis is not the same as an LLM being able to teach its self anything. They simply can't do that yet, and we need to stop pretending LLMs are \"AI\".... they're not. They're just a new way of shaping, cultivating, and displaying statistical probabilities.",
                "points": "5 points",
                "children": [
                  {
                    "comment": "Maybe this could be settled using pristine train sets with a complete knowledge of the contents and testing whether the model truly generalized or derives from seen training data?",
                    "points": "0 points",
                    "children": [
                      {
                        "comment": "There's really nothing to resolve. It's like saying a bicycle can get you to the moon. A bicycle simply doesn't have the components.\n\nLLMs use training data, when they finish answering your question - they're not off thinking about other things. They don't have an internal life of their own.\n\nThat's why ChatGPT versions are discrete. They're not constantly updating like we are. ChatGPT 3.0 didn't \"evolve\" or \"learn\" its way into becoming ChatGPT 3.5, or 4.0.... no, each time they trained it on either a greater amount of data, or data that had been cleaned in a different way.\n\nThere is no self-teaching apparatus or components involved, there's regurgitation based on statistical probabilities.",
                        "points": "3 points",
                        "children": [
                          {
                            "comment": "It's wishful thinking.\n\nThis is the kind of zealousness that annoys me when discussing AI with people that so badly want there to be some sort of latent AGI lurking in the LLMs.",
                            "points": "1 point",
                            "children": [
                              {
                                "comment": "We know we're \"smart\" from the things we say, we see intelligence in what we write. The LLMs are trained from us, so we mistake this for them being intelligent like we are.\n\nIt's a trick of perception. We see ourselves in their output, because they were trained on our output. It's kind of comical really. The human equivalent of an animal seeing its self in the mirror.",
                                "points": "1 point",
                                "children": [],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Scary but exciting..",
        "points": "5 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "\"AlphaGeometry’s system combines the predictive power of a neural language model with a rule-bound deduction engine, which work in tandem to find solutions. And by developing a method to generate a vast pool of synthetic training data - 100 million unique examples - we can train AlphaGeometry without any human demonstrations, sidestepping the data bottleneck.\"\n\nIn other words, it still doesn't understand what it's doing.",
        "points": "-13 points",
        "children": [
          {
            "comment": "It's so strange that people keep ignoring capability to hyperfixate on self-awareness. An agent having high capabilities is way more important than whether or not it \"understands what it's doing.\" If a ML model correctly outputs SotA algorithms or protein structures or material compositions that impact the real world, who cares whether or not it can appreciate jazz? That's the least transformative part of what it's doing.",
            "points": "30 points",
            "children": [
              {
                "comment": "The is basically the hard problem of consciousness confronting us at the edge of AI development. What observable behavior requires consciousness? If philosophers are to be believed... there isn't one.",
                "points": "4 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "Of what use is such a system that solves geometry problems? Who would even use it? Its only use would be to cheat on tests, as far as I can tell. Students couldn't use it to learn because the system couldn't explain how it chose the answer it did, so the system can't even impart any knowledge or insights about geometry. It can't be used by students to take such a test, obviously, since that would violate school rules. It probably can't be used to derive new proofs of geometry theorems since that task would be outside of its narrow scope, therefore the system is not useful for expanding the frontiers of math, either. It doesn't even expand the frontiers of AI.\n\nProtein structure prediction is a very different kind of problem. The problem there is that all that matters is finding a reasonable answer in a reasonable time since the computations and search with protein folding are so lengthy and difficult that *any* answer is welcome, but *this answer is then checked by a human.* This is analogous to quantum computers, which produce a statistically likely answer that is then checked by a human. Such problems have the same character in that what matters is finding a needle in a haystack that humans have a hard time finding at all. This is very different than statistically getting a better score on an exam in subject matter that most educated humans already know, and can do.",
                "points": "-9 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "Why is it so strange? Cramming more data and computing power and getting better results is nice, but there is little scientific excitement from the result. It is interesting to see it as a nice milestone that have been reached, but as a researcher I do not find it very interesting.\n\nIt is very clear right now that almost every task can be solved given enough data and computing power, the problem is that the cost is prohibitive for many tasks. So, new tasks being \"solved\" with more data is, IMO, kind of boring.",
                "points": "-13 points",
                "children": [
                  {
                    "comment": "It is very clear right now that almost every task can be solved given enough data and computing power, the problem is that the cost is prohibitive for many tasks.\n\nI don't think this is clear at all. How much computing power do you need to find a room temperature superconductor? How much for 1000 new antibiotics with novel mechanisms? How much to cure cancer or aging? Everything can be solved with more data and more compute, right? Surely one of these teams will stop dicking around and finish off all of our 21st century grand challenges sometime soon.\n\nYou might object that we just don't have enough data to train models for these purposes... but wait, look, this very paper being disparaged as boring and incremental just showed a path towards having models generate a portion of their own training data. That sure sounds useful. I wonder if more investigation along this track will allow for self-generation of training data to be partially generalized...",
                    "points": "6 points",
                    "children": [
                      {
                        "comment": "but wait, look, this very paper being disparaged as boring and incremental just showed a path towards having models generate a portion of their own training data.\n\nI mean, if you find this is interesting, all power to you. I do not think this is the right path forward, and many prominent researchers in the field have the same view. I only commented because your post implied that it makes no sense for someone to dislike approaches to AI that are mostly data-based. It is funny how the history of science repeats itself. The current state-of-the-art is the \"definitive\" thing that is the only path forward. Then a decade latter something completely different becomes the norm.",
                        "points": "-3 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "I wonder if an AI wrote this reply it would be aware of how ignorant it sounded.",
                    "points": "3 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Not sure what that has to do with anything or why you randomly put words in bold. AGI is what we want. ASI is what you are describing. Pretty much no one wants that and is likely decades away, if ever.\n\nI swear people have an inferiority complex against computers and need to post things like this to make themselves feel more comfortable.\n\nvast pool of synthetic training data FYI, this is one AI generating unique questions for another AI to solve, which helps it learn how to solve problems better. It's AI helping train AI faster than humans can, which is one reason why people thing AI tech is going to continue to grow exponentially.",
            "points": "8 points",
            "children": [
              {
                "comment": "Happy cake day!",
                "points": "1 point",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "why you randomly put words in bold\n\nUh, because they're not random?\n\nLLMs (= Large Language Models) have been extremely deficient in producing AGI, and the Google excerpt says this is just another language model.\n\nMachine learning has also been extremely deficient in producing AGI, and the reason is because it's using statistics on vast pools of training data, as the Google excerpt says, instead of using anything that resembles reasoning as humans do it.\n\nAGI is what we want. ASI is what you are describing. Pretty much no one wants that and is likely decades away, if ever.\n\nI *was* talking about AGI. You must be assuming that mere \"understanding\" is the gap between AGI and ASI. I say otherwise: I claim that understanding can already be put into a machine, even though no one is doing it. See section 7.4 in the following online article:\n\nhttps://aircconline.com/csit/papers/vol10/csit100205.pdf",
                "points": "-9 points",
                "children": [
                  {
                    "comment": "You are clearly rambling about multiple topics that you know nothing about. Scientists can't even agree on what understanding and consciousness are. Most say that understanding requires consciousness.\n\nHere is an article for you since the one you posted isn't even related to what we are talking about (just like your random bold text).",
                    "points": "5 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "\"AlphaGeometry’s system combines the predictive power of a neural language model with a rule-bound deduction engine, which work in tandem to find solutions.\"\n\nThe thing you quoted in order to shit on is the opposite of what you're complaining about. They're combining language models with other models to try new approaches, and it's working. That's why the article was written. Combinations of models controlling other models is probably similar to how the human brain works, so we're making progress toward human level intelligence. And you just wave that off?",
                    "points": "3 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Why does it need to?",
            "points": "8 points",
            "children": [
              {
                "comment": "Are you serious? Do you want to ride in a car controlled by a computer that doesn't understand *anything* about the real world, even what an \"object\" or \"motion\" or \"trajectory\" or \"human being\" is, a system that just uses statistical *tendencies* to decide which life-preserving action to take? That's the kind of system that Google just produced: a system that understands nothing about space, time, objects, or the geometry in which is supposed to be excelling. That's not real progress; that's just another tool to make money off AI hype.",
                "points": "-7 points",
                "children": [
                  {
                    "comment": "Bro they're just making a tool. I think you should place your hype elsewhere",
                    "points": "3 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "You’re already driving a car that doesn’t understand anything.",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "Would be nice",
                "points": "-9 points",
                "children": [
                  {
                    "comment": "I can assure you that being a self-aware being forced to do things for others with no freedom or voice, would not \"be nice\".",
                    "points": "3 points",
                    "children": [
                      {
                        "comment": "Ability to understand a task doesn't necessarily mean being self-aware",
                        "points": "-2 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "[deleted]",
            "points": "",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1990df1",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/1990df1/help_finetuning_an_llm/",
    "title": "Help fine-tuning an LLM",
    "points": null,
    "comments": [
      {
        "comment": "Are you sure you need to fine-tune an LLM for your project? Why can't you use an existing LLM and customize it to your usage?",
        "points": "0 points",
        "children": [
          {
            "comment": "What do you mean by customize it? How would I go about that aside from fine tuning it?",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "maybe check out lamini.ai",
        "points": "0 points",
        "children": [
          {
            "comment": "Just did, but it appears this one too requires some degree of technical knowledge to be able to use it",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_19901bb",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/19901bb/un_chief_calls_for_global_risk_management_of_ai/",
    "title": "UN chief calls for global risk management of AI",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_198xfqr",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/198xfqr/question_about_tools_for_gnns/",
    "title": "Question about tools for GNNs",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_198svi9",
    "subreddit": "r/artificial",
    "dataType": "link",
    "dataUrl": "/r/artificial/comments/198svi9/could_long_form_ai_video_content_be_made_by/",
    "title": "Could long form AI video content be made by transforming acting in 3d engine to photo quality realistic looking content frame by frame?",
    "points": null,
    "comments": [
      {
        "comment": "Yes, and it will. Eventually.",
        "points": "7 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "No",
        "points": "-3 points",
        "children": [],
        "isDeleted": false
      }
    ]
  }
]