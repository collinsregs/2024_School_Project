[
  {
    "id": "t3_1acjiji",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "http://idea.co.uk",
    "title": "How to develop an app that allows me to add/edit IPTC data on photos",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1acib2p",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://youtu.be/PieZjz2Pyhw",
    "title": "Entire Blind 75 - Leetcode interview questions solved - cheers.",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1aci8hq",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://www.plotteus.dev",
    "title": "Plotteus | The JavaScript library for data storytelling",
    "points": null,
    "comments": [
      {
        "comment": "Here's the gist of it:\n\nPlotteus is an open-source JavaScript library designed for data storytelling. It allows full control over animations, enabling more natural and engaging data-driven stories. The library supports seamless transitions between different chart types and elements, including colors. It includes six chart types like bar, bubble, and scatter, and offers features like config-based operation, grouping support, and theme adaptability to any background color. The focus is on empowering the audience to interact with the data at their own pace, making stories more memorable.\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually 👍",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "This is pretty sweet, thanks for sharing u/fagnerbrack",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Uhg... that's some awful scroll jacking. I scroll and then I'm forced to wait for janky animations to complete before I can scroll some more. Rinse repeat... 3 times?\n\nNot a good look.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1achjol",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://www.inngest.com/blog/python-errors-as-values",
    "title": "Python errors as values: Comparing useful patterns from Go and Rust",
    "points": null,
    "comments": [
      {
        "comment": "except code you call can still throw despite you writing non throwing code, which means you have to handle exceptions being thrown as well",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1acgibb",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://genplus-language.com",
    "title": "Natural Language Programming - Building applications with natural English",
    "points": null,
    "comments": [
      {
        "comment": "Is English even the best natural language to build something? how much context do you need to explain something simple in a proper way and without room for interpretation?",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Do the videos have an AI voiceover? I noticed it pronounce additional as \"additinal\" which sounded like an AI reading a typo. Either way, it shows virtually no detail on what development actually looks like, so I suspect it is as limited as chat GPT currently is. There was someone who made a POC on this, which basically did the same thing, but they showed how limited it was and you had to do a lot of manual tweaking. It was basically just Microsoft's copilot.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "This is the stupidest idea in the history of computer science.\n\nWhat we need is better programming languages, not worse ones. Much less something like english which is literally the worst possible.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1acfkiy",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://app.daily.dev/posts/LeE07VivA",
    "title": "Uiverse.io 2.0 - +3500 UI Elements, copy the code or use in Figma!",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1acfhif",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://careercutler.substack.com/p/becoming-a-go-to-person-gets-you",
    "title": "Becoming a go-to person gets you promoted. Here's how to do it as a software engineer.",
    "points": null,
    "comments": [
      {
        "comment": "You can just as easily be punished for this behavior. You might be helping the team overall, but if your boss doesn’t value this they’ll see it as you being distracted.",
        "points": "34 points",
        "children": [
          {
            "comment": "This is correct. I’ve almost gotten fired for this behavior. The same manager later actually did recommend me for promotion, but it can go either way.\n\nThe bottom line is that you get promoted by serving (or creating the impression that you serve) the goals of your managers.",
            "points": "14 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Becoming a go-to-person gets you everyone else's work for no benefit.",
        "points": "31 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Promoted and burnt-out.",
        "points": "46 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "In my experience, it gets you more urgent DMs for the same pay.",
        "points": "12 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Unless it's the goto for glue work...\n\n\"we have this really impactful project, you write good docs can you write them for us\" and then you wonder why you don't get recognition when the project is delivered.",
        "points": "7 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "All hard work will be rewarded with more work.",
        "points": "3 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Basically:\n\nThe post discusses strategies for software engineers to become the go-to person in their team, which can lead to promotions. It emphasizes the importance of increasing one's scope, impact, and ownership at work. Specific examples include becoming an expert in certain areas like database, Python, caching, frontend, or TypeScript, or specializing in particular product domains. The article suggests that this expertise will make one indispensable and a key player in the team.\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually 👍",
        "points": "-17 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Getting promoted depends on your desired track. Being a go-to person isn’t necessarily the direction to go.\n\nIf you want to remain an individual contributor, be an expert in something, very competent in adjacent technologies, and understand what depends on those technologies. Be humble about your expertise but confident.\n\nBecoming an engineering leader requires all that but also being aware of other teams, their priorities, and their limitations. You also need to be aware of your team’s strengths and goals and how to help members accomplish their goals. You also have to be capable of articulating that to other teams and executive leadership.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1acfg0w",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://youtu.be/TwPgHgPsJXg",
    "title": "All the ways to manage files in Neovim",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1aceb7u",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://nishtahir.com/i-looked-through-attacks-in-my-access-logs-heres-what-i-found/",
    "title": "I looked through attacks in my access logs. Here's what I found",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1acbzyi",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://arstechnica.com/gadgets/2024/01/i-abandoned-openlitespeed-and-went-back-to-good-ol-nginx/",
    "title": "I abandoned OpenLiteSpeed and went back to good ol’ Nginx",
    "points": null,
    "comments": [
      {
        "comment": "Having a similar experience with CyberPanel. OLS+LSPHP >>> PHP-FPM, and LSCache is great, but for literally everything that isn't PHP-related I bail out to Nginx: I reverse-proxy PHP requests to OLS but let Nginx take care of everything else.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "[deleted]",
        "points": "1 point",
        "children": [
          {
            "comment": "Username checks out.",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Good for you!. Many people I know seem to be using caddy these days though.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1aca15j",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "http://n8n-automation.com/2024/01/27/improve-your-productivity-with-google-sheets-automation-n8n-cloud-tutorial/",
    "title": "Improve Your Productivity with Google Sheets Automation",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1ac9yze",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://github.com/apache/opendal/discussions/4076",
    "title": "Apache OpenDAL™, a library for accessing data freely supporting various languages (C, C++, Haskell, LUA, Ruby, Swift, Zig, Java, Node.js, Python) is now graduated and in search for GSoC 2024 projects!",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1ac8j36",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://localghost.dev/blog/engineering-progression-for-humans",
    "title": "Engineering Progression for Humans",
    "points": null,
    "comments": [
      {
        "comment": "Digest Version:\n\nThe blog post discusses strategies for career advancement in engineering, focusing on personal development rather than just technical skills. It emphasizes the importance of soft skills, such as communication and leadership, in becoming a valuable team member. The post also explores how engineers can position themselves as go-to experts in their field, thereby increasing their visibility and opportunities for promotion. It provides insights on balancing technical expertise with interpersonal skills to build a well-rounded and successful engineering career.\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually 👍",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac7wd0",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://jacobbartlett.substack.com/p/2-minute-tips-the-strategy-pattern",
    "title": "2 Minute Tips: The Strategy Pattern",
    "points": null,
    "comments": [
      {
        "comment": "I enjoyed reading this, I like your writing style. I'm still going to pick some nits :)\n\nThe strategy pattern should encapsulate and make interchangeable the possible implementations, *independently from the clients that use it*.\n\nIn your example, the client has to set a property before using it, defeating the purpose IMO, and introducing potential issues.\n\nIt would be safer in this case to allow the client to name the implementation it wants to use (seeing as they have to know about them all anyway) in an overload argument. This way multiple clients can execute the sort method with different implementations and not have to worry about the current state of the strategy property.\n\nEven better if there is some internal, automatic way of selecting the strategy.\n\nHave a look at how the Sort method works in a framework like dotnet. The remarks on each of those methods tells you exactly how the system *internally* picks an implementation (the strategy).\n\nOptionally, the client can pass in an IComparer to specify their own strategy *if they want*.",
        "points": "6 points",
        "children": [
          {
            "comment": "To be fair, dotnet does not use the strategy pattern for algorithm selection. Yes, it has conditional logic, but it's not the implementation of the pattern.",
            "points": "0 points",
            "children": [
              {
                "comment": "Yes it does.\n\nIt has access to various sort algorithms and it selects one based on the input.",
                "points": "1 point",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "tl;dr: higher-order functions in the kingdom of nouns.",
        "points": "3 points",
        "children": [
          {
            "comment": "Can't strategies relate to nouns? For example, HashMap vs BTreeMap.",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Interesting, now I wonder how it differs from dependency injection 🤔",
        "points": "0 points",
        "children": [
          {
            "comment": "To properly utilize the strategy pattern you should also use dependency injection to get strategy into scope for use. The strategy itself is the stable but purposefully vague API of the interface that hides many possible implementations. The additional use of dependency injection let's the caller decide which strategy to use at the time of calling or construction. If you use the strategy pattern without dependency injection you get the same freedoms, but the choice is made by the developer at commit time, which still has value though much less.\n\nA lot of these design patterns build on each other or work hand in hand with others.",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac7lpg",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://medium.com/expedia-group-tech/candidate-generation-using-a-two-tower-approach-with-expedia-group-traveler-data-ca6a0dcab83e",
    "title": "Candidate Generation Using a Two-Tower Approach with Expedia Group Traveler Data",
    "points": null,
    "comments": [
      {
        "comment": "Here's a summary to help you with the decision to read the post or not:\n\nThe post explores the implementation of a two-tower approach to candidate generation using Expedia Group's extensive traveler data. This technique aims to enhance the personalization and efficiency of travel recommendations. The method involves using separate models for query and item representation, allowing for more precise matching between user preferences and available options. The post details the benefits of this approach in improving the accuracy and relevance of travel suggestions, demonstrating its effectiveness in the context of the Expedia Group's extensive travel-related datasets.\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually 👍",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac7cb2",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://visualstudiomagazine.com/articles/2024/01/25/copilot-research.aspx",
    "title": "New GitHub Copilot Research Finds 'Downward Pressure on Code Quality' -- Visual Studio Magazine",
    "points": null,
    "comments": [
      {
        "comment": "It's like people think LLMs are a universal tool to generated solutions to each possible problem. But they are only good for one thing. Generating remixes of texts that already existed. The more AI generated stuff exists, the fewer valid learning resources exist, the worse the results get. It's pretty much already observable.",
        "points": "650 points",
        "children": [
          {
            "comment": "Machine learning is pattern extrapolation. Like anything else in technology, it’s a tool that places accountability at people to use effectively in the right places and right times. Generalizing about technology itself rarely ends up being accurate or helpful.",
            "points": "148 points",
            "children": [
              {
                "comment": "This is why companies that rush to replace workers with LLMs are going to suffer greatly, and hilariously.",
                "points": "121 points",
                "children": [
                  {
                    "comment": "These companies may have never cared about quality. Which tbh is fine, so long as everyone is clear about the trade offs. Offshore contractors also write the worst code ever and it ends up in critical places. 737 max control code written by unqualified people.\n\nAt least with AI you can automate quality bars.",
                    "points": "52 points",
                    "children": [
                      {
                        "comment": "Their customers will not be in the clear about the loss of quality, me thinks.",
                        "points": "29 points",
                        "children": [
                          {
                            "comment": "It’s really not that different from today. Fairly unskilled cheap contractors write critical and shitty code daily. There’s a quality bar for engineering and it’s not as high as you’d think.\n\nQuality bar is already pretty low, hard to see ai changing that too much.",
                            "points": "17 points",
                            "children": [
                              {
                                "comment": "Yes but AI makes much dumber yet more nuanced issues. They'll be left in an even worse place than before when nobody remembers how things should work.",
                                "points": "12 points",
                                "children": [
                                  {
                                    "comment": "Many of the people who do this work cannot write efficient code or classes with proper scopes. 5k line god clases. How much worse can it get? If anything it might improve things for the bottom 25%.\n\nThe way to look at it is a return to the mean. Great code bases lose quality. Terrible code bases gain quality.",
                                    "points": "-3 points",
                                    "children": [
                                      {
                                        "comment": "It gets worse when those are the people writing the LLM prompts and trying to replace it all. It'll be a shit show",
                                        "points": "6 points",
                                        "children": [
                                          {
                                            "comment": "It’s a shit show now. Your fundamental point is just wrong. These tools will help the worse programmers because they already suck. It will hurt the best because they have the skills to write better code.",
                                            "points": "-2 points",
                                            "children": [
                                              {
                                                "comment": "",
                                                "points": "",
                                                "children": [],
                                                "isDeleted": false
                                              }
                                            ],
                                            "isDeleted": false
                                          }
                                        ],
                                        "isDeleted": false
                                      }
                                    ],
                                    "isDeleted": false
                                  },
                                  {
                                    "comment": "",
                                    "points": "",
                                    "children": [],
                                    "isDeleted": false
                                  }
                                ],
                                "isDeleted": false
                              },
                              {
                                "comment": "",
                                "points": "",
                                "children": [],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      },
                      {
                        "comment": "The 737 MAX code that caused those planes to crash was written perfectly according to spec. That one's on management, not the offshore contractors.",
                        "points": "10 points",
                        "children": [
                          {
                            "comment": "The fundamental problem with the 737 MAX code was architectural and involved an unsafe lack of true redundancy, reinforced by the cost saving measure of selling the indicator light for the known issue separately.\n\nI'm not sure why this person is trying to throw a bunch of contractors under the bus when it wasn't their call, they just built the shotty system that was requested.",
                            "points": "8 points",
                            "children": [
                              {
                                "comment": "I mean, they built it knowing what it was for. It’s our responsibility to speak up for things when lives could be lost or irrevocably changed. Same story behind the programmers of the Therac-25 in the 80s. We have a responsibility to do what’s right.",
                                "points": "5 points",
                                "children": [
                                  {
                                    "comment": "It is delusional to expect the contractors implementing control logic software as per their given spec to raise issues that are way outside their control (i.e. not enough AoA sensors and skimping on pilot training). The only blame should go towards the people that made those decisions",
                                    "points": "8 points",
                                    "children": [
                                      {
                                        "comment": "It begs the question of what our moral responsibility is. I refuse to accept that it’s okay for a developer or group of developers to accept conditions that would lead to them contributing to lives lost or at risk in a fully preventable situation.\n\nTo push this example to the extremes, it is my opinion that we need to know enough before agreeing to a contract to be reasonably sure that our code will not be used to run the gas chambers of the Holocaust.\n\nI know it’s extreme, and that capitalism and compartmentalization put pressure on this, but it’s my opinion. I don’t believe it to be delusional, just impractical and idealistic. But it is my belief, and one that I wish we all shared.",
                                        "points": "-4 points",
                                        "children": [
                                          {
                                            "comment": "Jesus Christ man. You are acting like everybody involved in the 737 MAX was acting maliciously and trying to make sure the planes were going to crash. Of course people should reasonably try to ensure that their work is not going to put people at risk, but how is a random software engineer going to know that executives 5 levels above them were cutting corners? I think you deeply misunderstand the 737 MAX design failures and who should actually shoulder any blame for them.",
                                            "points": "3 points",
                                            "children": [
                                              {
                                                "comment": "",
                                                "points": "",
                                                "children": [],
                                                "isDeleted": false
                                              }
                                            ],
                                            "isDeleted": false
                                          },
                                          {
                                            "comment": "I think that's the wrong question to ask and the focus is misplaced. This is directly the consequence of private ownership of things like airlines and infinite profit seeking. It is directly their fault and their choice. At the end of the day they will find someone to write that code for cheap. It should be our job as a society to not allow this, yet we have defanged institutions like the FAA to the point that they can't even do anything. It's ridiculous to act like personal responsibility even comes into play here",
                                            "points": "1 point",
                                            "children": [
                                              {
                                                "comment": "",
                                                "points": "",
                                                "children": [],
                                                "isDeleted": false
                                              }
                                            ],
                                            "isDeleted": false
                                          }
                                        ],
                                        "isDeleted": false
                                      }
                                    ],
                                    "isDeleted": false
                                  },
                                  {
                                    "comment": "",
                                    "points": "",
                                    "children": [],
                                    "isDeleted": false
                                  }
                                ],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          },
                          {
                            "comment": "That's what the other V in V&V is for.",
                            "points": "1 point",
                            "children": [],
                            "isDeleted": false
                          },
                          {
                            "comment": "Good software isn’t built by blindly following specs",
                            "points": "2 points",
                            "children": [
                              {
                                "comment": "and it's definitely not built by making up your own spec either... the problem was baked into the design decisions and pilot training standards",
                                "points": "3 points",
                                "children": [],
                                "isDeleted": false
                              },
                              {
                                "comment": "",
                                "points": "",
                                "children": [],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      },
                      {
                        "comment": "Define Off-shore.\n\nLinus Torvalds is from Finland, Satya Nadella and Raja Koduri are from India, Juan Linietsky is from Argentina, Lisa Su and Jen-Hsun Huang are from Taiwan.\n\nThey are all top engineers.\n\nLook at this video, same airplane but built in two different factories in the USA are widely different. They did not \"off-shore\" anything, yet, quality is very different.\n\nhttps://www.youtube.com/watch?v=R1zm_BEYFiU\n\nWhat is the difference? It is management, not people, not off-shore.",
                        "points": "1 point",
                        "children": [],
                        "isDeleted": false
                      },
                      {
                        "comment": "",
                        "points": "",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "laughs nervously in Post Office Horizon",
                    "points": "5 points",
                    "children": [
                      {
                        "comment": "",
                        "points": "",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "While you're right, the one thing it does phenomenally well is writing any sort of test. I can definitely see us using managed resources to use AI off the shelf to build testing suites instead of needing a large team of QA to do it. I have to change a decent amount of copilot code today, but unit testing? It all just works.\n\nAlso for building any sort of helm/harness yaml, code pipelines. Its so wonderful and speeds all of that up.",
                    "points": "2 points",
                    "children": [
                      {
                        "comment": "Yeah I found this too. I had copilot save me 45 minutes the other day by it instantly creating a 95% correct unit test based off of a comment.\n\nI also had a bunch of reddit commenters choose that hill to die on by indicating it's absolutely impossible that I could be a dev that knows what he's doing, making a unit test w/ an LLM, reviewing it, submitting it to PR review by the rest of my human team etc etc. According to them if you use an LLM as a tool you're a hack, and nothing you create can possibly be robust or part of a quality system.",
                        "points": "1 point",
                        "children": [],
                        "isDeleted": false
                      },
                      {
                        "comment": "Just because tests pass doesn't mean you have quality software. When you try to add new features and teammates it will fall apart pretty quickly without a vision/architecture.",
                        "points": "-1 points",
                        "children": [
                          {
                            "comment": "",
                            "points": "",
                            "children": [],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      },
                      {
                        "comment": "I have seen people commit code with tests that contain no assertions or that don't assert the correct thing, and based on pairing with these people I strongly believe they are in the camp of \"let co-pilot write the tests\". IMO the tests are the one thing that humans should be writing.\n\nBasic testing practice knowledge is being lost: if you can't observe the test fail, you don't have a valuable test. If anything a lack of testing hygiene and entrusting LLMs to write tests will result in more brittle, less correct software.",
                        "points": "-1 points",
                        "children": [
                          {
                            "comment": "",
                            "points": "",
                            "children": [],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "The big companies are doing it, and our internal LLMs barely fucking help code generation. Metrics management goes off of is how many times their generation API is called not actual production developed code. It's hot garbage when it's forced on everyone",
                    "points": "0 points",
                    "children": [
                      {
                        "comment": "Exactly, and corp leaders love to force the latest hype on everyone. It is a given lol",
                        "points": "1 point",
                        "children": [
                          {
                            "comment": "You don't even know, it's so fucking bad at some of the big tech companies man. Teams are on life support and being put on the most dumb fucking projects. AI and data shoved into every hole possible. Fuck thinking about what the customer wants lmao",
                            "points": "1 point",
                            "children": [],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "Pretty sure the headlines are partly exaggerated by companies who want to push their LLM tools.\n\nThen it’s partly companies who have gotten their eyes up for the apparent ability to cut people doing things that absolutely can be replaced by LLM.\n\nThe company I work for is testing out LLM in customer support.\n\nIt answers trivial questions, does some automation, and most importantly it categorizes and labels requests.\n\nIt helps the customer center people work more efficiently and give better responses. We don’t expect to cut anyone, as we’re a growth company, but if the number of requests were linear then it would easily have cut one person from our customer center. YMMV, obviously.",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "But that was the entire value statement of AI? That's why it's positioned by execs how it is and why it is used the way it is.",
                "points": "4 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "\"pattern extrapolation\" - very good definition",
                "points": "1 point",
                "children": [
                  {
                    "comment": "As my statistics professor used to say:\n\n\"Interpolation is fine. Extrapolation is where the problems start.\"",
                    "points": "1 point",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "Your theory is sound, based on the Cynefin framework. In complex systems, there are no \"best\" practices, only \"good\" ones.",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "s/ENHANCE!/IMPROVE!/g",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "It's a bit of an eye opener to read opinions here, as compared to places like r/technology which seems to have fully embraced the \"in the future all these hiccups will be gone and AI will be perfect you'll see\" mindset.\n\nI work in art/audio, and still haven't seen real legitimate arguments around the fact that these systems as they currently function only rework existing information, rather than create truly new, unique things. People making claims about them as art creation machines would be disappointed to witness the reality of how dead the art world would be if it relied on a system that can only rework existing ideas rather than create new ones.",
            "points": "27 points",
            "children": [
              {
                "comment": "I don't disagree with your overall take, but these algorithms can generate plenty of novel content, though it may not always be what you want. The problem is in exactly how they're trained, as well as how large the data set is that they're trained on. Bad training or low-quality training data will lead to worse results.\n\nJust like all other modes where AI is used, it can only currently be used as a helper or tool for art. It's good for concepting ideas in a quick and dirty way, and it's good for getting a starting point, but you're not going to be able to make much useful with it unless you get your hands dirty and modify the outputs yourself, or use the outputs as inspiration for your own work.\n\nI doubt it'll be used as anything other than a tool any time soon. Nobody's jobs are being replaced by AI that weren't already going to be replaced by a non-ML automated system.",
                "points": "6 points",
                "children": [
                  {
                    "comment": "Oh totally, I've seen it used really well as an assist and/or time saver for creation. In terms of the visual art/asset realm, I honestly think the technology would be in a much better place socially if terms like art generation were simply replaced with image generation. Marketing to non-artists that they can now be artists via this technology belies the entire foundation of what art is, but it's a product marketing point so I don't see that happening anytime soon",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "I feel like the idea of \"new truly unique things\" isn't even really definable. An AI art service like Midjourney let's me create a character for a dnd game I'm running, put a description in, and then walk it to what I want. In the process of doing this has Midjourney not created a new unique thing?\n\nYou might say: Well that's just a remix of everything it's seen before!\nOkay, but that's true of everything. No person creates in a vacuum. Many pieces of art are derivative or reactionary to other previous pieces. Or simply inspired, whether consciously or unconsciously.\n\nYou might also say that Midjourney didn't create the thing I did, but it seems like if I were to take Midjourney's output and post it saying \"I made this\" that would be pretty disingenuous.",
                "points": "1 point",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "I mean you can create new things. I remember that alpha game or whatever thing that learned to write sort algs in assembly through reinforcement learning. It was graded on if it worked and then the speed and found some solutions for sorting iirc 3 or 5 numbers with one less instruction. Of course we knew exactly what it should do so evaluating it wasn't that hard but it's still pretty impressive.",
                "points": "4 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "\"Truly new\" is an undefinable and meaningless concept.  Bottom line is does it create things that solve the need or problem. Same question or to human labor too.",
                "points": "5 points",
                "children": [
                  {
                    "comment": "Yep. OP somehow thinks that everything is not a remix.",
                    "points": "1 point",
                    "children": [
                      {
                        "comment": "That's a gross oversimplification of any creative/generative process. Hip hop has origins in jazz, which has origins in combined blues and European harmony, which has origins in Bach-era romanticism, which has origins in Mozart-era classical aesthetics, but alluding that any of these links are just remixes of what came before is missing the entire creative process. The same can be said of technological advances, shoulders of giants of course but denying the amount of truly original concepts is downplaying the amazing power of your fellow humans' creativity",
                        "points": "0 points",
                        "children": [
                          {
                            "comment": "It's a gross simplification of what AI is doing to say that it can't synthesize new things. You're imagining the slight against the human race.",
                            "points": "3 points",
                            "children": [],
                            "isDeleted": false
                          },
                          {
                            "comment": "Evolution created new things too. The \"creative process\" doesn't require anything more than mutation and selection. Mutation is just stochastic process thrown in the mix - which we have in any optimization process too. It's all search algorithms, and they mostly all employ a stochastic process (ie, random mutation) plus selection criteria (ie natural selection or objective function error).\n\nAnd voila, you have a creative process that generates new things.",
                            "points": "0 points",
                            "children": [],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "It's a bit of an eye opener to read opinions here, as compared to places like r/technology which seems to have fully embraced the \"in the future all these hiccups will be gone and AI will be perfect you'll see\" mindset.\n\nYou are finding the difference between tech professionals and tech enthusiasts.\n\nEnthusiasts know very little and are incredibly easy to manipulate with marketing and false promises, and constantly extrapolate from already shaky claims with their own fantasies.\n\nYou will find the same undercurrent of tech enthusiasts who want very complex smart homes versus security professionals who want all dumb hardware that is network disconnected.",
                "points": "1 point",
                "children": [
                  {
                    "comment": "",
                    "points": "",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "Haha, we’ve been saying “there is nothing new under the sun” for thousands of years. Everything is a remix. What LLMs do is conceptually much closer to the human creative process than artists and writers want to admit. Scientists are better at acknowledging that work builds on previous work.\n\nThe idea of originality as a virtue is culturally and historically contingent. Right now we want to believe we have it and AI models don’t, but it’s probably more accurate to say that we don’t actually have it either, just better/wider experience feeding our internal remix machines.",
                "points": "1 point",
                "children": [
                  {
                    "comment": "Lol as if the outdated concept that a human brain is a computer/machine isn't equally if not more so culturally tied to modern western societies with no actual foundation in reality. I guess agriculture is the same as hunting/gathering, just a remix, as well as every other technological or cultural advance that humans have ever gone through. Just because some people have said something for centuries doesn't make it correct, flat-Earthers have been around a long time as well and that doesn't really give them any more credibility",
                    "points": "-2 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "People making claims about them as art creation machines would be disappointed to witness the reality of how dead the art world would be if it relied on a system that can only rework existing ideas rather than create new ones.\n\nI think you need to be exposed to a variety of art in order to understand how much the artist's intent and point of view matters to the end result.",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "My work is trying to buy Copilot and ChatGPT for us because everyone else asks ChatGPT and Copilot for help. They're also pasting or highlighting entire (proprietary) files into the prompts.\n\nI've made this exact argument, we're seeing some documentation gaps as LLMs write them, and LLMs will have only old data to train on as sites like SO (as shitty as it is) have less activity. I also generally don't like the reliance on LLMs. It's making people make stupid changes that are already causing problems, plateauing their experience, and they're already writing worse code. Using copilot is absolutely like the difference between hand writing notes versus typing notes, where studies show you have a worse memory on the contents of the notes. Getting something done is half the battle, maintaining it without breaking it further is another.\n\nI don't want our small company to spend money on making our product worse, and I certainly don't want to be the person who fixes problems (which is 90% of what I do now) where I can't ask someone the reason they wrote something and what that might impact. It's already led to me rewriting the work in its entirety on several occasions.",
            "points": "5 points",
            "children": [
              {
                "comment": "This is one side of AI, but I feel like you're leaving out the SIGNIFICANT upsides of AI for an experienced user.\n\nLearning a new language, library, or environment? ChatGPT is a great cheap tutor. You can ask it to explain specific concepts, and it's usually got the 'understanding' of an intermediate level user. It's like having a book that flips exactly to the page you need. I don't have to crawl through an e-book to find my answer.\n\nWriting boilerplate code is also a huge use case for me. You definitely have to pretend that ChatGPT is like an intern and you have to carefully review it's changes, but that still saves me a load of time typing in a lot of cases, and once it's done I can often get it to change problematic parts of it's code simply by asking in plain english.\n\nDebugging code is also easier, not because ChatGPT looks at your code and peeps out the bug which happens only rare, but because it 'understands' enough to ask you the right questions to lead to finding a bug in a lot of cases. It's easy to get tunnel vision on what's going wrong.",
                "points": "-1 points",
                "children": [
                  {
                    "comment": "Boilerplate code is the only example that resonates, and even then there's nothing for boilerplates that LLMs can do that shortcuts and extensions can't do. Everything else makes you a bad programmer if you can't do it yourself.\n\nLearning a new language is not hard, it's arguably trivial. Only learning your first language is hard. New frameworks can be a task on its own, but it's not hard. Especially if you're claiming to have the \"experience\" to make it more powerful, you should not be struggling.\n\nDebugging code is an essential skill. If you can't identify issues yourself, you're not identifying those issues in your own code as you write it (or more likely, as you ask an LLM to write it for you). If you claim to have the experience, you should use that, otherwise what good are you? If ChatGPT can solve problems that you can't, you're not as experienced as you think.\n\nYou might just be a bad programmer using a tool as a crutch.",
                    "points": "-2 points",
                    "children": [
                      {
                        "comment": "> Boilerplate code is the only example that resonates, and even then there's nothing for boilerplates that LLMs can do that shortcuts and extensions can't do. Everything else makes you a bad programmer if you can't do it yourself.\n\nExcept there is way more that an LLM can do that shortcuts and extensions can't? You can literally describe the simple class or piece of code you want, have it write it, and then review it as if it was a junior developer. I would never ask an LLM to write anything I couldn't myself.\n\n> Learning a new language is not hard, it's arguably trivial. Only learning your first language is hard. New frameworks can be a task on its own, but it's not hard. Especially if you're claiming to have the \"experience\" to make it more powerful, you should not be struggling.\n\nGood for you man. I bet you just picked up Haskell and Rust that first day. Straight out of the womb understood monads and borrowing. Learning a new language beyond just basic comprehension usually requires reading a book. ChatGPT can act as a personal tutor since these books are in it's training material. You can also ask it questions about your specific usecase and it often has answers you'd have a much harder time finding on SO. Acting like learning a new language is \"trivial\" is just stupid man. No one learns C++, Rust, C, etc. in a day. I picked up Python and Django in like 3 days, but would I say I \"know\" either one of those? Absolutely not. Huge difference between being able to use a tool and mastery.\n\n> Debugging code is an essential skill. If you can't identify issues yourself, you're not identifying those issues in your own code as you write it (or more likely, as you ask an LLM to write it for you). If you claim to have the experience, you should use that, otherwise what good are you? If ChatGPT can solve problems that you can't, you're not as experienced as you think.\n\nIt's not solving problems I'm using it as a tool to interrogate my code. It's ASKING me questions that often lead to the solution. It's like a souped up rubber ducky.",
                        "points": "-1 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "",
                    "points": "",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "We got banned from using AI for code because no one can define what the copyright position is",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "I knew this was the case from day 1. How did other devs not already know this? I take anything AI generates with a grain of salt.",
            "points": "3 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "Yeah there’s some fundamental gap whereby current AI cannot genuinely create information from entropy — something we can do more or less at will (though in a finite capacity every day before we have to learn).\n\nEven to train it we must sort through the data and tell it where the info is.",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "Generating remixes of texts that already existed.\n\nA general rebuke to this would be: Isn't this what human creativity is as well? Or, for that matter, evolution?\n\nAdd to that some selection pressure for working solutions, and you basically have it. As much as it pains me (as someone who likes software as a craft): I don't see how \"code quality\" will end up having much value, for the same reason that \"DNA quality\" doesn't have any inherent value. What matters is how well the system solves the problems in front of it.\n\nEdit: I get it, I don't like hearing that shit either. But don't mistake your downvotes for counter-arguments.",
            "points": "-5 points",
            "children": [
              {
                "comment": "A general rebuke to this would be: Isn't this what human creativity is as well? Or, for that matter, evolution?\n\nno, this is the first fleeting thought everyone has \"haha so it's like how we internalize patterns and apply them, with our regurgitating approach and limitations\" and - apologies for the rudeness - if you did even the slightest bit of research before commenting you'd understand why that comparison makes no sense\n\nyour understanding of code quality seems a bit off as well, maybe you are thinking of code elegance rather than net negative contributions to maintainability, bugs, extensibility and ultimately just total cost of human time spent interacting with it as described in the article. it is directly quantifiable impedance to \"how well the system solves the problem in front of it\"",
                "points": "14 points",
                "children": [
                  {
                    "comment": "why that comparison makes no sense\n\nCan you explain? As far as I know, it is thought that in humans the prefrontal cortex is able to combine neuronal ensembles (like the neuronal ensemble for \"pink\" and the neuronal ensemble for \"elephant\" to create novel ideas (\"pink elephant\"), even if they have never been seen before.\n\nHow exactly does this differ from \"remixing seen things\"? As long as the training data contains some content where novel ideas are described, the LLM is incentivized to learn to create such novel ideas.",
                    "points": "1 point",
                    "children": [
                      {
                        "comment": "at the most surface level, conceptually, the idea of have innate capabilities -> intake instructions -> intake references -> process and pattern match -> output vaguely overlaps with us. and that's a fun observation ! but nothing more\n\nmy comment was just highlighting that this is not some novel thought and is not an argument, as anything beyond that extremely superficial \"ha isn't it neat how that's similar\" holds zero water, while the commenter thought they were coming up with some hard truth insight\n\nid rather not get into a prolonged discussion, but the simplest thing i could highlight is the very nature of training data for \"ai art\" - in its current and forseeable future, the art cannot exceed beyond a few iterations of the training data. if the training data (human art) freezes right now, and ceases to grow, you will either train up until 2024, or begin training on itself. the former stagnation is hopefully obvious why it is not the same as human work. the latter, by contrast, is a far more horrific scenario as the output will not have any breakthroughs, context or change of style, it will begin to actively degrade. incidental cool and novel happenings will emerge, but it will absolutely not do what humans would normally do. understanding why requires some understanding of LLMs.\n\nthat's the simplest thing i can highlight without getting in a very, very obnoxious discussion about LLMs and neuroscience and speculative social science that i do not wish to have",
                        "points": "1 point",
                        "children": [
                          {
                            "comment": "in its current and forseeable future, the art cannot exceed beyond a few iterations of the training data.\n\nThe \"forseeable future\" in this context isn't a very strong statement.\n\nAnd generally you see the same thing with humans. Most of the time they make evolutionary progress based heavily of what the previous generation did. Be it art, science or society in general.\n\nSo far humans are still better in many fields, I don't think there's a good reason denying this. But this is not necessarily because the general approach of Transformers or subsequent architectures won't be able to ever catch up.\n\ntraining on itself is a far more horrific scenario as the output will not have any breakthroughs, context or change of style, it will begin to actively degrade\n\nWhy should that be true in general? And why did it work for humans then?\n\nbut it will absolutely not do what humans would normally do. understanding why requires some understanding of LLMs.\n\nThat wasn't what was suggested. The point of the argument basically is that \"Generating remixes of texts that already existed\" is a far more powerful principle that is given credit for.\n\nthat's the simplest thing i can highlight without getting in a very, very obnoxious discussion about LLMs and neuroscience and speculative social science that i do not wish to have\n\nFair enough, but know that I don't see this as an argument.",
                            "points": "2 points",
                            "children": [],
                            "isDeleted": false
                          },
                          {
                            "comment": "Firstly, I think AI is already training on AI art. But there's still humans in the loop selecting, refining, and sharing what they like. That's a selection bias that will keep AI art evolving in the same way that art has always evolved.\n\nSecondly, I don't for a second believe that AI cannot produce novel art. Have you even tried one of these things? Have you heard of \"Robots with Flowers\"? None of those images existed before DALL-E.\n\nThe whole \"AI can only regurgitate what it's been trained on\" is such an obvious lie, I don't get how people can still think that. Is it denial? Are you so scared?",
                            "points": "1 point",
                            "children": [
                              {
                                "comment": "",
                                "points": "",
                                "children": [],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "if you did even the slightest bit of research before commenting you'd understand why that comparison makes no sense\n\nI think I have a cursory understanding of how creativity, evolution by natural selection and LLMs work. But evidently that's not enough. So here's your chance: If it only takes the slightest bit of research, then you only need the slightest bit of argumentation to rectify that shortcoming of mine, and you'll be helping everyone reading this at the same time.\n\nyour understanding of code quality seems a bit off as well\n\nThanks for that, and I don't think so. But my (admittedly) unstated assumption was that it doesn't matter what the code looks like, as long as the artifact it produces does what's asked of it. In that scenario, humans wouldn't really enter the picture. It's just that awkward in-between phase that this is a problem.",
                    "points": "-1 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "A general rebuke to this would be: Isn't this what human creativity is as well?\n\nIt is true. But humans are very good at finding patterns. Sometimes even so good that it becomes bad (apophenia). Humans don't need that many examples to make something new based on it. AI on the other hands, requires an immense amount of data. And that data is limited.",
                "points": "2 points",
                "children": [
                  {
                    "comment": "Added to that is the fact that humans are able to draw upon an absolutely vast amount of stimuli that are seemingly unmoored entirely from the topic at hand in a subconscious, free association network - all of it confusing mixed between positive, negative, or neutral. These connections influence the patterns we see and create, with punishment and reward tugging at the taffy we’re pulling.\n\nCompare that to LLMs, which simply pattern match with an artificial margin of change injected for each match it walks across.\n\nThese processes are entirely different in approach and outcome.\n\nNot only that, but LLMs are now being fed back their own previously generated patterns without any addition of reward/punishment associations, even (or perhaps especially) ones that are seemingly unrelated to the pattern at hand.\n\nIt simply gobbles up its own shit and regurgitates it back with no reference to, well, everything else.\n\nIt basically just becomes an extraordinarily dull Ouroboros with scatological emetophilia.",
                    "points": "2 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "I think the difference between Human learning and AI learning is that Humans have been building upon knowledge for thousands of years (just based on written history, not whatever tribes existed before that). That neural network is constantly expanding and reinforcing itself.\n\nAI is a fairly new blip on the radar and doesn't have that kind of reinforcement.\n\nPlus Humanity is able to take in new experiences and develop new ideas by exposing itself to enviroments outside of the work field, While AI is purposely built to do one thing over and over again, and doesn't have that component.\n\nAI can be trained, but for the most part it's teaching itself in a sterile environment created by humans with no outside influence.\n\nI think that outside influence is far more important to the development of new ideas, because some ideas are built entirely by circumstance.\n\nIn order for AI to truely succeed, you'll probably have to let it outside the box, and that's terrifying.",
                "points": "0 points",
                "children": [
                  {
                    "comment": "AI […] doesn't have that kind of reinforcement.\n\nIt does though. That's what all the interactions with LLMs (and for that matter, CAPTCHAs) do – they provide feedback to the system. Sure it's new, and fair enough. But its newness doesn't seem like a fundamental difference, and will go away eventually.\n\nPlus Humanity is able to take in new experiences and develop new ideas by exposing itself to enviroments outside of the work field, While AI is purposely built to do one thing over and over again, and doesn't have that component.\n\nThat really just seems like a difference in how it is used, not how it is constructed.\n\nIn order for AI to truely succeed, you'll probably have to let it outside the box, and that's terrifying.\n\nSo I guess we agree, basically?",
                    "points": "-1 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "A general rebuke to this would be: Isn't this what human creativity is as well? Or, for that matter, evolution?\n\nNo, humans understand general concepts and can apply those in new and novel ways.\n\nAn LLM fundamentally cannot do that, it's a fancy Mad Libs generator that is literally putting tokens together based on their probability of existing in proximity based on existing work. There is no understanding or intelligence.",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "a general rebuke\n\nNo. You’re begging the question. Observably, LLMs do not display anything approaching human proficiency at any task. So it’s totally fair for us to sit around waxing philosophical about why that might be. We have evidence, and we’re seeking an explanation.\n\nYour “rebuke” is that “actually LLMs work just like human creativity”. But there’s no evidence of that. It has no foundation. So, yeah, you’re not entitled to a counter argument. Because you haven’t said anything",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "You are talking about an unrelated and highly debatable phenomenon compared to what the post is about.",
            "points": "-1 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "TBH I think people actually get that. What tech fans don't get is that LLMs are not composable. You can slap a filter on top of them but you cannot take some kind of actual intelligence and stick it in the middle of the LLM. It just doesn't work that way.\n\nA lot of people talk as if it is just as easy as iterating on this but what we have is likely the best we'll do. There's a reason most of this technology was written off as not being the answer 30 years ago in academia.",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "I was having a convo with another senior at work and we have both noticed and hypothesise that the juniors are using ai assistant stuff to produce code which often doesn't make sense or is clearly suboptimal.",
        "points": "137 points",
        "children": [
          {
            "comment": "There's another aspect people are not considering: chances of a junior that uses this kind of thing too much staying junior forever is really big. I'm seeing that happening at work.",
            "points": "95 points",
            "children": [
              {
                "comment": "Yeah that imo is the biggest threat of AI. It replaces the junior employees of a field and/or hinders their growth. Once the seniors retire there will be no one to take their place.",
                "points": "53 points",
                "children": [
                  {
                    "comment": "On the other hand, as someone who has \"grown up\" in programming without AI assistance, I could see that as a potential advantage for my personal career in the future.",
                    "points": "23 points",
                    "children": [
                      {
                        "comment": "",
                        "points": "",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "I tend to lean towards \"don't blame the tool\".\n\nThe type of person that would use AI and never improve was most likely never going to improve without it.\n\nTo me it sounds like the same old argument about copying and pasting code. That they'll never learn.\n\nBut I think most of us have learned very well from seeing finished solutions, using them, and learning from them. And if I'm being honest - no copy/paste code has ever really worked without editing it and somewhat learning to understand it. I've probably got countless examples of code that started out as a some copy/paste and evolved into a full proper solution because it got me past a wall.\n\nAI doesn't seem much different. Just another tool. People uninterested in improving or understand will get some use of it but has a very hard limit on what you can accomplish. People willing to use the tool to better their skills will do so.",
                "points": "20 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "I noticed it years ago when juniors around me would copy paste code snippets from stackoverflow while I would type them.\n\nThere is hidden and unexplainable magic in writing that helps you (a) learn and (b) understand",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "I'm pretty sure juniors have been making nonsensical, suboptimal code for decades now ;)",
            "points": "30 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "I do use AI as a glorified search engine and i sometimes have to double check because its incorrect in places.\n\nWould i ever copy the code that was given to me without rewriting the key points and checking the rest? never in a million years.",
            "points": "4 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "The wild thing for me has been seeing people use AI to generate tests that validate the behaviour of their implementation “automatically”. This of course results in buggy behaviour being enshrined in a test suite that nobody has validated.",
        "points": "55 points",
        "children": [
          {
            "comment": "AI is bad at many problems, but generating tests is something it is good at. You of course have to review the code and the cases, making an edit here or there. But it does save a lot of typing time.\n\nWriting test is a lot more blunt in many cases. You explicitly feed in value A and B expecting output C. Then A and A, and get D. Then A and - 1,and error. Etc etc. AI can generate all of those fast, and sometimes think of other cases.\n\nIt in no way replaces you and the need for you to think. But it can be a useful productivity tool in select cases.\n\nI will also add, it also acts like a \"rubber duck\", as you explain to it what you're trying to do.",
            "points": "20 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "I personally think this is it's one use case. I've found it can generate decent tests quite quickly for pure functions.",
            "points": "3 points",
            "children": [
              {
                "comment": "Why not use existing property based testing libraries for this though? They've been around for ages already.",
                "points": "6 points",
                "children": [
                  {
                    "comment": "Llm tests can actually be quite in depth. As an example, I added a seeded uniform random function in a toy project and asked for some tests, and it actually added some statistical sampling to verify the distribution of the function was statistically expected.\n\nAt the very least they can come up with some good ideas for tests, and at the best of times they can automate away coding up a bunch of obvious edge cases. I see it as a why not rather than a why.\n\nCaveat, that was in python. Trying to use a llm in rust for example has been awfully shit in comparison (in my experience).",
                    "points": "3 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "You can use both",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "the people advocating for AI based tests is a big headscratcher to me. test code can be as buggy or more than the code it's supposed to be testing, and writing a meaningful test is really hard. are the people using AI to write tests actually getting meaningful tests, and did they ever write meaningful tests in the first place?",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "This feels obvious to anyone who has used copilot.  It almost never gets it 100% right, and relies on human proofreading.  All this is saying is that humans are better at catching mistakes in their own code as they write it vs reading ai assisted code.\n\nThe real question is \"even with increased churn is ai assistance still faster\"",
        "points": "88 points",
        "children": [
          {
            "comment": "And if there is one thing we all know\n\nDevelopers almost always prefer writing more code over reading existing code",
            "points": "23 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "All this is saying is that humans are better at catching mistakes in their own code\n\nHumans are not actually good at catching their own mistakes. Humans overrate the ability of humans. This is why unit test exists and good code coverage is required to catch our own mistakes.",
            "points": "27 points",
            "children": [
              {
                "comment": "Haha yeah I didn't mean to imply that we were good at that either.  Just that we're apparently better at it than catching copilot mistakes.",
                "points": "8 points",
                "children": [
                  {
                    "comment": "I think it comes to down to the fact, that when writing something you have to be focused, meanwhile when reading you can lose that focus. If you're stuck while writing something you are perfectly aware of it because you're not generating anything. You can however skim a text or some code with basically limitless amounts of absent-mindedness and never notice you're doing a half-assed job.",
                    "points": "7 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "This is why unit test exists\n\nHuman's overestimate their ability to be smarter building the test than when building the code, which is why most unit tests are mostly just testing the harness and trivial cases that wouldn't have hit bugs anyway.",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "relies on human proofreading\n\nWhich seems to fuck over noobs, but what do I know?",
            "points": "5 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "It took me four times as long as it should have for me to write up a 40-line example in Codepen a few days ago, because it kept trying to inject what it thought I was trying to do. It should not have been that frustrating to bang out a few lines of javsacript. I hate this MBA-designed bullshit.",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "It’s one of the reasons I’m against AI-assisted code. The challenge in writing good code is recognizing patterns and trying to express what needs to be done in as little code as possible. Refactoring and refining should be a major part of development but it’s usually seen as an afterthought.\n\nBut it’s vital for the longevity of a project. One of our code bases turned into a giant onion of abstraction. Some would consider it “clean” but it was absolutely incomprehensible. And because of that highly inefficient. I’m talking about requesting the same data 12 times because different parts of the system relied on it. It was a mess. Luckily we had the opportunity to refactor and simplify and flatten the codebase which made adding new features a breeze. But I worry this “art” is lost when everybody just pastes in suggestions from an algorithm that has no clue what code actually is.",
        "points": "143 points",
        "children": [
          {
            "comment": "The challenge in writing good code is recognizing patterns and trying to express what needs to be done in as little code as possible\n\nWe probably agree, but I would phrase it as simplest code possible, not shortest/littlest. Often more code is simpler and easier to reason about, understand, maintain etc than less code. See: code golf",
            "points": "102 points",
            "children": [
              {
                "comment": "Yes, simplest indeed.",
                "points": "25 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "See: the senior who made me, for my first assignment, condense some legacy code that had like a 12 layer nested if statement that was fairly readable into a single line nested ternary that was as readable as hieroglyphs. It was such a waste of time and made things actively worse for everyone who needed to work in that area.",
                "points": "8 points",
                "children": [
                  {
                    "comment": "Yeah, that’s not simplification, that’s just trying to cramp code into less symbols/lines.",
                    "points": "4 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "12 layers of nesting just sounds bad anyways.",
                    "points": "3 points",
                    "children": [
                      {
                        "comment": "I mean it wasn't good but it was readable and did what it needed to do.",
                        "points": "1 point",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "An intern on my team recently reached for ChatGPT to figure out how to make Color(0.5, 0.5, 0.5, 1.0) into a lighter grey, after previously defining values for green and red.\n\nI don't fault anyone for not already knowing what RGBA is, but.... the impulse to start by talking to an LLM instead of reading the documentation robs people of skills and knowledge.\n\nEdit: okay, took the time to actually look it up and the documentation isn't, so that anecdote doesn't mean shit",
            "points": "24 points",
            "children": [
              {
                "comment": "Well in this case I imagine docs will say it's RGBA and then assume people already know what that is, so it wouldn't be helpful to someone completely clueless. You could ask the AI to explain \"what does these numbers mean and why is it gray\", and then I assume you'd get a decent answer. I do agree however that stereotypically, people who reach for AI as a default probably won't ask that kind of question. They will task the AI with the problem directly, and use the solution without reflection. And hence they'll need to as the AI again next time.",
                "points": "2 points",
                "children": [
                  {
                    "comment": "... took the time to actually look it up, and it's worse - you just get function parameter names (abbreviated, naturally, because we're running out of bytes for source code).\n\nhttps://github.com/ocornut/imgui/blob/master/imgui.h#L2547\n\nI wish he'd asked someone to figure out how that works instead of using an LLM, still. He'll be fine - the application he built this semester works fine and doesn't suck any more than I'd expect from a third-year student.",
                    "points": "5 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "I had to fight hard to get a few weeks to refactor a similar codebase, and my boss' boss was \"unhappy he had to wait\" but reluctantly agreed.\n\nThe tech debt I eliminated in that 2 weeks meant I was able to implement the features the man-baby demanded very quickly, but he'll never forget that I made him wait.\n\nMotherfucker...",
            "points": "5 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "I’m definitely an artisan when it comes to coding. I like it to be ergonomic, well architected, aesthetically pleasing and consistent AF.\n\nYou can do all that and still use AI assisted code. Copilot is pretty much just a fancy autocomplete for me. It saves me 20-30 minutes a day of writing boilerplate.",
            "points": "13 points",
            "children": [
              {
                "comment": "It’s not all bad. I use it from time to time. But I know what I’m doing. The statement is about the people who don’t.",
                "points": "8 points",
                "children": [
                  {
                    "comment": "Sorry yeah I kind of pointed out the obvious I guess. Yes - people shouldn't use copilot as a crutch. I've had moments before where copilot recommend a 2-3 line block and I'm feeling lazy and it looks largely correct, until upon closer inspection it's most definitely incorrect code... In those moments I've very nearly created some tricky bugs for myself!",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "I actually think that’s a pretty important thing to point out. In most cases, my stance is: if you can’t figure something out without copilot, you shouldn’t use it. This take is kind of situational and isn’t always true, because sometimes it does point me into a direction I wouldn’t have thought of - but it is often the situation.\n\nI just came back from a rock climbing gym, but the first analogy that comes to mind is: using copilot is like using a belay for climbing. If you rely too heavily on the belay (as in you ask your partner to provide no slack and practically hoist you up), you’re not really climbing and in most cases you’re reinforcing bad practices. You should know how to climb without it, and use it to assist.\n\n… on second thought this might not be the best analogy but, eh, I’ll go with it for now",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "Honest question:\n\nI hear this exact phrasing a lot that it \"saves me X amount of time every day of writing boilerplate\", and as someone who has been programming professionally for 15 years, I don't think I've ever dealt with enough boilerplate that wasn't already automatically generated. What are some examples of the boilerplate you're spending 20-30 minutes on each day?\n\nThe only things I could think of that might fit \"boilerplate\" are:\n\nSerDe-related code, e.g. ORM code, JSON code, etc.\nFramework scaffolding, e.g. creating directory structures, packaging configurations, etc.\nCode scaffolding, e.g. creating implementation stubs, creating test stubs, etc.\nTooling scaffolding, e.g. CI configurations, deployment configurations like Kubernetes YAMLs, etc.\n\nThe vast majority of these things are already automatically generated for me by some \"dumb\"/non-generative-AI tool, be it a CLI or something in my editor.\n\nAm I missing something obvious here?",
                "points": "6 points",
                "children": [
                  {
                    "comment": "SerDe-related code, e.g. ORM code, JSON code, etc.\n\norm code - yeah this is a big one, I write a lot of it. I could write a generator (I've written some NX generators), and I do plan on it, but the perfect orm-layer service for a DB table is still evolving... would need prisma, logging, rollback logic, result monad usage for all the CRUDs... would be a massive time saver. In the meantime copilot helps a lot.\n\njson code - yeah writing out json is sped up by copilot, maybe up to five minutes a day here.\n\nFramework scaffolding, e.g. creating directory structures, packaging configurations,\n\nI use generators for a lot of framework scaffolding but definitely not all of it. again, couple minutes a day here for copilot\n\nI could do on here, but basically - you are somewhat right, generators would solve at least half of the copilot use cases I run into. Ultimately there's many many ways a dev can be more productive, and generators just hasn't been a focus on mine, tho I do aspire to do adopt them, eventually!",
                    "points": "2 points",
                    "children": [
                      {
                        "comment": "",
                        "points": "",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "I use copilot and it can definitely help save time. It'll automatically create the same test cases I would have written (just the test scenario description, not the implementation). I'll write a comment that says \"filter payments that are currently in progress and update the label status\" and it'll do it. It's helpful for little things, not creating a whole class or designing something. Things that I know how to do but take 30 seconds to a minute to code, it will instead get done in 2 seconds. And I don't need to pick some CLI tool or IDE plugin to do these things, it just automatically happens.",
                    "points": "1 point",
                    "children": [
                      {
                        "comment": "",
                        "points": "",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Ai will become better at it. It’s a bit like complaining that a iPhone 3gs is slow to browse the web and go on a lengthy explanation why a PC is better at it.\n\nEdit: ok guys, we are living in peak ai, it will never become better than it is now. Lol\n\nEdit2: I’m not expecting upvote, it’s a bit like going in an art sub and telling them about how great dall-e is. Or telling a bunch of taxi drivers about Uber.",
            "points": "-30 points",
            "children": [
              {
                "comment": "except it cant get better at it if its not in its training data, which it wont be if every one is copying from it.\n\nIts probably already started that those models produce nasty feedback loops where theyre trained on what they produce.",
                "points": "20 points",
                "children": [
                  {
                    "comment": "I would agree if it was happening in some sort of closed system where we have no way of influencing the process or evaluating the quality of the output.",
                    "points": "-2 points",
                    "children": [
                      {
                        "comment": "curating TBs of textual data is extremely difficult and time consuming. They are normally trained on web crawls. Influencing the process is also pretty hard because they are trained by simply generating text that is likely based on what it observed.\n\nThere is no incentive to generate text that follows design or achitectural patterns unless it has seen a ton of them in training",
                        "points": "1 point",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "Will it? It’s trained on what people produce. But if the quality of code becomes less and less, the AI generated stuff becomes poorer as well.\n\nIf you’re talking about a true AI that can reason about the world and thus the code you’re working on, we are a long ways off. Some say we might actually never reach it.",
                "points": "15 points",
                "children": [
                  {
                    "comment": "IMO this is where we should start mixing in things like genetic algorithms, which can bounce a program out of local extrema, and we’ve already seen that come up with crazy stuff on its own. (E.g., it was applied to Core Wars and it came up with techniques for hiding and self-repair, no teaching needed beyond a Goodness metric, and that metric can presumably be learned from the user’s preferences with respect to prior selections.)\n\nSo you end up with expert_LLM↔GA←|→UI_LLM←|→user, or something along those lines, with the UI LLM tied to developer’s environment and the rest shared. A GA might also help with some of the copyright sortsa issues, since it can come up with novel content.",
                    "points": "-1 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "Yes it will. They just started and it’s already improving. Compare gpt3 to gpt4, GitHub copilot is still running on codex. They are already talking about gpt5, its just getting started.",
                    "points": "-18 points",
                    "children": [
                      {
                        "comment": "Both gtp3 and gpt4 are just datasets, data that has been categorized and will be used as the input to train an llm. They are not revolutionary, they’re just very good models.\n\nWhat everyone in this chain is trying to tell you is that if everyone starts using ai models to write code, overall code quality will degrade because ai models don’t have the ability to take code context into account, so, any subsequent model (e.g gpt5 or whatever) will have as input an already degraded input.\n\n“Ai feeds ai”, this becomes a weird problem where ai consumes its own data to train itself which in turn will generate that for another model to consume.\n\nIn short, it just becomes a self contained loop of shit.",
                        "points": "8 points",
                        "children": [
                          {
                            "comment": "But those are all problems that can be solved. There is already smaller models that are trained on high quality code. You can look at what Phind is doing. It’s not a train on everything publicly available or nothing type of thing.",
                            "points": "-2 points",
                            "children": [
                              {
                                "comment": "Look at the sub you’re in. Saying llms will improve at tasks (which they are) is like telling artists generative ai will get better. They just don’t want to hear it",
                                "points": "0 points",
                                "children": [
                                  {
                                    "comment": "To me its surprising this sub don’t get it (or don’t want to). Other places like hacker news are all excited about the progress. Copilot autocomplete is not great, true, but Copilot is due for an upgrade too. We will look at those tools in a couple a years laughing at how basic they were. If you believe people here the peak have been achieved and it could only go backwards from here.",
                                    "points": "1 point",
                                    "children": [],
                                    "isDeleted": false
                                  }
                                ],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      },
                      {
                        "comment": "They just started and it’s already improving.\n\nWhat professional programmers are telling you is it's already declining.\n\nThe only way to refute this is to sketch out the mechanisms for it improving.",
                        "points": "3 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "And yet a PC is still better for browsing the web.",
                "points": "2 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "I agree with you. I frequent /r/localllama and there is this constant move to find better and better ways to train models. There are open source models as good as gpt-3.5 you can run on a local machine.\n\nThe real shift is going to be when you have more agent-based frameworks being used. Instead of it being a fancy auto complete, you have a feedback loop with a code reviewer, code tester, and code writer agent. All these concerns people have about copilot can be trained and programmed around.\n\nOf course a human expert is going to be hard to beat given enough time and effort, but copilot surely isn't the final end point. Software development is going to change significantly, whether people want it to or not. There is too big of a potential benefit.",
                "points": "-1 points",
                "children": [
                  {
                    "comment": "You can check github workspace short video they released. That’s where they are heading.\n\nBut the reaction you see here is a pretty much expected. Not a single industry get disrupted and people are happy with it. Lot of anger and denial. But progress won’t stop.\n\nThere’s a guy who posted one of his creation with dall-e to an art subreddit and the reaction was pretty much the same as here. He got downvoted into oblivion, but those models keeps getting better so in the end it doesn’t really matter. Even with my business we were hiring illustrator for blog posts and the website, now we just use dall-e. Things are changing, personally I’m fine and excited about the future.",
                    "points": "-1 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Literally nothing what you said has anything to do with AI.\n\nYou can replace AI with Stackoverflow or any other source and nothing would change.\n\nThe difference is Copilot actually does understand code and uses your already written code as a basis.\n\nHell, it even specifically has a refactoring feature.",
            "points": "-45 points",
            "children": [
              {
                "comment": "The problem is not people writing bad code. The point is that tools like copilot encourages people to write bad code. Or rather, obfuscate the fact that people are writing bad code.\n\nYou yourself are a great example. You think that copilot understands the code you write but that’s not how this works. Copilot is only a very advanced autocomplete. It has no idea what your code does.",
                "points": "41 points",
                "children": [
                  {
                    "comment": "Copilot is only a very advanced autocomplete.\n\nI've been banging this drum for a very long time (although talking about LLM's in general).\n\nIt's....noteworthy that the only place I see broad agreement is in the programming subreddit.",
                    "points": "13 points",
                    "children": [
                      {
                        "comment": "While programmers are some of the only folks left who understand that LLMs are overhyped and not fundamentally capable of the things people hope to use them for, I have seen a troubling amount of buy-in from the mainstream tech scene. Microsoft paying $10b for half of openAI for example. to do what? replace their help documentation with a chatbot who gives you instructions for the wrong versions of windows? Really feels like the entire tech sector is jumping the shark on this one.",
                        "points": "4 points",
                        "children": [
                          {
                            "comment": "I can totally see that.\n\nI develop tech but am not really in the tech industry: I use R and Python to process data into a database and display the results of the analysis in my website.\n\nReading the general vibe in this and other subs like /r /webdev is disheartening: I wouldn't do well in some of these professional worlds.\n\nThe entire sector jumped the shark seems about right, and I don't see any way of joining the party.",
                            "points": "1 point",
                            "children": [],
                            "isDeleted": false
                          },
                          {
                            "comment": "There's going to be a hiring boom when companies realize GenAI isn't going to replace 70% of their workforce and these layoffs were premature",
                            "points": "1 point",
                            "children": [],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "Not even close to the real world. It has massively improved code quality at my company.\n\nAlso, still going on about \"it doesn't understand anything\" when it's perfectly capable of describing what code does is just incredibly denial.",
                    "points": "-2 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "It’s quite easy to imagine that in the future it will be able to run your full codebase. We are not there yet, but pretending that a computer can’t understand code…",
                    "points": "-29 points",
                    "children": [
                      {
                        "comment": "maybe this is an issue of terminology but computers do not understand code, they execute code.\n\nif computers understood code they could go \"hey, this statement would be better written this way...\", but they can't. what we do have is compilers that do that for us, but compilers are written by humans and humans understand code.\n\nthe same is true for LLM:s. they don't understand their input, but they are able to take that input and get you a result that looks like they did.\n\ncompare with a machine that sorts potatoes and you're able to input that you only want potatoes that are 100g or heavier. does the machine understand your request? no, but a human does and has made it so that when the scale measures a potato under 100g it will be removed. you could say the machine understood your request, but in reality a person did.\n\nso no, computers don't understand code and if they did they would have an artificial general intelligence and those don't exist.",
                        "points": "28 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "Copilot actually does understand code\n\nCopilot doesn't understand code a tiny bit. your editor take data in adjacent files open in the editor and sends that data as context for Copilot.\n\nit is extremely dangerous to insinuate that Copilot knows what it is doing - it does not. all it does is produce output that is statistically likely to be what you're looking for and while that is extremely impressive in and of itself there is no reasoning, there is no intelligence, there is no verification.\n\nmeanwhile over on the stackoverflow side of things there's a human out there that does have intelligence, reasoning and verification about the things they talk about. perhaps they're wrong, that happens, but Copilot will be wrong and lie to your face about it.\n\nI like Copilot as a product, it oftentimes helps me find solutions in old frameworks that have dead forum links, but talk about it and treat it for what it is.",
                "points": "32 points",
                "children": [
                  {
                    "comment": "Saying \"it doesn't understand code\" when it's perfectly capable of writing functioning code for coding challenges based on a problem description is extremely dishonest. The underlying principle being simple doesn't matter, this is called emergent behavior.\n\nAt this point it's just reductionism with denial. It's clearly able to write code to meet requirements and also describe what code does.",
                    "points": "-1 points",
                    "children": [
                      {
                        "comment": "",
                        "points": "",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "You’re getting downvoted but this is the truth. Bad coders have been copying and pasting code they don’t understand since copy and paste became a thing.\n\nWhat Copilot does is make the copying and pasting easier. It doesn’t miraculously make a bad coder understand code better.",
                "points": "-18 points",
                "children": [
                  {
                    "comment": "That’s not the point. The point is that tools like copilot encourage those behaviors.",
                    "points": "28 points",
                    "children": [
                      {
                        "comment": "I agree with both takes. Copilot is just making it even easier to not understand the code you’re contributing to the code base. I do worry that it’s robbing newer devs of certain experiences that will increase their skill, but I seem to be doing ok without knowing assembly, so I am comforted by the thought that it’s just the next step of that trend.",
                        "points": "-9 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "It’s one of the reasons I’m against AI-assisted code.\n\nI'm for AI assisted coding if it worked in a sane way.\n\nInstead of being trained on all code everywhere, if you could train it on exemplar code to set standards and patterns for your organization and then have it act as a AI pair programmer to promote the desired patterns and practices with live code review, that would be amazing.\n\nWhat we have instead is just hot garbage for effectiveness.",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "It's easy for me to assume that my skills as a programmer would degrade if I used coding tools like these.\n\nUse it or lose it, they always say.",
        "points": "16 points",
        "children": [
          {
            "comment": "I rhink is taught me a lot more and improved my skills because i have to go read documentation every time ai gives me an answer lmao",
            "points": "15 points",
            "children": [
              {
                "comment": "This is exactly what’s been happening for me. It started off as me putting too much confidence into AI, to then thinking “yeah this needs a lot of proofreading. Off to the documentation I go”",
                "points": "5 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "If you always ensure that the generated code is correct and verify it and you are skeptical of the answers it gives you then it can be used as a learning tool too.",
            "points": "5 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "It just seems to me that LLM are of limited use",
        "points": "49 points",
        "children": [
          {
            "comment": "If you have some facts (from another source), LLMs are fantastic in expressing those facts in human-sounding text.\n\nThe problem is that products are using the LLM itself as a source of facts about the world. This leads to all kinds of problems.",
            "points": "26 points",
            "children": [
              {
                "comment": "This is also where I'm at. Things like RAG/\"retrieval augmented generation\" (i.e. run a search query on external knowledge first, then generate a human-sounding response) seems like a much saner and slightly more predictable approach than \"prompt engineering\" (i.e. try to wrap inputs with some extra words that you cross your fingers will bias the LLM enough to output only the subset of it's knowledge that you want it to).",
                "points": "6 points",
                "children": [
                  {
                    "comment": "RAG is fantastic and already in use for things like personalized recommendations for music, books, movies etc. That's the perfect use case for it imo, you give it a big database and ask it for best matches, it'll scoop those up for you no problem.\n\nOf course this also leads to \"the algorithm\" shoving people down a pipeline of social media ragebait for the interactions, but that's another problem -- just likely to accelerate as it \"improves\".",
                    "points": "2 points",
                    "children": [
                      {
                        "comment": "",
                        "points": "",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "In my experience, LLM is great at ingesting documentation and providing natural language response to queries, pointing to the key phrases/words/part of the doc.\n\nA contrived example: someone who doesn't know what transactions are, and asks a LLM \"I want to group a set of operations where all happen or none of them happen\", it'll probably do the right thing and point them at transactions, and they can dig further.",
                "points": "2 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Been a user of copilot for the past year, and I've noticed that :\n\nit's very good at guessing what you're going to write in very popular languages like JS, TS or Python.\n\nIt's a good tool to churn out some boilerplate code (for unit tests for instance). I had to write a whole battery of unit tests the past 2 weeks, I managed the task in just under 6 work days, to write probably 150 tests. Most of these were very similar to one another, so I made a quick snipped to give the name of the tests, and the comments to guide the AI into writing the proper tests. Made it a breeze to implement, by the end of things, I was able to churn about 40 tests in a day.\n\nWhere Copilot gets useless is when it doesn't have any idea of what the code is supposed to do in the first place. That's when the tool really is just fancier code completion. Other than that, for very common algorithms, it gets the job done, and when it generates 5 to 10 lines, it's not the end of the world to either proofread, or just write manually, and let it complete shorter code snippets.",
        "points": "16 points",
        "children": [
          {
            "comment": "probably 150 tests. Most of these were very similar to one another\n\nIsn't this the point where you abstract the similarities away and feed test data into it in the form of tables?\n\nIt obviously depends on the amount of \"similar\" and the amount of \"expected similarity in the future\". I'm not trying render a verdict on your case specifically, but \"the ability to churn out lots of similar code fast\" sounds like a potential trap.",
            "points": "6 points",
            "children": [
              {
                "comment": "Isn't this the point where you abstract the similarities away and feed test data into it in the form of tables?\n\nFor context, these tests were testing the API modelisation of a flutter app, so pretty simple use case, and every concern is well separated.\n\nI did not fall into the trap of \"oh I'm going to make a factory function to test these\". It would grant me job security, but would be hell to maintain afterwards. My tests are basically testing that the models can serialize/deserialize to JSON recursively from dart models.\n\nSo it's repetitive in the sense that I'm testing the values of each json, and testing the type of the values as well. But making a magic method somewhere to abstract that away would only serve to gain time now, and have tests nobody can understand.\n\nI have the same problem at work with our backend. \"Senior\" (with large quotes) engineers decided on making helpers on helpers on helpers for the most mundane things in both unit tests and feature code. The result is Mixin classes abstracting away 3 lines of code, one of them being the class definition.\n\nDRY is only a good practice until it actively hurts the readability, discoverability and understandability of the codebase. Those same engineers decided on making a \"CRUD\" testing function that takes in a \"check\" argument (a function as well, callback, untyped) to \"automate\" unit testing of endpoints.\n\nGuess who got the delightful evening of troubleshooting flaky tests at 11PM.",
                "points": "1 point",
                "children": [
                  {
                    "comment": "I’m generally of the opinion that a little copy paste isn’t too bad in test code in order to bring more clarity to the test method. But that isn’t what the commenter is describing. They’re asking why you didn’t use property testing if all these tests were so similar.",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "The problem for me is that, when writing Rust, the suggestions are often wrong. Too often. The corpus there just isn't large enough.\n\nSwitching to TypeScript, it frequently it suggests outdated things.\n\nI think that copy pasting from Stack Overflow is inherently less bad than the AI suggestions.\n\nWhen you copy paste from SO you know the answer is not for your question. It's the answer for someone else's question that happens to match your question.\n\nThe AI answer however is presented to us as the answer to our question. But it's not. It's just the logical completion of the previous tokens, whether that is text or the code.\n\nAnd I don't struggle with the logical completions. They're plumbing, but not hard.\n\nBut the whole AI movement makes me look slow when I'm actually writhing code that answers the business questions. And there the context is in my head and not in the code. This is the engineering part.",
        "points": "4 points",
        "children": [
          {
            "comment": "I have the same experience. I was hoping that with the quality of documentation of some of the techs I use the LLMs would perform better, but it seems bulk LOC is what matters in most of the AI assistants.\n\nThere are some promising models that use higher quality training material instead of just quantity, which could circumvent this problem, but I've yet to seen a product based on them.",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "I almost never use it to write code, though it did help need get started on a tricky recursive function I needed to write one day.\n\nIt's great for education though.  Really valuable when you come up to something you aren't familiar with.",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Github copilot is useful, but it recently generated a a comment to a YouTube link for REM’s end of the world. I realize this sounds fake. I wish it was, but its not lol",
        "points": "3 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "We really need to be clearer on the distinction between actual artificial intelligence and machine learning models, because even in this thread for programmers there are people who have uncritically embraced the hype",
        "points": "28 points",
        "children": [
          {
            "comment": "",
            "points": "",
            "children": [
              {
                "comment": "Maybe so.\n\nIt could also just seem that way because of how easily hype online drowns out a lot of more mundane discourse.\n\nFor example, I'm a tech lead. I often get asked about this topic by either management or developers under my direction. For both groups, I've been able to have good conversations guiding them away from the hype and into a position of critically evaluating the technology and understanding where it is a helpful tool, and where it's not ready for prime time.\n\nSo I think at least on the small personal scale there's still plenty of opportunity to course correct on this - just maybe not so much when it comes to the overall direction of the online discourse.",
                "points": "10 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": true
          },
          {
            "comment": "",
            "points": "",
            "children": [
              {
                "comment": "Well put.",
                "points": "1 point",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "No. “AI” was previously a goal state, not something we had. It was understood to be affiliated with general AI. That’s why we used to call this stuff machine learning instead. Then a marketing exec realized these models would sound a lot cooler if they just started referring to them as AI. And here we are.",
                "points": "-1 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": true
          },
          {
            "comment": "",
            "points": "",
            "children": [
              {
                "comment": "There isn't one.\n\nIn my mind, actual AI requires at minimum a degree of general understanding/comprehension with the ability to extrapolate in new scenarios.\n\nLLMs are nothing more than models that trained on existing data, and cannot extrapolate. They only appear to be intelligent because their output comes from sources produced by actual intelligence",
                "points": "3 points",
                "children": [
                  {
                    "comment": "There's literally a Wikipedia article on this:\n\nThe AI effect occurs when onlookers discount the behavior of an artificial intelligence program by arguing that it is not \"real\" intelligence.[1]\n\nAuthor Pamela McCorduck writes: \"It's part of the history of the field of artificial intelligence that every time somebody figured out how to make a computer do something—play good checkers, solve simple but relatively informal problems—there was a chorus of critics to say, 'that's not thinking'.\"[2] Researcher Rodney Brooks complains: \"Every time we figure out a piece of it, it stops being magical; we say, 'Oh, that's just a computation.'\"[3]",
                    "points": "-1 points",
                    "children": [
                      {
                        "comment": "every time somebody figured out how to make a computer do something—play good checkers\n\nI get the \"gotcha\" but optimizing checkers with code is not AI. It's like calling A* an artificial intelligence because it finds the optimal path. But no one calls it that.",
                        "points": "2 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "I half agree. Yes, it does much worse with novel programming questions vs popular leetcode questions. But I dont think it does worse than an average programmer would either.",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": true
          },
          {
            "comment": "",
            "points": "",
            "children": [],
            "isDeleted": true
          },
          {
            "comment": "",
            "points": "",
            "children": [
              {
                "comment": "Only if you have an extremely generous definition of intelligence",
                "points": "5 points",
                "children": [
                  {
                    "comment": "Yeah. You’re confused. I suspect you mean something like Artificial General Intelligence.",
                    "points": "2 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": true
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "I think the technology's to young to really draw any strong conclusions from, but i do think the inevitable consequence of this sort of technology is less code reuse. It would actually be really surprising to me if it did have high code reuse, just due to how it works.",
        "points": "14 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "ya think?",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Is it any wonder when it suggests noob mistakes to you.\n\nI've been using it with react, and it always suggests that I toggle state directly, like setShowThing(!show thing) instead of setShowThing(curr => !curr).\n\nThis is a common newbie mistake, so because it is common, it is heavily weighted, so it's heavily suggested, so it's common, repeat.",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Gee, who could have predicted that leaning on an AI assistant to pump out code faster to satisfy product managers' desires for moving faster would produce lower quality code? /s",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "You are telling me the robot trained on the web, which consists of mostly bad code and questions about bad code, is...bad at code?",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I’ve found copilot very helpful as a time saver for writing any rote/repetitive/obvious code: finishing a spec that’s 80% the same to the one above it, template boilerplate, very simple convenience methods, stuff like that.\n\nFor anything more complicated I’ve found it a distraction. I’ve configured it to only suggest code when a hotkey is pressed, which feels like it should be the default. I summon the suggestions only when I feel very confident it’ll do the right thing so they don’t get in the way.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "All of this effort putting \"AI\" into code generation, all I want is fancier static analysis. It'd match the Copilot name a lot better, too.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I've seen ChatGPT used at work by newbies to code things they don't understand, and I think that's harmful in multiple ways: it increases the chance of latent bugs and postpones, perhaps indefinitely, technical growth. In one respect that's good for people who take the time for true self-development, as it creates endless long-term opportunity, but it can be a short-term hindrance. I try to rescue people from this when I can.\n\nI've also seen it used more than once now as an authority during arguments, again by newbies and sometimes supporting a wrong position. Unfortunately the proponent in such a case isn't equipped to realize their mistake easily, and if it's a particularly pushy person may even double down.\n\nOver-use of ChatGPT for technical work seems to go generally with a somewhat quick-and-easy/lazy mindset. Such personality types arguably aren't cut out for acquisition of deep expertise in the first place.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "are you supposed to be surprised?",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "No duh. I don't know why people think AI tools are going to write perfect code. It can be a great assistant for sure...but you really don't want to just blindly trust it like Tesla autopilot.\n\nI'm very convinced at this point that we'll see a major global Internet security event due to someone being lazy using AI and not reviewing the code.\n\nGranted this could (and has) happen without AI in the picture, but AI only makes people even lazier...but you know, it's got what plants crave.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "This is such a weird article and weird whitepaper. \"Churn\" is nebulous. Have any of you commenting on the \"churn\" in this paper even taken the time to lookup what it means? Aka read the whitepaper?\n\nI did.\n\nIt means \"code that was significantly changed or removed within 2 weeks of commit\". Now. That could be significant, but is it a guarantee of \"churn\"? That could just be that we have the ability to refactor faster. Hell it might be a beneficial thing.\n\nI think this analysis of numbers without discernment is meaningless. And I think you should all take the time to read through things before you form hasty opinions.\n\nThe only possible takeaway is that, code is written and updated faster. Whether that's good or bad is not able to be determined. Much less the wild ass leap this article took about code quality.",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Better LLMs will fix this in the near future.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Because idiots think AI is intelligent in the sense of replacing them",
        "points": "-1 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "GPT is great for i18n (copy paste entire Vue component, tell it to use vue-i18n component interpolation when necessary and to give you the extracted string in JSON format, done).\n\nCopilot is great to generate logging messages based on the context. Most of the time it just needs one example of how you like to format the string, and you then just write logger.info and tab to auto complete.\n\nAs for finding complete solutions, they both suck, I almost never use them.",
        "points": "-1 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Should it be writing your core logic for you? No. But it does a pretty good job creating documentation (like javadocs) and initial unit tests. That alone is a big productivity boost.",
        "points": "-1 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I wonder how this looks if you break it down by how users are working with copilot. Personally (as a grad-student mind you, so project complexity is limited) I find it to be a very effective autocomplete if it's essentially blindingly obvious what I already want to write. However, the moment it tries to make any sort of structural decision I find it to be thoroughly unhelpful",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "If you give such a tool to someone without much experience (i.e. knows what good code means) and/or someone working in a team without good coding standards, it will decrease quality.\n\nPersonally I've found these tools be to useful (I use CodeWhisperer daily at work). Helpful with completing simple/repetitive logic quicker, and it also picks up on your coding style after a while making it more robust. Writing skeleton tests, all in the same style, was a breeze for example. Overall, a time saver if used correctly.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "AI coding assistant is a complement to a human developer. For example I was using it a few days ago.\n\nIt was good at generating tests after I gave it the source and my examples. Saved me a lot of typing, but I still had cleanup to do, and had to correct a few cases.\n\nFor another task, It was useful because it was more familiar with SQLAlchemy then I was. Although it couldn't solve the problem to save it's life (modify my query to search for email ignoring periods in the local part but not the domain part), it's multiple failed attempts (and wow were they failures) did educate me on the various mechanisms in the library available, allowing me to solve it myself.\n\nIt's really at the level of a really exited intern that is really good at research, by lacks judgement.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "My own experience with copilot (in python) is it's pretty decent and boilerplating the boring stuff. As soon as you start tinkering, needing to deal with edge cases and whatnot, it's easier and better to do it yourself as it takes more effort to engineer the prompt than it does to just write the code.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Has anyone used the AI \"tools\" - I get downvoted every time, but I'll keep saying it, they're terrible. Copilot is mediocre at best right now; I have every hope that it improves and I have little doubt it will, but right now it's at best marginally better than google half of the time",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Turns out mindlessly copying code from any source isn't a good idea\n\nWhich is why I always take issue with the folk wisdom about great developers copying.\n\nThese things are great for getting a rough idea of something, but they cannot replace thinking or knowing your job.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "There is a strange psychology with co-pilot autocomplete. The code completions look good on the surface and it builds a bad habit of accepting it and then debugging it later, as opposed to reasoning about it upfront.\n\nI’ve found myself wasting more time fixing bad copilot code versus just writing it myself.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Yeah this matches what I found. You have to use it for small snippets and really test it out. Usually it's spot on but sometimes it inserts something that looks right but does something odd.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I’m mean, it was pretty damn obvious LLMs can’t make good code. Ask it to do anything non-trivial. But they are so useful for jumping into a new language quickly, learning the syntax.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac6x4r",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://makemychance.com/javas-static-final-variables/",
    "title": "Java’s Static Final Variables Explained",
    "points": null,
    "comments": [
      {
        "comment": "Yesss finally some blogspam!",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac65y8",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://newsletter.techleadmentor.com/p/vague-feedback-blocking-promo",
    "title": "Vague Feedback Blocking your Promotion to Senior Software Engineer?",
    "points": null,
    "comments": [
      {
        "comment": "Yes, but for Staff. Literally had a meeting about how to get to staff where they said to be in some leadership groups. These groups are focused on a certain technology and dictate certain directions. Guess what, I'm in 3 of them... That rug was pulled so fast, and moved to me needing to lead one of them",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac5wpw",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://medium.com/@AnalyticsAtMeta/being-a-senior-ic-59ee705ba3c1",
    "title": "Being a Senior IC",
    "points": null,
    "comments": [
      {
        "comment": "Key points:\n\nThe post discusses the role and expectations of a Senior Individual Contributor (IC) in the tech industry, particularly at Meta (formerly Facebook). It delves into the unique challenges and responsibilities that come with this senior position, emphasizing the importance of not only technical expertise but also soft skills like leadership, mentorship, and the ability to influence without authority. The article provides insights into how Senior ICs can effectively navigate their roles within large tech companies, contributing to strategic decisions and fostering a collaborative work environment.\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually 👍",
        "points": "-1 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I hate it when I accidentally become a Senior Integrated Circuit",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac48xe",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://lwn.net/SubscriberLink/959069/24c0b18e9fc1b073/",
    "title": "Turns out organizations exist for a reason - The things nobody wants to pay for [LWN.net]",
    "points": null,
    "comments": [
      {
        "comment": "Found this great read that gives a little history over corporate contributions to OSS and how they haven't found a critical mass at creating a movement anymore then home-grown inspiration any more then the die-hards at GNU.\n\nIf you've ever been a part of any large enterprise team, you might have seen this pattern too. Money thrown at engineering when there's a red-hot problem or the tech is the latest talk, but once long-term ownership sets in, you see it was less a commitment to the principles, and more an investment in a recent problem.\n\nIMO, this is one reason the Apache foundation exists, to hire engineers to provide some key \"extra\" roles such as localization or documentation for OSS code that is instrumental to most modern-day engineers.",
        "points": "7 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Companies, working in their own interest, have built up our body of free software hugely; it is almost as if this capitalism thing actually works.\n\nIf this is the highest you can dream, sure, but if you want something that works so well that you don't have to write articles about how poorly they're working, then capitalism doesn't seem too hot given the contents of this article.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac40qm",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://www.linkedin.com/posts/kishan-jaiswal-2586a4220_unitygamedev-gamedevelopment-dependencyinjection-activity-7156192078597607424-iIvC?utm_source=share&utm_medium=member_desktop",
    "title": "🚀 Elevate Your Unity Game Development with Zenject 🎮",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1ac3b30",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://asyncq.com/building-simple-http-client-in-java",
    "title": "Building Simple Http Client in Java",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1ac2zez",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://redixhumayun.github.io/databases/2024/01/26/extendible-hash-tables.html",
    "title": "Visualising Extendible Hash Tables",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1ac2dak",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://emacsconf.org/2021/talks/structural/",
    "title": "Why hasn't structural editing caught on?",
    "points": null,
    "comments": [
      {
        "comment": "I think the simple answer is that it is really expensive to maintain correctly structured code while writing it.\n\nFor example, we are used to writing \"[1, 2, 3\" and then finishing that off with a \"]\".\n\nBut that initial fragment isn't structurally sound, so you couldn't have it in a structural editor, per se, or it would need to be handled as some special case.\n\nWhich gives two approaches:\n\nforce input to be structurally sound and figure out a way to make that efficient\nallow text to transition between structurally sound and unsound forms\n\nMost editors have focused on (2) with pretty good success.\n\nI have yet to see a reasonable solution for (1).",
        "points": "83 points",
        "children": [
          {
            "comment": "I just want the editor to assume that my edits are local. Don’t color the rest of my file in red because I edit an expression. Like as a stupid rule, check from both sides using diff. Needs history. Can’t help this.\n\nIf I want to affect a large region, I fold it.",
            "points": "18 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "You have a good point, especially when it comes to pasted-in code that may contain syntax errors or structural errors (for example in C, putting a statement into an expression).\n\nThough it does require a shift in both mindset and editing workflows, I think it's possible to write code that remains structurally intact the entire time. For this array example, imagine this sequence (key press on left, resulting code on right)\n[ [|]\n1 [1|]\n, [1, |]\n2 [1, 2|]\n, [1, 2, |]\n3 [1, 2, 3]\n\nNow imagine that if you were to exit or do anything else when you're in the state of a comma with an empty item, the editor can simply remove the comma and go back to the previous state.\n\nAlso as it stands, structural editors \"cursor\" is actually highlighting an entire valid syntax construct. So this example isn't exactly correct, but IDK a better way to convey it.",
            "points": "20 points",
            "children": [
              {
                "comment": "It's obvious that it is possible.\n\nThe question is to find a way to make it sufficiently efficient to be competitive. :)",
                "points": "29 points",
                "children": [
                  {
                    "comment": "All the edge cases. The editor would have to know the structural soundness rules for all languages.\n\nThis is kinda moot with language servers anyways.",
                    "points": "14 points",
                    "children": [
                      {
                        "comment": "The expensive part is in the interaction with the human.",
                        "points": "8 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "For this array example, imagine this sequence\n\nWait, isn't this how most code editors already work? :D I don't know, I feel like a good amount of code I write in IntelliJ or VSCode is already kind of structural editing.",
                "points": "3 points",
                "children": [
                  {
                    "comment": "For that specific example, sure. But there are countless other examples where the first thing you type results in unsound code. You’ve just typed “w”, and there is no variable named “w”, so your code is unsound. Maybe you’re about to type “hile” to begin a while loop, or “indow” to refer to your window variable, but the “w” by itself is meaningless.",
                    "points": "3 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "If you write a [, just auto-append a ], as besides string literals, they can never be unpaired in most programming languages. Then it will always be in a sound state",
            "points": "3 points",
            "children": [
              {
                "comment": "Editors do that already\n\nThat's not a solution. You can easily construct cases where this is not enough. JavaScript: () =>| what can we fill here to make it sound? () and {} are both syntactically valid but semantically different and {} is even ambiguous by itself and thus not sound at all",
                "points": "5 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "Every IDE I've used for 15 years has done this out of the box by default.",
                "points": "2 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "More to your point, I think there's the potential for \"fluid structural editing\" where you have a normal text editor that can perform structural editing and navigation operations on demand. Barring an editor that's primarily structural, I think this idea has potential to catch on as an extension to existing editors.",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "\\1. is just not possible. You can't keep everything correct while typing. If you try, you might have to make big changes to the code.\n\nPython: if True:| what to fill in here? You must add pass in the next line until the user starts typing something, then you need to remove pass again. Doing this would make the code jump around a lot. Nobody would use this editor",
            "points": "0 points",
            "children": [
              {
                "comment": "Tree edit python already exists https://www.reddit.com/r/emacs/s/HUbl04WyAv\n\nIt's not impossible, it's just a design problem.",
                "points": "0 points",
                "children": [
                  {
                    "comment": "Wow that looks annoying to work with. They avoided the issue mentioned above by forcing you to write everything from the inside out. 1) half of the time you are moving the cursor around to replace the auto generated symbol 2) you can't just write the code down you have to think about in which order you have to write it down\n\nThank you no way I'd ever use that",
                    "points": "-1 points",
                    "children": [
                      {
                        "comment": "How do you know that it doesn't let you edit another way?",
                        "points": "0 points",
                        "children": [
                          {
                            "comment": "You can see in the video how syntax is created and how much you have to move the cursor vs how much you actually type",
                            "points": "-1 points",
                            "children": [
                              {
                                "comment": "\"have to\" bro the navigation is there to show off... Structural navigation is super fast in tree edit. Please stop commenting with your negativity and assumptions.",
                                "points": "-2 points",
                                "children": [
                                  {
                                    "comment": "You asked why tree edit doesn't catch on, I give you an answer why, and you call me negative? Like wtf? Besides what I already mentioned another reason is that you'd want to have invalid states while coding (note taking (not permanent notes; rather plans to what is still left to code in the function/algorithm), hashing / writing out ideas and see if they lead anywhere, copy pasting code that needs to be fitted in, translating code from a different language, etc)",
                                    "points": "1 point",
                                    "children": [
                                      {
                                        "comment": "At least look into things before you make a knee jerk criticism",
                                        "points": "-3 points",
                                        "children": [
                                          {
                                            "comment": "I did",
                                            "points": "0 points",
                                            "children": [],
                                            "isDeleted": false
                                          }
                                        ],
                                        "isDeleted": false
                                      }
                                    ],
                                    "isDeleted": false
                                  }
                                ],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Your example could maybe be solved with some kind of auto matching, but you couldn't do that for something like\n\nlet x =\n\n\nwhere you haven't typed yet what comes after the equal sign. I guess the editor would put some kind of placeholder there?",
            "points": "0 points",
            "children": [
              {
                "comment": "Well for let, the editor would just write \"let x;\"\n\nIn the case of const, yea maybe a placeholder. But how often do you write a variable name without a value?",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Imagine how much worse it would be for python and other languages with significant whitespace.",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "I'm the author of Combobulate, a structured editing and movement package for Emacs. So this is just my viewpoint, although I agree with Ethan pretty much all of what he says, even if his talk is a few years out of date now, and things have advanced a bit since then.\n\nThe problem is there is usually an infinite number of choices that can reasonably follow most production rules, and you'll have to build an interface that can credibly provide just the ones a programmer think they'd want to see, which is a tricky thing indeed to get right. Then there's the fact -- as others have alluded to here -- that if you write invalid code, then it's much harder (or impossible) to provide the user with valid and useful editing options.\n\nSecondly, there's the hidden cost of tree editing: you have to format your newly-minted code! That is not trivial: whitespace, newlines, indentation and formatting styles have to be accounted for, at least a little bit.\n\nMost programmers want to put their code into a broken state all the time: whether it's refactoring or just typing out a line of code.\n\nStructured editing/movement adds a lot of value to all manner of ancillary tasks, though: select all words named \"foo\" and let me edit them in parallel; find all function calls called bar; expand ever-larger selections of text, by syntactic unit; better and more correct navigation; complex search and highlighting.\n\nSo, having a concrete syntax tree is very useful, but you're also drinking from the fire hose, and all you've really done is formalise all the problems you had with regex/ad hoc parsing code. You haven't really 'solved' most of them with a CST.",
        "points": "38 points",
        "children": [
          {
            "comment": "I'm curious in what ways things have advanced since this talk.\n\nThere's definitely a MASSIVE design issue when it comes to structural editing workflows, expectations, etc. I have some novel ideas for how an intuitive structural editor could be designed, and I wish I had the time to test them out. I want to write an online JSON editor web app that uses structural editing and is also designed to be touch screen friendly.\n\nCall me idealist, but I think that programmers can learn to write code without breaking things mid-way. That's definitely part of the whole design problem, though. It needs to be nice enough that it's worth using.\n\nFor the formatting issue, it makes me think that the ideal is something like, you read the code into an AST, which is then \"rendered\" either to the user's screen or to the file itself on write based on two independent sets of specified rules. Like for example, you could split long args into multiple lines only when the window is resized. Though that in itself would be a huge undertaking.\n\nOverall, I'm getting the sense that the reason structural editing hasn't taken off is simply that it takes a massive amount of human effort to push forward this paradigm shift, to the point where languages themselves might even need to be designed around it in the first place.",
            "points": "3 points",
            "children": [
              {
                "comment": "JSON is simple enough to meet that goal.\n\nTo clarify, you do not want an AST: you want a concrete syntax tree which preserves tokens that are ejected from an AST. ASTs preserve just enough information to allow a compiler or some other tool to transform the AST into something else. Tree-sitter yields a CST, though even TS drops or merges rules to tidy up the tree a bit. You want a CST because you care about all the little tokens that an AST would find irrelevant: like ,, {} and whitespace. (You don't need those in an AST when you know you have an object or a list).\n\nYou need those because you want to format your code and so you need to know where these tokens would logically be in your tree. That is also what makes it challenging, because you have to ensure they're placed not only in the right place syntactically, but in a way that a human would find pleasing. That means you'll have to write a formatter for what ever language you want if you want to adaptively reflow/rewrite/generate code from a tree, be it one you've parsed or one you've created synthetically. For simple thing like JSON, that's easy. But try convincing C programmers to agree on one set of formatting rules for their code :-)\n\nWriting those rules, as you talk about, is indeed the key. It's not hard, just time consuming and... well, boring. You get into structured editing because you want to do cool shit, and then you find out it's 99% dealing with formatting and other, tricky, problems.\n\nOverall, I'm getting the sense that the reason structural editing hasn't taken off is simply that it takes a massive amount of human effort to push forward this paradigm shift, to the point where languages themselves might even need to be designed around it in the first place.\n\nThat language already exists. It's called LISP. That's why tools like paredit is 'the whole grail' among structured editing fans. Manipulating a language that is itself the CST and also the language you write makes things easy. Homoiconicity has its advantages here. And LISP is syntactically very simple; not so for languages like Python, JS, etc.",
                "points": "14 points",
                "children": [
                  {
                    "comment": "I get the feeling that modern languages (and communities) are moving towards the direction where you have one canonical source code formatting for particular syntax tree, or at least are taking formatting decisions away from programmer as much as possible. For example gofmt and rustfmt. I don't know if they are purely AST based or something in-between, but I think things are definitely moving towards that direction. Another example is Python which started with very basic and lax pep8 rules but has now evolved into \"black\", a very strict and opionated formatter.\n\nSo while I agree that especially for something like C and C++ formatting is very tricky problem, I imagine for many others its far less so? But that very question does raise the point that text editing has the benefit of universality, and structured editing inherently is coupled to the language to a degree.\n\nWhile discussing formatting, I want to bring up one of my favorites, Fortress (from Sun). It had the option to render code as beautifully formatted rich text (through tex). I think that could be really interesting concept to try to marry with structured editing, because as a developer you would be already one step removed from the plain text. Of course Fortress was not fully developed and I don't know if the rich text rendering was AST based or what, and the tex->pdf pipeline would have been wholly unsuitable for real-time editing. But it's a glimpse of something.",
                    "points": "2 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "I appreciate you clarifying AST vs. CST, it makes sense to me now thinking about it.\n\nYea I kind of wish I could make the case for structural editing in like, a kickstarter or something type thing and get people to fund it so that I can hire people (and involve myself) in the boring work to make it happen.\n\nSince you're saying this would be easy with JSON, now I'm getting more tempted to try to make this project. I just know most people won't bother to upload/download JSON files just to use the editor, so it's mostly a playground piece...\n\nAnd yea lol, I'm lisp pilled. I see every language as a worse LISP at this point. I go even further though, and I think it's possible that the full realization of structural editing hasn't even been thought of yet. I want to get there.",
                    "points": "1 point",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "For what it's worth, structural editing in the way you've described might be a boon for accessibility purposes. Additionally, with the autocompletion suggestions we have today and the advent of LLMs for code help, I imagine that some of the navigation and tree options could be made easier/more intuitive based on heuristics.",
                "points": "4 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "For the formatting issue\n\nPlease realize there is no formatter in existence today that can format code as well as a human.\n\nTake parameters. No formatter will make logical groups of parameters when they exceed the line length. Humans can.\n\nTake arrays. I know a specific array would be most readable formatted as 4x4, but no formatter will, and will happily cram together as many entries as will fit on a line.\n\nFluent method calls. I know that there are logical groups that can be made to improve readability. A formatter won't.",
                "points": "4 points",
                "children": [
                  {
                    "comment": "The CST contains data on comments and extra whitespace, which ofc are still possible to add in a structural editor. It doesn't remove the ability of human formatting.",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Very interesting, and very interesting topic globally. It seems that the important part is to be open minded and see the various spaces a programmer lives in and be able to provide the right paradigm at the right time. As a paredit lover I have no issues with limited s-edit (didn't have a chance to dig into newer ideas like parinfer or combobulate yet) though. But it seems that a lot of people don't like to think above syntax, they 1) really like witnessing magic syntax 2) don't think meta/macro level (most of the mainstream drives you away from that somehow).",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Now I know what to call the thing I've been wishing for and advocating since like, 2000.",
        "points": "8 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Because the tree structure provides little useful information for \"what comes next\". For example, you can give GPT a function name in totally bad pseudo code syntax and it will spew out something related. But you can't tell GPT to \"write a class with 2 methods\" and expect anything useful.\n\nThat's why enforcing tree structure during edit provides little value: a missing or wrongly-placed } can totally change control flow and cause a disaster when running the program. But it doesn't make the code much harder to work with as an intermediate state. All names and comments are still there and one can still deduce the intention.",
        "points": "3 points",
        "children": [
          {
            "comment": "To add to this. Creating new code, or trying to come up with an idea and expressing it into rules that can become code is difficult and is the real mental challenge for a decent amounth of programmers. This becomes more difficult with these editors because suddenly you’re forced to think about which strict set of keystrokes will allow you to write that code unless the editor is REALLY good. And even then it takes a mental capacity that is far better spend thinking about the fundamental problem your code must solve. And keeping these editors even a slight bit up to date is difficult.\n\nIt’s like painting. The first strokes on a blank canvas make absolutely no sense whatsoever, and trying to frame them into a very specific workflow is useless. Only once everything comes together is where you might get something out of a framework like “brush left to right” or something like that.",
            "points": "1 point",
            "children": [
              {
                "comment": "Just because you're used to an inferior mode of editing doesn't mean it's \"less brain power\". Structural editing is closer to how we actually think, it is actually less brain power.",
                "points": "-1 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "laughs in common lisp",
        "points": "4 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I recently discovered this talk and I'm wondering why structural editing hasn't caught on? It looks faster, more able to avoid programming errors, and potentially more accessible to phone users and dictation. After structural editing some lisp code myself, I found it far superior to standard editing operations. Tree-edit also supports C, Java, and Python, and I'm wondering if anyone has used it to edit those languages, what they think about it. Is this the future of programming?",
        "points": "6 points",
        "children": [
          {
            "comment": "Maybe I'm kind of stick in the mud, but I frequently find myself leaning the opposite way from this kind of thing -- wishing I could put the brakes on autocomplete and autoformat features when I'm doing some rapid fire coding. It's just that the intermediate states can sometimes be so far from anything those features recognize that they, at times, do more harm than good when they, for example, autoinsert close quotes or automatically fix a \"typo\" etc. I would actually love if some IDE had a quick shortcut to toggle them off/on (as long as it was really quick because I wouldn't want them off for very long) so I could WYSIWYG-style code quickly for a little bit and get them back on once the code is in a more stable position.",
            "points": "14 points",
            "children": [
              {
                "comment": "I feel like there's an \"uncanny valley\" effect where \"smart\" features suck because they're just dumped on top of what is really a plaintext editor. For example let's say you have some list with the cursor in front.\n\n[|1, 2, 3]\n\nAnd then you press '['. Most editors will then give you this:\n\n[[]1, 2, 3]\n\nBut what if you actually wanted to do this?\n\n[[1, 2], 3]\n\nThen you find yourself finessing the code in some silly way to solve the issue, likely way more hassle than a plain insertion. I use doom emacs with evil-mode and evil-surround, so I would type ysf2] in order to achieve that edit. But I find myself wrestling the editor all the time for this sort of thing.\n\nStructural editing, if it's ever going to be a thing, needs to be intentional on the part of the user. I don't want to add more \"smart\" features that cause random crap to pop up or unexpected character inserts. I want a conscious paradigm shift.",
                "points": "12 points",
                "children": [
                  {
                    "comment": "But what if you actually wanted to do this?\n\nAt least in IntelliJ, you select 1, 2, press [, and get [[1, 2], 3] out of it",
                    "points": "10 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "Emacs can do this already if you mark the things you want. The builtin M-( also tries to be clever and will wrap (especially in LISP-likes) the sexp ahead of point. Combobulate's own version is far cleverer and it will analyse the nodes at/near point and try to intelligently wrap the right thing. So it'll correctly ensnare an expression like 1 + (2 * 3) / foo(1, 2) with a simple press of a key: and if you do not agree with its choice, you can tab until it picks the one you want.",
                    "points": "5 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "Some freeform:\n\nI agree with you that structural editing would require a conscious effort to rewire one's interaction with text. It reorganizes what it means to be a unit of interaction. It's a different mode -- we're not even editing text anymore, so the usual practices are changed. No longer do we have to think about where we wish to make a change, but also at which level. Keys now represent plain text only at the level of identifier. At other levels, they are commands that install structures defined in the grammar of a language. Plain text is only a representation detail.\n\nFor the example you provide, my thinking would be this.\n\n[ {1,} 2, 3]\n\n[ {1, 2,} 3]\n\n3a. [ {[1, 2],} 3]\n\n3b. [[ {1, 2} ], 3]\n\n@1, 1 is selected.\n\n@2, selection is extended.\n\n@3, selection is contracted into a single node / deepened.\n\nThis would be two key commands - one to extend selection, second to deepen.\n\nNow any model that thinks about this as plain text is invasive and would have to be expunged (into a different mode). Mixing the two together adds complexity that I'm not sure it is possible to extract (maybe, but only after structural editing interfaces are well-developed and undergone some Darwinian pruning). Plain text operations are only insertion and removal of characters at an index in the buffer. Structural operations are insertion and removal of typed nodes within the tree. The fact that nodes are typed is both a con and a pro – it adds complexity, because selection of each node within a tree will admit different operations, and each grammar defines a different set of these. The pro is that you can't make grammar errors anymore, you can be more precise in selection and intention, etc.",
                    "points": "1 point",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Well tree sitter can handle not quite correct code in many languages and I know lapce uses it for editing support.",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I'm an anarchist. I just start writing.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "There exists no scenario where I want characters that I did not type (or select via intellisense) to be inserted into my code.",
        "points": "1 point",
        "children": [
          {
            "comment": "There exists no scenario where I want invalid syntax in my code.",
            "points": "-1 points",
            "children": [
              {
                "comment": "Code exists in transient states between builds/compilations. I'm perfectly OK with my code not running, updating, or reflecting the state of what's running in test/local if I haven't saved, for instance. Likewise, I can't rely on syntax as an indication that my code is runnable-i could have a null reference exception, runtime failures, etc. I don't know why I would care about syntax except as it impacts readability of what a program is doing/ pleasantness to write.",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Because typing skills are the easiest aspect of programming to acquire. Keyboards work well, so long as you're sitting at a desk. Moreover, your typing skills can gradually improve along with your conceptual understanding in a way that I suspect many developers barely notice. And when you get to the point where your physical typing speed is the bottle-neck, the automation afforded by a properly-configured editor or IDE is a serious force multiplier.\n\nThere are times when I do wish I could do high-level structural transformations on code, but even then, I can usually cobble together some ad-hoc regex solution or a particular sequence of keystrokes to get the job done at a tolerable pace. In any case, sweeping changes to code like this are rare, and for good reason.\n\nSo much of time is spent thinking: reading code to understand it, or trying to catch things in the debugger, or staring at log messages, or doing proper up-front design.\n\nFor reasons that are both historical and theoretical, computer languages and computer programs are oriented around linear sequences of symbols, and so computer languages are naturally mapped onto text. There's a great deal of freedom that comes with this. There's a great deal of tooling and infrastructure that is predicated on the notion of code-as-text. Computer languages are carefully designed to be comprehensible when read linearly.\n\nI suspect structured editing would be a win on tablets and other devices that lack a physical keyboard, but you'd still be less efficient with it than someone with experience and even a basic keyboard.\n\nGiven that the major tablet platforms don't exactly encourage direct development on said devices, we simply never got to see what serious structural editing on a touch-screen looks like.\n\nThe place where I can see structured editing really thriving is not so much for code, but for documents. I think a lot of applications would benefit from directly exposing the document structure as one possible mode of interaction, and there you might find structured editing that is tailored to nature of the document data to be a productivity boost. Here I'm thinking of word processing, spreadsheets, and even vector drawing.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Because it's not useful? His demo shows about 16 lines of code and the AST tree structure is a lot lot longer. And anyone who's ever examined an AST for an expression... it's ok, you're in your safe place, the bad bad tree is gone... will know expressions generate really big wordy trees.\n\nAnd what problem does this funky editor actually solve? I'm spoiled by Visual Studio because it offers great intellisense, great problem highlighting (though that one character wide red squiggle can be hard to find sometimes).",
        "points": "3 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1ac0sqb",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://www.florianbellmann.com/blog/never-taught-qa",
    "title": "You are never taught how to build quality software",
    "points": null,
    "comments": [
      {
        "comment": "\"My uni didn't teach QA, therefore no one is ever taught to build quality\"\n\nLike, no? Computer Science focuses on algorithmic correctness & optimization, Software Engineering focuses on the process and quality of the craft. Sorry your schooling didn't include quality, but like a lot of things, it's not required to get an approximation of the job done (see boot camps).\n\nQuite a bit of generalization going on there.",
        "points": "373 points",
        "children": [
          {
            "comment": "My school had a grad level course for SE and Devops. QA was part of it",
            "points": "34 points",
            "children": [
              {
                "comment": "Any books you'd recommend?",
                "points": "8 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "But how about code patterns? Software architecture? Algorithmics means very little in terms of writing maintainable software",
            "points": "24 points",
            "children": [
              {
                "comment": "yes and yes. my uni had courses for that, too. heck, there was an entire department dedicated to architecture",
                "points": "41 points",
                "children": [
                  {
                    "comment": "Same for me, upon entering the degree they made a difference between computer science and software engineering (among others). The software engineering specialization was precisely this.",
                    "points": "10 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "Same, my master’s degree is in computer science and my \"specialization\" (not sure of the term here) was software engineering. It feels very wrong to not be taught both at uni.",
                    "points": "9 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "Yeah I also had a Quality Assurance course, a Software Architecture one, two \"Software Engineering\" ones, one Object Oriented Modeling (BS though, UML crap all the way lol). And I wasn't even in the software engineering specialization.\n\nAlthough honestly I don't think those were super useful. All the pattern and architecture stuff never felt super grounded in science but it's more a flavor of the day stuff.\n\nBack then was lots of OOP/GoF patterns whereas I worked in embedded and 3D at that point where mentality was very different from the Enterprise Java world.\n\nAnd the QA stuff is so much talk... I mean to understand the difference between blackbox testing and whitebox testing you need 20 seconds, not a lecture ;). Before university, even earlier we spent tons of time on Nassi-Shneiderman, requirements specification docs (Pflichtenheft, Lastenheft etc. in German. They loved this stuff and had us write tons of docs for toy examples...).\n\nNever did any of that in practice in the end ;).\n\nI mean, it's probably good to have such courses and be exposed to all kinds of stuff that might be out there. But I never felt super enlightened by them ;)",
                    "points": "2 points",
                    "children": [
                      {
                        "comment": "from Pflichtenheft to Lastenheft alright. In some courses, Universities are just teaching what the old Profs thought the industry demands. Same goes for \"learning\" SVN in my case.",
                        "points": "0 points",
                        "children": [
                          {
                            "comment": "Hehe yeah I mean to be fair the institute I mentioned above at university was led by people who also ran a software company. So it wasn't just some Fantasy.\n\nBut what I've seen from a friend who started working there, the customers are all... Pensionsversicherungsanstalt and similar, government, banks etc. Where those things do exist in some form. I remember when one time he told me that they needed 3 weeks to change a date field in a form with a couple meetings and calls with the architect and the dependency management guy and testing/QA department and so on.\n\nIt's so different from my world where in 3 weeks we typically roll out a completely new PoC product to customers and products that don't sell well got stomped all the time.",
                            "points": "0 points",
                            "children": [],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      },
                      {
                        "comment": "For our testing course, we did lot of timed automata, automatic provers and some math for understanding step permutations of explicit testing for different levels of coverage.\n\nIt was pretty nice, even if it doesn't translate into the experience inside 99% of companies.",
                        "points": "0 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  },
                  {
                    "comment": "Then I'm jealous AF. I couldnt find uni in my country with subject similiar to software architecture in its syllabus",
                    "points": "1 point",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "Computer science != software engineering",
                "points": "15 points",
                "children": [
                  {
                    "comment": "Many education tracks mix both.",
                    "points": "7 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Comp Sci does not teach you how to build good software. Look at the progression of a junior developer to senior over say a decade. You would learn so much.",
            "points": "9 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "The major for my bachelor was software development, while it definitely didn’t cover enough detail at all it did have the introductory needed",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "People who study Computer Science expecting Software Engineering:",
        "points": "68 points",
        "children": [
          {
            "comment": "My school had a specialty path in its CS bachelors degree for software engineering. It was 2 software engineering classes ( agile and waterfall) and 2 testing courses ( testing process and QA). So few people took these courses who all planed to be software engineers. Most the people I work with never had these in their degree and it shows. When I would bring up formal ways to model software or create tests they look at me like a moon man. As a Senior now I can apply these and finally am on a team with a staff engineer that knows and uses them. He basically learned them on his own because they didn’t teach them in school. Always keep learning independently and be the change that is needed. Teach others",
            "points": "3 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "My anecdotal evidence:\n\npeople who care about quality will make quality software, whether they were taught or not\n\npeople who don't care about quality will make crappy software, whether they were taught or not",
        "points": "19 points",
        "children": [
          {
            "comment": "If you care, you will learn how to do it because you will seek that stuff out.",
            "points": "4 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "and many fields will pay you to deliver crap fast rather, so the 2nd group of people will \"thrive\" better",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Computer Science ≠ Software Engineering",
        "points": "71 points",
        "children": [
          {
            "comment": "FTFY: Software Engineering &SubsetEqual; Computer Science",
            "points": "2 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "You will end up getting taught UML nonsense most likely.",
        "points": "96 points",
        "children": [
          {
            "comment": "Drawings are a good way to illustrate systems. It doesn’t have to be UML, but if you can draw decent boxes and arrows it tends to make it a lot simpler to discuss changes or train new team members.\n\nPersonally I prefer drawing things by hand live in sessions instead of slapping a big diagram in peoples faces, but we have both. Hand drawing for training sessions, and diagrams for reference.\n\nI lean more towards the style of BPMN2 as I find it better communicates what needs to be communicated and has room for just saying “this box is hugely complex and you’ll need to look elsewhere”, plus the swimlanes, if used correctly, helps show separation of concern.",
            "points": "32 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "Yeah lets use flow charts in many colors. Ah yes also with arrows /s",
            "points": "5 points",
            "children": [
              {
                "comment": "In my experience, simple flow diagrams with some sequence diagrams where necessary are all that is really needed in most cases.",
                "points": "12 points",
                "children": [
                  {
                    "comment": "UML is a powerful industry standard to communicate with developers and stakeholders about how the system is designed. Everyone knows where you talk about.\n\nThose shitty flow charts are the reason why there are so much meetings because no one understands them.\nUML got different diagrams for multiple audiences. You can link them with each other.\n\nUsually those self taught programmers don’t understand UML since it’s not a part of their “become a programmer in 3 months”.\n\nSimon Brown has some nice talks about this and including the C4 model with UML.",
                    "points": "-9 points",
                    "children": [
                      {
                        "comment": "UML is a powerful industry standard to communicate with developers and stakeholders about how the system is designed. Everyone knows where you talk about.\n\nThose shitty flow charts are the reason why there are so much meetings because no one understands them.\n\nI couldn't possibly disagree harder. You got that entirely backwards. Everyone understands the basics of a flow chart: boxes linked together with arrows, pointing at the flow direction. You introduce diamonds for conditions, and they quickly grasp that as well if you add a question mark and yes/no paths. It's a great, almost-intuitive way to communicate.\n\nIn contrast, nobody understands let alone remembers UML. Why is this arrow filled and the other one not? Why is this line fatter than the other? Answer: who gives a shit? You've already lost your audience. It's a terrible communication tool conjured up by people literally with \"OMG\" in their name who need to touch grass.\n\nYou wanna communicate with fellow engineers? Make some ASCII art, either custom or with syntax like Mermaid. Sure, if you want to distinguish between synchronous and asynchronous by making your line dashed, do that, and swallow the rolling eyes in your audience. Beyond that, Stop. Making. Your. Diagrams. Complicated. they're diagrams, not rube goldberg machines.\n\nYou wanna communicate with non-engineers? Use even simpler visuals than that. Your intent is to be understood, not to be hated.\n\nYou wanna communicate with a computer? Programming languages exist.",
                        "points": "23 points",
                        "children": [
                          {
                            "comment": "Your example is exactly the problem. Boxed linked together with arrows. What does that mean? Is it consuming it? Or extending it? What are those diamonds? And you might have an idea at the company where you work, but does it have the same meaning in a different company. I bet you use a cilinder icon as database.\n\nUML is the language for this. There is no interpretation or assumption. Its just UML. Like we also have a standard diagram to design circuit boards and electrical schema’s, UML is the standard for software.\n\nI hope you are trolling with the ascii part.",
                            "points": "-8 points",
                            "children": [
                              {
                                "comment": "Boxed linked together with arrows. What does that mean? Is it consuming it? Or extending it?\n\nI don’t care. Those are implementation details. If I wanted to know your implementation, I’d look at that instead of at a diagram.\n\nWhat are those diamonds?\n\nConditions.\n\nUML is the language for this. There is no interpretation or assumption.\n\nAh but there is. UML doesn’t really answer those questions. It just answers them in a hypothetical high-level way. It’s both too abstract to actually serve as a real implementation, yet at the same time too concrete to be useful for a meeting. If you want to discuss your implementation with someone, do pair programming or code review. If you want to discuss the basics of a software architecture, UML is way too convoluted.\n\nI hope you are trolling with the ascii part.\n\nFor a multi-line code comment that explains the thought process behind a section of code, it’s great.\n\nFor anything more complicated, use Mermaid or similar.\n\nFor anything with a different audience, render Mermaid or similar to something graphical. Or use OmniGraffle or whatever.\n\nNot trolling at all.",
                                "points": "6 points",
                                "children": [],
                                "isDeleted": false
                              },
                              {
                                "comment": "I love me some cilinder icons, what you talkin' 'bout?",
                                "points": "2 points",
                                "children": [],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Lol just started learning it",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Joke's on you, I'm self taught",
        "points": "17 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Well, I think you might be projecting your personal experience upon all other programmers.\n\nBut it's just not the case for everyone, not even close.\n\nA lot of programmers are absolutely taught how to build quality software, through things such as...\n\nA) Interactions/discussions with fellow employees, particularly more senior employees,\n\nB) Or just VERY actively (in a highly motivated fashion) seeking out and constantly hunting down the BEST discussion books, articles, blogs, forums, videos, etc... on the subject of that programming language.\n\nC) Or other venues, such as school, training, or some university programs (in which direct interaction with professors and fellow students is where the real learning/passion occurs), etc...",
        "points": "57 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Sure wasn't. I figured it out with my peers.",
        "points": "13 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Either you are happily building shit software, or somebody has taught you how to build quality software.",
        "points": "6 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Let's be honest, this is a pretty vague and awful essay about how life is different than theory. It doesn't talk in detail about KPIs or any useful metrics, and alot of companies don't do great, but they do do better than whatever startup this poor dev encountered.\n\nDon't join a garage for your first job out of college. Join a company with experienced staff engineers. Learn. Don't have to be the initiator of the basics when you're 22.",
        "points": "9 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "A bit of clickbait, software quality is not the same as having processes for Quality Assurance. Basically just says that people should be doing more QA and that’s it.",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I have had a lot of changes in my thought process over the years on what \"quality\" software is. Sure, this touches slightly on the QA issue, but in reality I would argue you could have the most algorithmically perfect and tested way of doing something, but still have shit software in terms of features.\n\nIn reality I wouldn't want people to learn what \"quality\" software is because they won't benefit. Instead I would rather teach what can be standard practices to minimize workload and increase maintainability and couple that with a few lessons on case studies to build a solid foundation where the developer can feel comfortable breaking the rules for the right reason as they gain experience. The key for anyone looking to be senior or above is the ability to take in the business's domain into account and design around that in a way that satisfies the goal in the best way possible. I would argue some of the most \"quality\" software out there is probably not algorithmically beautiful, nor 100% tested. Maintainability is key ofc, but you also won't maintain anything if customers don't come, and I would love for all devs to be able to understant that at some level and realize we live in a world of tradeoffs.",
        "points": "3 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Speak for yourself mate, never went to uni, taught by someone that was largely self taught. Wrote a lot of bad but functional software. Learned the pain of long term maintenance. Read lots of books on software engineering practices and improved over time.\n\nClassic baity article with extreme heading, that isn't even capatilized properly.",
        "points": "10 points",
        "children": [
          {
            "comment": "Classic baity article with extreme heading, that isn't even capatilized properly.\n\nWhat’s capatilized?",
            "points": "-14 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Building quality software is an art that takes years and years of practice.\n\nI'm happy if the new intern/dev can figure out how to change the color of a button.",
        "points": "2 points",
        "children": [
          {
            "comment": "You have to READ a lot of software to learn how to write good software. When you spend weeks figuring out how something works, it gives you perspective on what works and what doesn't.\n\nPeople write too much software. Too large, too verbose, too many features that would better be left out.",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Would it kill universities to have a class that goes through clean code, code complete, and domain driven design?\n\nI have, in my career, hosted about twenty of those book clubs. They changed my life when I first encountered them.\n\nI don't feel like this is a big ask. One or two classes, maybe.",
        "points": "10 points",
        "children": [
          {
            "comment": "i feel like these things might be too subjective for academic learning",
            "points": "11 points",
            "children": [
              {
                "comment": "Maybe, but things like the principle of proximity, the span of a variable, aren't subjective. Those can be measured. The cyclomatic complexity of a function can be measured. They have even done studies on the fault rate of methods over a certain number of lines. Stuff that code complete talks about.\n\nOnly use variables for one purpose -> clear, not subjective.\n\nRegardless of that, a huge part of my job/experience is knowing how to balance solid principles and other goals. Should I increase coupling so I don't repeat myself or is it more important to keep these things completely divorced so some repetition is ok?\n\nI think for as much money as I paid for a degree, I should've been better prepared for tackling these realities. Instead they thought programming by contract was the way of the world.",
                "points": "-4 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "After I started learning about ddd I have finally started to understand at least something about object oriented programming, before that I was totally clueless. It's insane how through that you see the full power of oop",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "I think the problem is that a lot of the things you learn about code quality and how to write proper software on the job are tied to the scale of apps you create.\n\nUni or courses can't exactly teach you that it's important to write code in a certain way because Team XYZ will include such and such functionality two sprints down the line.\n\nA lot of the proper practices just look overkill and bloated in a mini-project you build during a course",
            "points": "0 points",
            "children": [
              {
                "comment": "Hmmm, I think all three would still apply personally. You certainly wouldn't benefit as much from Ddd and might struggle applying it.\n\nBut I prefer not to look at a utility with 1,000 line functions that have all their variables initialized at the top, then nested if/else/while loops all throughout it, with terrible variable names, let's not split any functions out for readability. Probably throw an outdated comment header at the top that is lying because Kyle changed something 400 lines down. Also let's reassign the input argument after 40 lines so we make wrong assumptions about what it is later on. Let's use the same index variable for our loops but forget to reinitialize it after the third loop. Let's make some crazy cryptic int return code where 100 means something completely unrelated to -7.2. The functions we do have lets pass similar argument types to but not be consistent about the order so I accidentally pass customer id as order id.\n\nClean code, code complete will save your life no matter how big of a project you're working on.",
                "points": "0 points",
                "children": [
                  {
                    "comment": "You shouldn't even be able to get past a complexity of 15 in any function before sonar waves some red flags your way.",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Lol what, I attended University of Maryland back in the early 2000s and we covered all that shit it 400 level classes.\n\nThe lack of QA is always a result of the people who control the money not allocating it to QA.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Because consumer and companies cares more about features. Tesla is a perfect example of this.\n\nInnovating takes corner cutting somewhere.\n\nWeapon systems, health monitor systems etc is another thing though, quality is a feature there",
        "points": "2 points",
        "children": [
          {
            "comment": "having quality IS more features, having the buggy nonsense code that sadly the majority puts out is LESS features as well as a worse end product. However, this is something that comes into effect over multiple months or a few years, not right away, and most POs are incompetent at their job because they incorrectly decide that buggy shit that will cost much, much more time overall to become usable would be an acceptable outcome of a ticket. The only scenario where low quality code is actually the fastest way is for a bad product that should only look good on paper or to enable the marketing team to lie and act as if it would be worth the money, but if you're programming on something like that you failed at life anyway.",
            "points": "2 points",
            "children": [
              {
                "comment": "First of you are wrong to assume its low quality just because you didnt put time on testing. No one goes out of their way to write bad code.\n\ntesting just confirms or denies it.\n\nBesides games and services are great example.\n\nEver heard of those being crashed and downed during release? People keep pounding the shit even if nothing works because the product is so good.\n\nNo one cares if your service is the best quality in the world but its useless.",
                "points": "4 points",
                "children": [
                  {
                    "comment": "your reply only contains incorrect assumptions (you e.g. dreamed up that I would be purely talking about \"testing\", which I never mentioned) and nonsense statements, so there's nothing proper for me to reply to. And whether the product itself is popular because good design or gameplay might counter low software qualtiy is irrelevant and a completely different topic, higher quality and therefore overall faster coding is superior to low quality code and therefore overall a slower and worse product. My point stands. On a bit longer time scale the fastest, cheapest way to build software is by caring about quality. You on the other hand seem like a bad programmer that wants to feel better about yourself by finding excuses for your lack of skill.",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Nobody knows how to build quality software.",
        "points": "0 points",
        "children": [
          {
            "comment": "That's not really true. A huge part of building quality software if figuring out the right feature set and usability. That takes time and effort and is embedded into all the project areas and steps in those companies that are able to pump out quality software on a fairly regular basis.",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "Most people do, a subset even know how to do it in a timeframe that keeps the product people happy",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Most programmers don't care. Most write garbage code and use either \"the compiler will optimize it anyway\" or \"hardware is getting faster so who cares\" as a defense.",
        "points": "-5 points",
        "children": [
          {
            "comment": "The real defense is \"I write what I have time for.\" I have worked at places where we did GOOD software. It was drilling stuff. Full unit tests. Full automated UI tests. Every PR was double reviewed. It then went to full field trial before going out to the sites. It was a 2 year cycle to get a new feature implemented and fully in the field.\n\nI worked there with guys who were slinging shitty C++/C# code for a company that did shovelware for Dell and other big computer manufacturers. This was right around when Vista hit. We all gotnlaid off. A bunch of us ended up at the drilling company.\n\nSame, guys. Wildly different code quality.",
            "points": "7 points",
            "children": [
              {
                "comment": "I write what I have time for\n\nThis is such a good way of framing it",
                "points": "3 points",
                "children": [
                  {
                    "comment": "My first tech job was in 96 when I was in high school. I worked for the school as a part of an ROP program. My first start-up was in 2000 as tech support. I have been QA, dev, and management. I have learned that it's the only measurement that matters.",
                    "points": "2 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "I guess all the people making those garbage excuses aren't real programmers then.",
                "points": "-9 points",
                "children": [
                  {
                    "comment": "I was QA for these guys. They asked me to become a dev with them at the mew company. Many of the devs there had spent time in QA on automation and other things. We knew good code from bad code. We just were not paid to make good code. We were paid to make shovelware.\n\nSometimes you just do the jobs you can find.",
                    "points": "2 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "That’s what you team and srs are for",
        "points": "-1 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Brief overview:\n\nFlorian Bellmann's blog post discusses the overlooked importance of Quality Assurance (QA) in software development. He notes that despite its crucial role, QA is often neglected in\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually 👍",
        "points": "-24 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Law of r/programming: most contrarian comment floats to the top",
        "points": "-2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "You have to study the protocols in use, their flaws. Hardware systems and the nature of digital/analog signals. You didn't learn that stuff. I guess that's the premise about degradation in (public) education? Holistic explanation? I bet you can code your *** off in (language xyz) though. If you're not dead start supplementing your education. Arouse purpose. Before you do die. Maybe you won't die? I'm sorry for the paradox of the unnecessary. ..",
        "points": "-12 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "I was never taught per se but I learned it as a part of the job.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Hope this helps. It shows the difference between using just testing Vs combining 2 reviews, tests and formal QA metrics.\n\nhttps://docs.google.com/spreadsheets/d/1h1bpuggseVZ65KiuPdNDrnvomfH5-lXHBMiCyyr4mRk/edit?usp=drivesdk\n\nPs. I have seen good and bad QA. A not so great one was for a 4 month project. The customer was reporting about 20 bugs a day when doing acceptance tests. I have also seen a 3 month project where only 1 bug was found by the end user. The only real difference between the two was the QA. Both similar complexity, skilled experienced Devs. ... The 4 month project became a 7 month project.\n\nresults in the customer reporting 20 bugs a day when doing acceptance tests. maybe the customer reports 1 bug. reduces costs/dev time by 30-50%",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "that's what good leads are for though?",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "how OP knows what I think/my school career topics?",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Taught? \"This feature needs to be finished by the end of this sprint!\"\n\nAlso, no refactor, only features!",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "When I was at uni, we were allowed to use any style in our assignments, as long as we're consistent with it. People failed assignments because they used spaces in one place and tabs elsewhere ( within the same assignment).\n\nWe were specifically given assignments with unrelated requirements, like function Y must return X, even though X isn't used anywhere.\n\nAnd several weeks later we were given assignments which would need function Y and its returned value X.\n\nWe were given random assignments, and later had to \"stitch together\" each other's code.\n\nWe were allowed to have, and reuse our assignments during exams.\n\nLots of random things were constructed in a way, that were meant to teach us the value of code quality.\n\nThere wasn't a dedicated course for \"code quality\" but they gave us a solid foundation for extrapolating and understanding \"quality\".",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "These (value of QA, how to do it and how to improve code base quality) were included on department specific courses starting freshman year in my university, department was Computer Science and Engineering. Also most of the common \"they don't teach this in school\" topics were possible majors in our department, and these days school requires a minor from another department, so everyone has at least one domain with relevant domain knowledge.\n\nIt was in industry where no-one, especially the veterans and self taught code wizards did not really care about these at all.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "QA is not about creating quality, it’s about measuring it.\n\nThat’s like saying no one is rich because there’s taxes. It’s a non-sequitur.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "teachings or not, there are a lot of factors college doesn't (or maybe cannot) address:\n\nteam dynamics\nturnover\noffice politics\nbusiness/ economic waves\n\nbeing taught to wing it because we don't need / have time to produce a properly designed solution is the norm (maybe since the 2000s ? I don't know)\n\nGive me a few angry engineers and some time and you'll get some good piece of software.. but 2 weeks with limited bullshitters and you'll get hacks.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "That’s why you can’t have both hard deadlines and the inability to cut scope. Software estimation is not a precise art. Because then quality inevitably suffers. Sometimes that’s ok, but most of the time you’re tremendously adding to development costs later on.",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1abwfph",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://youtu.be/XyV5QqLHO-8",
    "title": "Sharing a journey of building my first iOS app",
    "points": null,
    "comments": []
  },
  {
    "id": "t3_1abvs1j",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://medium.com/javascript-scene/the-shocking-secret-about-static-types-514d39bf30a3",
    "title": "The Shocking Secret About Static Types",
    "points": null,
    "comments": [
      {
        "comment": "The premise seems silly. Static typing is not supposed to be a panacea against bugs. Static typing simply time-shifts detection of type errors from runtime to compile-time. It makes type errors easier to find. That's all.",
        "points": "21 points",
        "children": [
          {
            "comment": "There is also the thing that what a type is what the type system says.\n\nSo we can make types to catch certain logic errors. Like having a type for positive or non-negative numbers, having types for string formats like URL or email. We can encode logic in the type system. That's what they are for.\n\nIt's just that if your lang doesn't include these, you either have to look for library or write those yourself.",
            "points": "7 points",
            "children": [
              {
                "comment": "Yes, a type system can do that, but that's not a specific property of static typing. My point is that (properly implemented) static typing and dynamic typing will catch the same errors, just at different times.",
                "points": "2 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "In other words, do you want to find the bug or so you let the users find it.",
            "points": "0 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Static type checking catches more type errors than dynamically typed language compilers do. This is almost an obvious tautology.\n\nIt doesn’t make promises about catching logic errors. But it does give a way to leg into turning more and more logic errors into type errors if the type system is expressive enough.",
        "points": "8 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "TDD is just absolute garbage- almost as much as this article. Static typing is a tool that can let you write better code, but like anything else in programming you can’t go into it naively and expect to have everything work out.\n\nLook at programs that are commonly used as case studies in low defect programs- for example xmonad. They are almost always written in statically typed languages.",
        "points": "1 point",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Essential Highlights:\n\nThe post challenges the popular belief that static types significantly reduce bug density in software development. It references studies showing the limited impact of static types on bug reduction, compared to the more substantial benefits of Test Driven Development (TDD). The post also argues that while static types offer certain developer tools and can be useful, they provide a false sense of security regarding bug prevention. It concludes by advocating for TDD as a more effective method for reducing bugs while recognizing the ancillary benefits of static types. NOTE: This is not related to the actual summary, but this shows more that types have an effect on the wider programming market than an effect on a highly proficient team. So if you have control of the hiring, go for TDD and hire those skills, if you don't, typescript will probably be a great plumbing tape to get delivery going.\n\nIf you don't like the summary, just downvote and I'll try to delete the comment eventually 👍",
        "points": "-17 points",
        "children": [
          {
            "comment": "this post challenges nothing...its old, and misinformed",
            "points": "13 points",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      }
    ]
  },
  {
    "id": "t3_1abvjxt",
    "subreddit": "r/programming",
    "dataType": "link",
    "dataUrl": "https://medium.com/@tomerr90/project-valhalla-javas-epic-quest-for-performance-immortality-a894db5e0577?source=friends_link&sk=29bdfbc77a80e698e6e32eb2e87587f4",
    "title": "Java’s Epic Quest for Performance Immortality",
    "points": null,
    "comments": [
      {
        "comment": "so valhalla pretty much introduces c#-like structs?",
        "points": "11 points",
        "children": [
          {
            "comment": "Sssshhhhh!!!",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "At first, C# seems like just a Microsoft-ed version of Java. But then you start using it and realize they’ve fixed everything that you hated about Java, and they did it years and years ago.\n\nThis article is just basically saying “we’re trying to add structs” which have been supported in C# since maybe 1.0?\n\n(Since I said “everything” was fixed in C#, here are some other things that I love in C# and am perpetually bugged that Java doesn’t have:\n\nProperties (don’t have to use getters and setters everywhere)\nOperator overloading, including [] for lists\nAsync/await (Java 21 recently released go-like green threads but up until then it had poor concurrency support at the language level)\nExtension methods\nNo type erasure\n\nAnd tons of other syntactic-sugar type stuff. Note that many of these things are available in Kotlin for the JVM but not the performance-improving ones such as struct, since Kotlin is limited by the underlying JVM.)",
        "points": "14 points",
        "children": [
          {
            "comment": "Not to diminish the great work of C#'s team but they also had the benefit of coming after java. They could start fresh (type erasure comes to mind).",
            "points": "2 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "Looks like you forgot a couple of things. Luckily I really enjoy listing them.\n\nThe following is a list of C# language features that have no equivalent in java:\n\nstatic classes\nevents\npartial\nnullable value types\nnullable reference types\nyield\nextension methods\nanonymous types\ntuples\ndeconstruction\nobject initializers\ncollection initializers\ndictionary initializers\nLINQ query syntax\nExpression trees\ndynamic\nnamed arguments\noptional arguments\n[CallerMemberName]\nnameof\nthrow expressions\nnull coalescing operator ??\nnull propagation operator ?.\nnull coalescing assignment ??=\nexpression bodied members\nexception filters\nlocal functions\nref returns and ref locals\nstackalloc\nfixed\ninternal\nprivate protected\nproperty patterns\ntuple patterns\nglobal using\nasync yield\nindices\nranges\nmodule initializers\nnative sized integer types\nfunction pointers\ntop level statements (java's version is awful)\ninit-only\nprimary constructors\nand, not and or patterns\nlist patterns\ngeneric math\ngeneric attributes\nrequired\nmany other I'm probably forgetting right now\n\nLooking at this list, java, even in its current version, is totally laughable.",
            "points": "1 point",
            "children": [],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "The above was fine in 1995, when the first version of Java came out, as the speed of memory and CPU back in those days was about the same.\n\nHowever, in modern days the CPU is MUCH faster than memory, and so this memory layout becomes a significant drag on performance.\n\nI'm fairly certain that none of that \"was fine in 1995\" either. Even back then, we only had 8KB code and data caches on our P5s, but we were also running SIMMs on much narrower busses. RAM has always been slow...",
        "points": "3 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "The thing that was most impressive to me is actually not the numbers themselves, but the fact that a language as old as Java can still make such fundamental changes that have such a significant impact\n\nWell, if you had written that code in C or Rust, you would know that Java still has lots of overhead for problems like that... in fact, I bet even with Project Valhalla, this will still run at least 2x slower than those languages (because Java still will have more overhead from GC, JIT, thread schedulers etc that those languages don't).",
        "points": "-1 points",
        "children": [
          {
            "comment": "That's pretty incorrect. In fact, a JIT compiler can make optimizations and memory allocations in a way that AoT compilation can't.\n\nSo... Realistically, the performance is at parity except for very bespoke, small scope optimizations at or below the language level.",
            "points": "17 points",
            "children": [
              {
                "comment": "Of course it's below language level. That's the entire point: java as a language currently doesn't give you control to create cache friendly flat memory layouts because every object must be able to be null.\n\nIt's the same with SIMD. Java does not have intrinsics, so every language that does will be several times faster for non-trivial vectorisable problems, which is exactly what you see in language benchmarks.",
                "points": "6 points",
                "children": [
                  {
                    "comment": "It will have an API for accessing SIMD computations some time relatively soon.\n\nhttps://openjdk.org/jeps/460",
                    "points": "2 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "a JIT compiler can make optimizations and memory allocations in a way that AoT compilation can't.\n\nKeyword here is: can. In practice how often does this happen and is the difference significant (beyond specific benchmarks)?\n\nJava and its frameworks are very pointer heavy often with deep stacks from many function calls. Even with the introduction of value types the programming culture isn't going to change that quickly, if at all.\n\nRust/C/C++ on the other hand offers tools right from the start to use of large contiguous memory structures with few pointers. Many programmers will be aware of this while designing frameworks/libraries and their applications.\n\nFaster throughput alone isn't everything. Slightly less throughput with little/no variable delays might be preferable depending on the application. In that case using a GC may not even be an option.\n\nEdit:\n\nWith 'pointer heavy' I meant 'indirection heavy'.",
                "points": "8 points",
                "children": [],
                "isDeleted": false
              },
              {
                "comment": "I am not guessing here... I measure these things and spend far too much time doing that... if I am incorrect, I would love to be corrected by some proof if you have any... because from all benchmarks I've tried, and I've done quite a few, no, JIT does not solve the Java overhead... the GraalVM lead (someone who also has done his fare share of measurement) has publicly said that JIT is not as capable as they had once believed it could be and AOT is the better approach in every case they tried to compare.\n\nEDIT: if you want me to provide evidence, I would say check out any language benchmark you can find (maybe start here)... or visit my blog and check my own posts on the topic: https://renato.athaydes.com/all-posts",
                "points": "6 points",
                "children": [
                  {
                    "comment": "GraalVM tackles the startup delay of the JVM, not the performance.  In fact, their official goal is to achieve 90 to 95% of the performance of the JIT JVM.",
                    "points": "4 points",
                    "children": [],
                    "isDeleted": false
                  },
                  {
                    "comment": "fwiw benchmarks game Java vs GraalVM",
                    "points": "0 points",
                    "children": [],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              },
              {
                "comment": "An AoT compiler could silently inject a JIT compiler into its output if it wanted to, and in theory AoT (which includes \"AoT with injected JIT compiler\") cannot be worse than JIT alone.\n\nHowever; there are no AoT compilers that do silently inject a JIT compiler into their output. The reason is that (in practice) JIT is worse than other alternatives (e.g. the compiler auto-generating a \"switch ( CPU_model ) { ....\" where it matters).\n\nThe biggest reason for JIT is the \"more secure because the language is safe and the JIT compiler provides that safety\" myth. In other words, JIT is primarily used by people who can't be trusted, and we accept that slow software is better than having to trust these people (e.g. nobody wants their web browser to download and execute raw AoT compiled machine code from web sites).",
                "points": "0 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "This is very cool",
        "points": "2 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "Im trying to understand why this needs to leaked into the syntax. Can't this be done at compile time instead? I guess since java already takes a long time to compile?",
        "points": "0 points",
        "children": [
          {
            "comment": "Because primitives have different identity semantics to objects, and you cant know what code is reliant on the current semantics. You can't just go changing the meaning of a whole bunch of existing code - otherwise no-one with a codebase of any significant size will use the newer versions",
            "points": "11 points",
            "children": [
              {
                "comment": "Explain how it's represented as byte code for a new compiler version, changes the meaning?\n\nFor example, let's say you are working in Java, and they changed booleans to just be integers at compile time. How would that affect anything? It's a new java version for a new VM? Java isnt low enough level for it to matter (at least that I can see)\n\nThen in the metadata portion, you can say this is the new feature? Like you havent given really any reason that cant be solved.",
                "points": "-2 points",
                "children": [
                  {
                    "comment": "The java bytecode is also stable, if you change bools to ints then any code compiled with the previous compiler is no longer compatible with code compiled with the new compiler. Java has never done this, they only introduce new features, I don’t think there has ever been a breaking change in the bytecode",
                    "points": "7 points",
                    "children": [
                      {
                        "comment": "So you introduce a compiler flag? Solvable.\n\nAnd maybe java should do it when it calls for it, like for this feature rather than bloating the already fat syntax of java\n\nWhat I don't understand is if you add a new keyword it isn't going to work with old compilers anyways. So I really don't understand the argument.",
                        "points": "-3 points",
                        "children": [
                          {
                            "comment": "Compiler flags don’t solve abi or language breakages. If the flag fully breaks compatibility then you essentially created a new language. It’s like saying we added a flag that changes the semantics of == operator to now do the same as obj.equal instead of doing referential equality (this is actually happening with the new record classes)…practically all source code would need to be fixed",
                            "points": "4 points",
                            "children": [
                              {
                                "comment": "I dont get the argument at all. A new keyword requires a new compiler.\n\nA new compiler that does it with flags is somehow ridiculous?",
                                "points": "-2 points",
                                "children": [
                                  {
                                    "comment": "I think I either don’t understand what your suggestion is or you don’t understand backwards compatibility and how languages evolve without breaking their entire ecosystem every time they do updates",
                                    "points": "3 points",
                                    "children": [
                                      {
                                        "comment": "A new keyword isnt backwards compatible?\n\nIm just as confused as you haha. Im trying to understand what you are getting at and you are doing the same for me. I also dont know the ins and outs of java bytecode, but my assumption was if they could rearrange the internals of an array with a new keyword and have the bytecode figure out what to do, then it should be possible with doing it with a compiler flag and be just as backwards compatible. I cant see why not at least",
                                        "points": "0 points",
                                        "children": [
                                          {
                                            "comment": "A flag that changes the semantics of existing constructs is not backward compatible\n\nAdding a new keyword does not break existing code and semantics\n\nYour comment was “why introduce new syntax why not just change the semantics of existing constructs”, at least that’s what I’m understanding it to be…if not clarify what you mean",
                                            "points": "4 points",
                                            "children": [
                                              {
                                                "comment": "",
                                                "points": "",
                                                "children": [],
                                                "isDeleted": false
                                              }
                                            ],
                                            "isDeleted": false
                                          }
                                        ],
                                        "isDeleted": false
                                      }
                                    ],
                                    "isDeleted": false
                                  },
                                  {
                                    "comment": "Maybe you are missing that the way Java libraries are distributed is as bytecode. If you change the translation strategy then you break the ABI and libraries compiled on Java 1 (which still today work) will no longer be usable unless they are recompiled.\n\nBesides the fact that sometimes the source is just not around anymore, this implies a \"flag day\". A point where everyone has to agree to use the new version and migrate everything. This is what happened with python 2->3 and is generally considered something to be avoided",
                                    "points": "0 points",
                                    "children": [
                                      {
                                        "comment": "I think the biggest unknown to me which may be why I am having a hard time understanding why it's breaking, is knowing what the new keyword's generated bytecode looks like. I think once I see that, itll be much more clear",
                                        "points": "0 points",
                                        "children": [],
                                        "isDeleted": false
                                      }
                                    ],
                                    "isDeleted": false
                                  }
                                ],
                                "isDeleted": false
                              },
                              {
                                "comment": "And no. All source code would not need to be fixed? Wth?",
                                "points": "0 points",
                                "children": [],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "Well a few things\n\nJava is pretty fast to compile. It's compiler does very little \"work\" in the same way a rust or C++ compiler would. The optimizations happen at runtime.\n\"Identity semantics\" are the big thing that makes it very hard for the VM to not store data behind a pointer.\nEvery object has a unique result for System.identityHashCode. that needs to be stored somewhere.\nEvery object can potentially be used with \"synchronized\". That monitor needs to live somewhere too.\nObjects are mutable behind their references, which implies indirection to deal with shared references.\nFor maximal flattening in arrays, you need to be able to exclude null from your value set.\n\nTo exclude null, you need some VM notion of implicit constructibility. That's not doable at the compiler level. Hence implicit constructors.\n\nTo have something not behind a pointer, you need to either make sure that no identity sensitive operations happen on the object or you need to rule it out entirely for that category of objects. The first needs a potentially global analysis of code, the second just requires an analysis of the class definition. Hence value classes.",
            "points": "6 points",
            "children": [
              {
                "comment": "Right, but based on their implementation arrays would still have metadata. So, I would think that could store some information about the type of array.\n\nIn the even that an element in array needs a null value, then that could be converted to the legacy array was my thinking but could all be houses in this new array type. So the reason you listed seem solvable.\n\nAnd while identity semantics are great if you plan on running on older VMs, but that can be solved with a compiler flag. So everything you listed is solvable.\n\nAlso, java is not fast to compile. I dont know if you've worked in large code bases before, but whenever I touched a java codebase with close to a million lines, it would take ages compared to even C and significantly slower than Go.",
                "points": "-1 points",
                "children": [
                  {
                    "comment": "So arrays do store information about their type already. The new bit of information they need to store is about null-restricted-ness. If you didn't then you would need to somehow transparently \"unflatten\" when you have an array store that has a null.\n\nAnd no, you cannot solve that with a compiler flag. Rather than dig into the minutia of why, consider this: there are more JVM languages than Java. If any of them could have identity-less classes somehow just by doing things in their compilers, they would.\n\nAnd honestly that's the angle I think we need to approach this from. Very smart people have spent over a decade trying to solve this and they are finally kinda sorta close. If it could be solved by \"why don't they just ...\" It would have been.\n\nI'll track down some videos/articles and update this comment with them since I'm clearly not the best at explaining the situation.\n\nhttps://www.youtube.com/watch?v=a3VRwz4zbdw\n\nhttps://openjdk.org/projects/valhalla/\n\nhttps://mail.openjdk.org/pipermail/valhalla-spec-experts/2023-February/002223.html",
                    "points": "3 points",
                    "children": [
                      {
                        "comment": "I think that last part is a fallacy. Why think of any new features, they would have already done it.\n\nBut Id need to dig into the byte code and see how arrays are represented. I was going based off the article and the level of detail they gave, made it seem like it could just be a compiler option",
                        "points": "-1 points",
                        "children": [
                          {
                            "comment": "Medium is always mid",
                            "points": "1 point",
                            "children": [],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Isn't the article outdated compared to the current form? I think they are not going to introduce primitive objects, but rather null restricted value objects, allowing the vm to make optimizations",
        "points": "0 points",
        "children": [],
        "isDeleted": false
      },
      {
        "comment": "java's epic quest to become a half-assed, badly designed imitation of C# 2.0 from 2005\n\nftfy.\n\nEDIT: lol no, it's worse than that. Even C# 1.0 from 2002 actually supported struct. This is fucking ridiculous.",
        "points": "-25 points",
        "children": [
          {
            "comment": "Idk why people are downvoting you, this is the truth right here",
            "points": "-1 points",
            "children": [],
            "isDeleted": false
          },
          {
            "comment": "Why are so many people against him? What did he say wrong?",
            "points": "-3 points",
            "children": [
              {
                "comment": "He’s not really saying anything interesting…yea sure dotnet had this since 2002, dotnet as a VM sucked for decades, Java still regularly beats it in performance despite CLR having an instruction set and memory model that should be more efficient.",
                "points": "3 points",
                "children": [
                  {
                    "comment": "... I dunno. According to Debian's benchmark game, C# outperforms Java nearly always: https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/csharp.html\n\nIt also performs pretty impressively in the 1BRC: https://hotforknowledge.com/2024/01/13/1brc-in-dotnet-among-fastest-on-linux-my-optimization-journey/#results\n\nMaybe the fact that dotnet provides access to much lower-level tools for performance is making up for some (as you say), uh, sub-optimal internal implementations?",
                    "points": "-1 points",
                    "children": [
                      {
                        "comment": "Yea and if you look at the techempower web benchmarks dotnet is usually behind Java…I agree with you that nowadays clr does perform well if you know what you’re doing but the gap isn’t that big, especially if you consider popular frameworks, despite the fundamental advantages the CLR has.",
                        "points": "1 point",
                        "children": [
                          {
                            "comment": "I'd be interested to know what the deal is with the significant difference between the techempower results and the debian results... any insight into that?",
                            "points": "2 points",
                            "children": [
                              {
                                "comment": "The benchmarks game program source code is probably short enough for you to read and come to your own understanding.",
                                "points": "1 point",
                                "children": [],
                                "isDeleted": false
                              }
                            ],
                            "isDeleted": false
                          }
                        ],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          },
          {
            "comment": "I mean, there is more to say, but the fact that it was in 1.0 meant C# never had to worry about what it meant for code already written or how to upgrade classes that should have had value semantics in a backwards compatible way.\n\nC# also, if I remember correctly, has some rules with their structs that are counter productive like that they always need to be copied into caller contexts instead of that being a VM decision.\n\nC# also made much bigger language mistakes like async/await.\n\nThis feels like the \"is he stupid?\" memes. Like, yes, you did it. Everyone is just as incompetent as you think they are. Congrats, what a fun world.",
            "points": "1 point",
            "children": [
              {
                "comment": "but the fact that it was in 1.0 meant C# never had to worry about what it meant for code already written or how to upgrade classes that should have had value semantics in a backwards compatible way.\n\nWhich is why java should have been thrown to the garbage bin, where it really belongs, 20 years ago.\n\nC# also, if I remember correctly, has some rules with their structs that are counter productive like that they always need to be copied into caller contexts instead of that being a VM decision\n\nI don't think this is correct: https://github.com/dotnet/runtime/blob/main/docs/design/coreclr/jit/first-class-structs.md\n\nC# also made much bigger language mistakes like async/await\n\nSorry, you clearly have no idea what you're talking about. I recently implemented a workflow engine where the workflows are expressed as a single method using async/await, which has the capability to wait for user input, external input, etc. Such thing would have been impossible to implement without async/await in the context of a client application.\n\nasync/await have nothing to do with threading and everything to do with compiler-generated stateful continuations. java can only dream of something like that.",
                "points": "1 point",
                "children": [
                  {
                    "comment": "Which is why java should have been thrown to the garbage bin, where it really belongs, 20 years ago.\n\nThis is just Reddit, you don't have to be mean. That's a choice you are making.\n\nAnd I know you don't actually want that because like, if you stop to think about what that would imply for a little bit it gets horrifying.\n\nLike yes, we should throw out the website where people apply for unemployment benefits. The system that processes medical records too. Lets start from scratch on all those. It will be worth it because reasons.\n\nI don't think this is correct\n\nMaybe this is just a symptom of the existence of mutable value types, but if you do an assignment with a value type it sure does seem like there is a guaranteed copy going on.\n\nFully ready to be wrong about this though.\n\nhttps://learn.microsoft.com/en-us/dotnet/csharp/language-reference/builtin-types/value-types\n\nSorry, you clearly have no idea what you're talking about.\n\nYou got me! Again, what a winner\n\nI recently implemented a workflow engine where the workflows are expressed as a single method using async/await, which has the capability to wait for user input, external input, etc. Such thing would have been impossible to implement without async/await in the context of a client application.\n\nI don't know how you define \"impossible\", but it definitely is possible without async/await. Whether that be by a threading alternative + queues like what virtual threads are in Java or by VM supported continuations like what underpins virtual threads.\n\nIt is definitely doable. Give me enough context and I'll try to make a parallel example.\n\nasync/await have nothing to do with threading and everything to do with compiler-generated stateful continuations. java can only dream of something like that.\n\nEven the .net folks kinda regret async/await. I don't know how well the runtime does with tracking async tasks (I'd assume better than Java would, but worse than normal threads), but doing continuations in the VM over the compiler has a lot of benefits, not the least of which to the programming model and observability.",
                    "points": "1 point",
                    "children": [
                      {
                        "comment": "Even the .net folks kinda regret async/await\n\nI'd rather have a language that actually does things, even if they're not perfect, and later on does research on how to improve that, before I'm forced to use a language that's basically the same piece of ugly shit it was in 1999, and doesn't even have properties in 2024 ffs.",
                        "points": "-1 points",
                        "children": [],
                        "isDeleted": false
                      }
                    ],
                    "isDeleted": false
                  }
                ],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      },
      {
        "comment": "Instead of removing boxing, they invent this bullshit",
        "points": "-19 points",
        "children": [
          {
            "comment": "Think you missed the point, boxing or no boxing they added pass by value not reference which wasn’t possible before. Boxing is an artifact of their standard collections needing to have object not primitive types, this is allowing pass by value instead of reference is how I’m interpreting it.",
            "points": "8 points",
            "children": [
              {
                "comment": "Values are still \"boxed\", it's just that the data structure is flattened to be the same size as the primitive being wrapped, AFAIK.",
                "points": "5 points",
                "children": [],
                "isDeleted": false
              }
            ],
            "isDeleted": false
          }
        ],
        "isDeleted": false
      }
    ]
  }
]